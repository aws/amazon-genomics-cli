<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Amazon Genomics CLI – Concepts</title>
    <link>/docs/concepts/</link>
    <description>Recent content in Concepts on Amazon Genomics CLI</description>
    <generator>Hugo -- gohugo.io</generator>
    
	  <atom:link href="/docs/concepts/index.xml" rel="self" type="application/rss+xml" />
    
    
      
        
      
    
    
    <item>
      <title>Docs: Accounts</title>
      <link>/docs/concepts/accounts/</link>
      <pubDate>Thu, 02 Sep 2021 13:52:05 -0400</pubDate>
      
      <guid>/docs/concepts/accounts/</guid>
      <description>
        
        
        &lt;p&gt;Amazon Genomics CLI requires an AWS account in which to deploy the cloud infrastructure required to run and manage workflows. To begin
working with Amazon Genomics CLI and account must be &amp;ldquo;Activated&amp;rdquo; by the Amazon Genomics CLI application using the &lt;a href=&#34;#activate&#34;&gt;account activate&lt;/a&gt; command.&lt;/p&gt;
&lt;h2 id=&#34;which-aws-account-is-used-by-amazon-genomics-cli&#34;&gt;Which AWS Account is Used by Amazon Genomics CLI?&lt;/h2&gt;
&lt;p&gt;Amazon Genomics CLI uses the same &lt;a href=&#34;https://docs.aws.amazon.com/cli/latest/userguide/cli-configure-quickstart.html#cli-configure-quickstart-precedence&#34;&gt;AWS credential chain&lt;/a&gt;
used by the AWS CLI to determine what account should be used and with what credentials.
All that is required is that you have an existing AWS account (or create a new one) which contains at least one IAM Principal
(User/ Role) that you have can access.&lt;/p&gt;
&lt;h2 id=&#34;which-region-is-used-by-amazon-genomics-cli&#34;&gt;Which Region is Used by Amazon Genomics CLI?&lt;/h2&gt;
&lt;p&gt;Much like accounts and credentials, Amazon Genomics CLI uses the same chain used by the AWS CLI to determine the region that is being targeted.
For example, if your AWS profile uses &lt;code&gt;us-east-1&lt;/code&gt; then Amazon Genomics CLI will use the same. Likewise, if you set the &lt;code&gt;AWS_REGION&lt;/code&gt; environment
variable to &lt;code&gt;eu-west-1&lt;/code&gt; then that region will be used by Amazon Genomics CLI for all subsequent commands in that shell.&lt;/p&gt;
&lt;h2 id=&#34;shared-infrastructure&#34;&gt;Shared Infrastructure&lt;/h2&gt;
&lt;p&gt;When a region is first activated for Amazon Genomics CLI, some basic infrastructure is deployed including a &lt;a href=&#34;https://docs.aws.amazon.com/vpc/latest/userguide/index.html&#34;&gt;VPC&lt;/a&gt;
and an &lt;a href=&#34;https://docs.aws.amazon.com/AmazonS3/latest/userguide/index.html&#34;&gt;S3&lt;/a&gt; bucket. This
core infrastructure will be shared by all Amazon Genomics CLI users and projects in that region. Note that context specific infrastructure
is not shared and is unique and namespaced by user and project.&lt;/p&gt;
&lt;h2 id=&#34;bring-your-own-vpc-and-s3-bucket&#34;&gt;Bring your Own VPC and S3 Bucket&lt;/h2&gt;
&lt;p&gt;During account &lt;a href=&#34;#activate&#34;&gt;activation&lt;/a&gt; you may specify an existing VPC ID or S3 bucket name for use by Amazon Genomics CLI. If you do not these will
be created for you. Although we use AWS best practices for these, if your organization has specific security requirements
for networking and storage this may be the easiest way to activate Amazon Genomics CLI in your environment.&lt;/p&gt;
&lt;h2 id=&#34;account-commands&#34;&gt;Account Commands&lt;/h2&gt;
&lt;p&gt;A full reference of the account commands is &lt;a href=&#34;/docs/reference/agc_account/&#34;&gt;here&lt;/a&gt;&lt;/p&gt;
&lt;h3 id=&#34;activate&#34;&gt;&lt;code&gt;activate&lt;/code&gt;&lt;/h3&gt;
&lt;p&gt;You can activate an account using &lt;code&gt;agc account activate&lt;/code&gt;. An account must be activated before any contexts can be deployed
or workflows run.&lt;/p&gt;
&lt;p&gt;Amazon Genomics CLI requires an S3 bucket to store workflow results and associated information. If you prefer to use an existing bucket
you can use the form  &lt;code&gt;agc account activate --bucket my-existing-bucket&lt;/code&gt;. If you do this the AWS &lt;a href=&#34;https://docs.aws.amazon.com/IAM/latest/UserGuide/index.html&#34;&gt;IAM&lt;/a&gt; role used to run
Amazon Genomics CLI must be able to write to that bucket.&lt;/p&gt;
&lt;p&gt;To use an existing VPC you can use the form  &lt;code&gt;agc account activate --vpc my-existing-vpc-id&lt;/code&gt;. This VPC must have at least
3 availability zones each with at least one private subnet. The private subnets must have connectivity to the internet,
such as via a NAT gateway, and connectivity to AWS services either through VPC endpoints or the internet. Amazon Genomics CLI will not
modify the network topology of the specified VPC.&lt;/p&gt;
&lt;p&gt;Issuing account activate commands more than once effectively updates the core infrastructure with the difference between
the two commands. For example, if you had previously activated the account using &lt;code&gt;agc account activate&lt;/code&gt; and later invoked
&lt;code&gt;agc account activate --bucket my-existing-bucket --vpc my-existing-vpc-id&lt;/code&gt; then Amazon Genomics CLI will update to use &lt;code&gt;my-existing-bucket&lt;/code&gt;
and the identified VPC. The old VPC and related infrastructure will be destroyed. S3 buckets will be &lt;em&gt;retained&lt;/em&gt; according
to their retention policy.&lt;/p&gt;
&lt;p&gt;If you initially activated the account with &lt;code&gt;agc account activate --bucket my-existing-bucket --vpc my-existing-vpc-id&lt;/code&gt;
and later invoked &lt;code&gt;agc account activate&lt;/code&gt; then Amazon Genomics CLI will stop using the previous specified bucket and VPC. &lt;em&gt;ALL&lt;/em&gt; of the
pre-existing S3 and VPC infrastructure will be retained and a new bucket and VPC will be created for use by Amazon Genomics CLI.&lt;/p&gt;
&lt;h3 id=&#34;deactivate&#34;&gt;&lt;code&gt;deactivate&lt;/code&gt;&lt;/h3&gt;
&lt;p&gt;The &lt;code&gt;deactivate&lt;/code&gt; command is used to remove the core infrastructure deployed by Amazon Genomics CLI in the current region when an
account is activated. The S3 bucket deployed by Amazon Genomics CLI and its contents are retained. If a VPC and/ or S3 bucket were
specified by the user during account activation these will also be retained. Any CloudWatch logs produced by Amazon Genomics CLI will
also be retained.&lt;/p&gt;
&lt;p&gt;If there are existing deployed contexts the command will fail, however, you can force the removal of these at the same
time with the &lt;code&gt;--force&lt;/code&gt; flag. Note that this will also interrupt any running workflow of any user in that region.&lt;/p&gt;
&lt;p&gt;The deactivate command will only operate on infrastructure in the current region.&lt;/p&gt;
&lt;p&gt;If the deployed infrastructure has been modified through the console or the AWS CLI rather than through Amazon Genomics CLI deactivation
may fail due to the infrastructure state being inconsistent with the &lt;a href=&#34;https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/index.html&#34;&gt;CloudFormation&lt;/a&gt; state. If this happens you may need
to manually clean up through the CloudFormation console.&lt;/p&gt;
&lt;h2 id=&#34;costs&#34;&gt;Costs&lt;/h2&gt;
&lt;p&gt;Core infrastructure deployed for Amazon Genomics CLI is &lt;a href=&#34;/docs/concepts/namespaces/#tags&#34;&gt;tagged&lt;/a&gt; with the &lt;code&gt;application-name: agc&lt;/code&gt; tag. This tag can be activated for cost
tracking in &lt;a href=&#34;https://docs.aws.amazon.com/awsaccountbilling/latest/aboutv2/ce-what-is.html&#34;&gt;AWS CostExplorer&lt;/a&gt;. The core infrastructure is shared and &lt;em&gt;not&lt;/em&gt; tagged with any username, context name or
project name.&lt;/p&gt;
&lt;p&gt;While an account region is activated there will be ongoing charges from the core infrastructure deployed including things such
as VPC NAT gateways and VPC Endpoints. If you no longer use Amazon Genomics CLI in a region we recommend you deactivate it. You may also
wish to remove the S3 bucket along with its objects as well as the &lt;a href=&#34;https://docs.aws.amazon.com/AmazonCloudWatch/latest/monitoring/index.html&#34;&gt;CloudWatch&lt;/a&gt; logs produced by Amazon Genomics CLI. These are retained
by default so that you can view workflow results and logs even after deactivation.&lt;/p&gt;
&lt;h3 id=&#34;network-traffic&#34;&gt;Network traffic&lt;/h3&gt;
&lt;p&gt;When running genomics workflows, network traffic can become a significant expense when the traffic is routed
through NAT gateways into private subnets (where worker nodes are usually located). To minimize these costs we recommend
the use of VPC Enpoints &lt;a href=&#34;#VPC Endpoints&#34;&gt;(see below)&lt;/a&gt; as well as activating Amazon Genomics CLI and running your workflows in the same region as your S3
bucket holding your genome files. VPC Gateway endpoints are regional so cross region S3 access will &lt;em&gt;not&lt;/em&gt; be routed through
a VPC gateway.&lt;/p&gt;
&lt;p&gt;If you make use of large container images in your workflows (such as the GATK images) we recommend copying these to a
private &lt;a href=&#34;https://docs.aws.amazon.com/AmazonECR/latest/userguide/index.html&#34;&gt;ECR&lt;/a&gt; repository in the same region that you will run your analysis to use ECR endpoints and avoid traffic through
NAT gateways.&lt;/p&gt;
&lt;h3 id=&#34;vpc-endpoints&#34;&gt;VPC Endpoints&lt;/h3&gt;
&lt;p&gt;When Amazon Genomics CLI creates a VPC it creates the following VPC endpoints:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;com.amazonaws.{region}.ecr.api&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;com.amazonaws.{region}.ecr.dkr&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;com.amazonaws.{region}.ecs&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;com.amazonaws.{region}.ecs-agent&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;com.amazonaws.{region}.ecs-telemetry&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;com.amazonaws.{region}.logs&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;com.amazonaws.{region}.s3&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;If you provide your own VPC we recommend that the VPC also has these endpoints. This will improve the security posture of
Amazon Genomics CLI in your VPC and will also reduce NAT gateway traffic charges which can be substantial for genomics analyses that use
large S3 objects and/ or large container images.&lt;/p&gt;
&lt;h2 id=&#34;technical-details&#34;&gt;Technical Details.&lt;/h2&gt;
&lt;p&gt;Amazon Genomics CLI core infrastructure is defined in code and deployed by &lt;a href=&#34;https://aws.amazon.com/cdk/&#34;&gt;AWS CDK&lt;/a&gt;. The CDK app responsible for creating the core
infrastructure can be found in &lt;a href=&#34;https://github.com/aws/amazon-genomics-cli/packages/cdk/core&#34;&gt;&lt;code&gt;packages/cdk/core/&lt;/code&gt;&lt;/a&gt;.&lt;/p&gt;

      </description>
    </item>
    
    <item>
      <title>Docs: Users</title>
      <link>/docs/concepts/users/</link>
      <pubDate>Fri, 03 Sep 2021 09:59:23 -0400</pubDate>
      
      <guid>/docs/concepts/users/</guid>
      <description>
        
        
        &lt;p&gt;When the CLI is set up, the user of the CLI is defined using the &lt;code&gt;agc configure email&lt;/code&gt; command. This email should be
unique to the individual user. This email address is used to determine a unique user ID which will be used to uniquely
identify infrastructure belonging to that user.&lt;/p&gt;
&lt;h2 id=&#34;amazon-genomics-cli-users-are-not-iam-users-or-principals&#34;&gt;Amazon Genomics CLI Users are Not IAM Users (or Principals)&lt;/h2&gt;
&lt;p&gt;Amazon Genomics CLI users are primarily used for identification and as a component of namespacing. They are not a security measure, nor
are they related to IAM users or roles. All AWS activities carried out by Amazon Genomics CLI will be done using the AWS credentials in
the environment where the CLI is installed and are &lt;em&gt;not&lt;/em&gt; based on the Amazon Genomics CLI username.&lt;/p&gt;
&lt;p&gt;For example. If Amazon Genomics CLI is installed on an EC2 instance and configured with the email &lt;code&gt;someone@company.com&lt;/code&gt; Amazon Genomics CLI will interact
with AWS resources based solely on the IAM Role assigned to that EC2 via it&amp;rsquo;s instance profile. Like wise if you use Amazon Genomics CLI
on your laptop then the IAM role that you use will be determined by the same process as is used by the AWS CLI.&lt;/p&gt;
&lt;h2 id=&#34;who-am-i&#34;&gt;Who am I?&lt;/h2&gt;
&lt;p&gt;To find out what username and email has been configured in your current environment you can use the following command:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-shell&#34; data-lang=&#34;shell&#34;&gt;agc configure describe
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h2 id=&#34;changing-user&#34;&gt;Changing user&lt;/h2&gt;
&lt;p&gt;If you update your configured email, a new user identity is generated. If this is done while infrastructure is deployed,
Amazon Genomics CLI may no longer be able to identify that infrastructure as belonging to your project. We strongly
recommend stopping all running workflows and destroying all your deployed contexts from &lt;em&gt;all&lt;/em&gt; projects before changing user.
If you do not do this, you or an account administrator will need to identify any un-needed infrastructure in the CloudFormation
console and remove it from there.&lt;/p&gt;

      </description>
    </item>
    
    <item>
      <title>Docs: Projects</title>
      <link>/docs/concepts/projects/</link>
      <pubDate>Tue, 31 Aug 2021 17:27:06 -0400</pubDate>
      
      <guid>/docs/concepts/projects/</guid>
      <description>
        
        
        &lt;p&gt;An Amazon Genomics CLI project defines the &lt;a href=&#34;/docs/concepts/projects/&#34;&gt;projects&lt;/a&gt;, &lt;a href=&#34;/docs/concepts/contexts/&#34;&gt;contexts&lt;/a&gt;, &lt;a href=&#34;/docs/concepts/data/&#34;&gt;data&lt;/a&gt; and &lt;a href=&#34;/docs/concepts/workflows/&#34;&gt;workflows&lt;/a&gt; that make up a genomics analysis. Each project is defined
in a project file named &lt;code&gt;agc-project.yaml&lt;/code&gt;.&lt;/p&gt;
&lt;h2 id=&#34;project-file-location&#34;&gt;Project File Location&lt;/h2&gt;
&lt;p&gt;To find the project definition, Amazon Genomics CLI will look for a file named &lt;code&gt;agc-project.yaml&lt;/code&gt; in the current working directory. If
the file is not found, Amazon Genomics CLI will traverse up the file hierarchy until the file is found or until the root of the file
system is reached. If no project definition can be found an error will be reported. All Amazon Genomics CLI commands operate on the project identified by the above process.&lt;/p&gt;
&lt;p&gt;Consider the example directory structure below:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;/
├── baa/
│   ├── a/
│   └── agc-project.yaml
├── foo/
└── foz/
    └── a/
        ├── agc-project.yaml
        └── b/
            └── c/
                └── agc-project.yaml
&lt;/code&gt;&lt;/pre&gt;&lt;ul&gt;
&lt;li&gt;If the current working directory is &lt;code&gt;/baa&lt;/code&gt; or &lt;code&gt;/baa/a&lt;/code&gt; then &lt;code&gt;/baa/agc-project.yaml&lt;/code&gt; will be used for definitions,&lt;/li&gt;
&lt;li&gt;If the current working directory is &lt;code&gt;/foo&lt;/code&gt; an error will be reported as no project file is found before the root,&lt;/li&gt;
&lt;li&gt;If the current working directory is &lt;code&gt;/foz&lt;/code&gt; an error will be reported as no project file is found before the root,&lt;/li&gt;
&lt;li&gt;If the current working directory is &lt;code&gt;/foz/a&lt;/code&gt; or &lt;code&gt;/foz/a/b&lt;/code&gt; then &lt;code&gt;/foz/a/agc-project.yaml&lt;/code&gt; will be used for definitions.&lt;/li&gt;
&lt;li&gt;If the current working directory is &lt;code&gt;/foz/a/b/c&lt;/code&gt; then &lt;code&gt;/foz/a/b/c/agc-project.yaml&lt;/code&gt; will be used for definitions.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;relative-locations&#34;&gt;Relative Locations&lt;/h3&gt;
&lt;p&gt;The location of resources declared in a project file are resolved relative to the location of the project file &lt;em&gt;unless&lt;/em&gt;
they are declared using an absolute path. If the project file in &lt;code&gt;/baa&lt;/code&gt; declared that
there was a workflow definition in &lt;code&gt;a/b/&lt;/code&gt; then Amazon Genomics CLI will search for that definition in &lt;code&gt;/baa/a/b/&lt;/code&gt;.&lt;/p&gt;
&lt;h2 id=&#34;project-file-structure&#34;&gt;Project File Structure&lt;/h2&gt;
&lt;p&gt;A minimal project file can be generated using the &lt;code&gt;agc project init myProject --workflow-type nextflow&lt;/code&gt;. Using &lt;code&gt;myProject&lt;/code&gt; as a project name and workflow type &lt;code&gt;nextflow&lt;/code&gt; will result in the following:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-yaml&#34; data-lang=&#34;yaml&#34;&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;name&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;myProject&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;schemaVersion&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#0000cf;font-weight:bold&#34;&gt;1&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;contexts&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;  &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;ctx1&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;    &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;engines&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;      &lt;/span&gt;- &lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;type&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;nextflow&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;        &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;engine&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;nextflow&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;This is fully usable project called &amp;ldquo;myProject&amp;rdquo; with a single context named &amp;ldquo;ctx1&amp;rdquo;. At this point &amp;ldquo;ctx1&amp;rdquo; can be &lt;a href=&#34;/docs/concepts/contexts/#deploy&#34;&gt;deployed&lt;/a&gt;
however, there are currently no workflows defined.&lt;/p&gt;
&lt;h3 id=&#34;name&#34;&gt;&lt;code&gt;name&lt;/code&gt;&lt;/h3&gt;
&lt;p&gt;A string that identifies the project&lt;/p&gt;
&lt;h3 id=&#34;schemaversion&#34;&gt;&lt;code&gt;schemaVersion&lt;/code&gt;&lt;/h3&gt;
&lt;p&gt;An integer defining the schema version. Version numbers will be incremented when changes are made to the project schema
that are not backward compatible.&lt;/p&gt;
&lt;h3 id=&#34;contexts&#34;&gt;&lt;code&gt;contexts&lt;/code&gt;&lt;/h3&gt;
&lt;p&gt;A map of context names to context definitions. Each context in the project must have a unique name. The &lt;a href=&#34;/docs/concepts/contexts/&#34;&gt;contexts&lt;/a&gt;
documentation provides more details.&lt;/p&gt;
&lt;h3 id=&#34;workflows&#34;&gt;&lt;code&gt;workflows&lt;/code&gt;&lt;/h3&gt;
&lt;p&gt;A map of workflow names to workflow definitions. Workflow names must be unique in a project. The &lt;a href=&#34;/docs/concepts/workflows/&#34;&gt;workflows&lt;/a&gt;
documentation provides more details.&lt;/p&gt;
&lt;h3 id=&#34;data&#34;&gt;&lt;code&gt;data&lt;/code&gt;&lt;/h3&gt;
&lt;p&gt;An array of data sources that the contexts of the project have access to. For example:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-yaml&#34; data-lang=&#34;yaml&#34;&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;data&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;  &lt;/span&gt;- &lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;location&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;s3://gatk-test-data&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;    &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;readOnly&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;true&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;  &lt;/span&gt;- &lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;location&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;s3://broad-references&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;    &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;readOnly&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;true&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;  &lt;/span&gt;- &lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;location&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;s3://1000genomes-dragen-3.7.6&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;    &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;readOnly&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;true&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h2 id=&#34;commands&#34;&gt;Commands&lt;/h2&gt;
&lt;p&gt;A full reference of project commands are available &lt;a href=&#34;/docs/reference/agc_project/&#34;&gt;here&lt;/a&gt;&lt;/p&gt;
&lt;h3 id=&#34;init&#34;&gt;&lt;code&gt;init&lt;/code&gt;&lt;/h3&gt;
&lt;p&gt;The &lt;code&gt;agc project init &amp;lt;project-name&amp;gt; --workflow-type &amp;lt;worklow-type&amp;gt;&lt;/code&gt; command can be used to initialize a minimal &lt;code&gt;agc-project.yaml&lt;/code&gt; file in the current
directory. Alternatively project yaml files can be created with any text editor.&lt;/p&gt;
&lt;h3 id=&#34;describe&#34;&gt;&lt;code&gt;describe&lt;/code&gt;&lt;/h3&gt;
&lt;p&gt;The &lt;code&gt;agc project describe &amp;lt;project-name&amp;gt;&lt;/code&gt; command will provide basic metadata about the &amp;lsquo;local&amp;rsquo; project file. See
&lt;a href=&#34;#project-file-location&#34;&gt;above&lt;/a&gt; for details on how project files are located.&lt;/p&gt;
&lt;h2 id=&#34;versioning-and-sharing&#34;&gt;Versioning and Sharing&lt;/h2&gt;
&lt;p&gt;We recommend placing a project under source version control using a tool like &lt;a href=&#34;https://git-scm.com&#34;&gt;Git&lt;/a&gt;. The folder containing the &lt;code&gt;agc-project.yaml&lt;/code&gt;
file is a natural location for the root of a Git repository. Workflows relating to the project would naturally be located
in sub-folders of the same repository allowing those to be versioned as well. Alternatively, more advanced Git users may
consider storing workflows as a Git &lt;a href=&#34;https://git-scm.com/book/en/v2/Git-Tools-Submodules&#34;&gt;sub-module&lt;/a&gt; allowing them to
be independent of the project and reused among projects.&lt;/p&gt;
&lt;p&gt;Projects and associated workflows can then be shared by &amp;ldquo;pushing&amp;rdquo; the project&amp;rsquo;s Git repository to a website such
as &lt;a href=&#34;https://github.com&#34;&gt;GitHub&lt;/a&gt;, &lt;a href=&#34;https://gitlab.com&#34;&gt;GitLab&lt;/a&gt;, or &lt;a href=&#34;https://bitbucket.com&#34;&gt;BitBucket&lt;/a&gt; or hosted on a
private Git Server like &lt;a href=&#34;https://docs.aws.amazon.com/codecommit/latest/userguide/index.html&#34;&gt;AWS Code Commit&lt;/a&gt;. To facilitate sharing you should
ensure that any file paths in your definitions are relative to the project and not absolute. You will also need to make
sure that data locations are appropriately shared.&lt;/p&gt;
&lt;h2 id=&#34;costs&#34;&gt;Costs&lt;/h2&gt;
&lt;p&gt;A project itself doesn&amp;rsquo;t have infrastructure. It is not deployed and therefore has no direct costs. If the contexts defined
by an infrastructure are deployed or the workflows run then those &lt;em&gt;will&lt;/em&gt; incur costs.&lt;/p&gt;
&lt;h3 id=&#34;tags&#34;&gt;Tags&lt;/h3&gt;
&lt;p&gt;The project &lt;code&gt;name&lt;/code&gt; will be &lt;a href=&#34;/docs/concepts/namespaces/#tags&#34;&gt;tagged&lt;/a&gt;
on any deployed contexts or workflows defined in this project allowing costs to be aggregated to the project level.&lt;/p&gt;
&lt;h2 id=&#34;technical-details&#34;&gt;Technical Details&lt;/h2&gt;
&lt;p&gt;A project is purely a &lt;a href=&#34;https://en.wikipedia.org/wiki/YAML&#34;&gt;YAML&lt;/a&gt; definition. The values in the &lt;code&gt;agc-project.yaml&lt;/code&gt; file are used by CDK when Amazon Genomics CLI deploys contexts
and when Amazon Genomics CLI runs workflows. The project itself has no direct infrastructure. The project &lt;code&gt;name&lt;/code&gt; is used to help namespace
context infrastructure.&lt;/p&gt;

      </description>
    </item>
    
    <item>
      <title>Docs: Contexts</title>
      <link>/docs/concepts/contexts/</link>
      <pubDate>Tue, 31 Aug 2021 17:26:49 -0400</pubDate>
      
      <guid>/docs/concepts/contexts/</guid>
      <description>
        
        
        &lt;h2 id=&#34;what-is-a-context&#34;&gt;What is a Context?&lt;/h2&gt;
&lt;p&gt;A context is a set of cloud resources. Amazon Genomics CLI runs &lt;a href=&#34;/docs/concepts/workflows/&#34;&gt;workflows&lt;/a&gt; in a context. A deployed context will include an
&lt;a href=&#34;/docs/concepts/engines/&#34;&gt;engine&lt;/a&gt; that can interpret
and manage the running of a workflow along with compute resources that will run the individual tasks of the workflow. The
deployed context will also contain any resources needed by the engine or compute resources including any security, permissions
and &lt;a href=&#34;/docs/concepts/logs/&#34;&gt;logging&lt;/a&gt; capabilities. Deployed contexts are &lt;a href=&#34;/docs/concepts/namespaces/&#34;&gt;namespaced&lt;/a&gt; based on the user, project and context name so that resources
are isolated, preventing collisions.&lt;/p&gt;
&lt;p&gt;When a workflow is run the user will decide which context will run it. For example, you might choose to submit a workflow
to a context that uses &amp;ldquo;Spot priced&amp;rdquo; resources or one that uses &amp;ldquo;On Demand&amp;rdquo; priced resources.&lt;/p&gt;
&lt;p&gt;When deployed context resources that require a VPC will be deployed into the VPC that was specified when the &lt;a href=&#34;/docs/concepts/accounts/&#34;&gt;account&lt;/a&gt; was
activated.&lt;/p&gt;
&lt;h2 id=&#34;how-is-a-context-defined&#34;&gt;How is a Context Defined?&lt;/h2&gt;
&lt;p&gt;A context is defined in the YAML file that defines the &lt;a href=&#34;/docs/concepts/projects/&#34;&gt;project&lt;/a&gt;. A project has at least one context but may have many.
Contexts must have unique names and are defined as YAML maps.&lt;/p&gt;
&lt;p&gt;A context may request use of &lt;a href=&#34;https://aws.amazon.com/ec2/spot/pricing/&#34;&gt;Spot priced&lt;/a&gt; compute resources with &lt;code&gt;requestSpotInstances: true&lt;/code&gt;. The default value is &lt;code&gt;false&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;A context must define an array of one or more &lt;code&gt;engines&lt;/code&gt;. Each engine definition must specify the workflow language that it
will interpret. For each language Amazon Genomics CLI has a default engine however, users may specify the exact engine in the &lt;code&gt;engine&lt;/code&gt;
parameter.&lt;/p&gt;
&lt;h2 id=&#34;instance-types&#34;&gt;Instance Types&lt;/h2&gt;
&lt;p&gt;You may optionally specify the instance types to be used in a context. This can be a specific type such as &lt;code&gt;r5.2xlarge&lt;/code&gt;
or it can be an instance family such as &lt;code&gt;c5&lt;/code&gt; or a combination. By default, a context will use instance types up to &lt;code&gt;4xlarge&lt;/code&gt;&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Note, if you only specify large instance types you will be using those instances for running even the smallest tasks so
we recommend including smaller types as well.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Ensure that any custom types you list are available in the region that you&amp;rsquo;re using with Amazon Genomics CLI or the
context will fail to deploy. You can obtain a list using the following command&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-shell&#34; data-lang=&#34;shell&#34;&gt;aws ec2 describe-instance-type-offerings &lt;span style=&#34;color:#4e9a06&#34;&gt;\
&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&lt;/span&gt;    --region &amp;lt;region_name&amp;gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h3 id=&#34;examples&#34;&gt;Examples&lt;/h3&gt;
&lt;p&gt;The following snippet defines two contexts, one that uses spot resources and one that uses on demand. Both contain a
WDL engine.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-yaml&#34; data-lang=&#34;yaml&#34;&gt;&lt;span style=&#34;color:#000&#34;&gt;...&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;contexts&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;  &lt;/span&gt;&lt;span style=&#34;color:#8f5902;font-style:italic&#34;&gt;# The on demand context uses on demand EC2 instances which may be more expensive but will not be interrupted&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;  &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;onDemandCtx&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;    &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;requestSpotInstances&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;false&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;    &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;engines&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;      &lt;/span&gt;- &lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;type&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;wdl&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;        &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;engine&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;cromwell&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-yaml&#34; data-lang=&#34;yaml&#34;&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;  &lt;/span&gt;&lt;span style=&#34;color:#8f5902;font-style:italic&#34;&gt;# The spot context uses EC2 spot instances which are usually cheaper but may be interrupted&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;  &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;spotCtx&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;    &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;requestSpotInstances&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;true&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;    &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;engines&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;      &lt;/span&gt;- &lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;type&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;wdl&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;        &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;engine&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;cromwell&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;...&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;The following context may use any instance type from the &lt;code&gt;m5&lt;/code&gt;, &lt;code&gt;c5&lt;/code&gt; or &lt;code&gt;r5&lt;/code&gt; families&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-yaml&#34; data-lang=&#34;yaml&#34;&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;contexts&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;  &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;nfLargeCtx&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;    &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;instanceTypes&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;[&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#34;c5&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;,&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#34;m5&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;,&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#34;r5&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;]&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;      &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;engines&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;        &lt;/span&gt;- &lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;type&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;nextflow&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;          &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;engine&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;nextflow&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h2 id=&#34;context-commands&#34;&gt;Context Commands&lt;/h2&gt;
&lt;p&gt;A full reference of context commands is &lt;a href=&#34;/docs/reference/agc_context/&#34;&gt;here&lt;/a&gt;&lt;/p&gt;
&lt;h3 id=&#34;describe&#34;&gt;&lt;code&gt;describe&lt;/code&gt;&lt;/h3&gt;
&lt;p&gt;The command &lt;code&gt;agc context describe &amp;lt;context-name&amp;gt; [flags]&lt;/code&gt; will describe the named context as defined in the project YAML
as well as other relevant account information.&lt;/p&gt;
&lt;h3 id=&#34;list&#34;&gt;&lt;code&gt;list&lt;/code&gt;&lt;/h3&gt;
&lt;p&gt;The command &lt;code&gt;agc context list [flags]&lt;/code&gt; will list the names of all contexts defined in the project YAML file&lt;/p&gt;
&lt;h3 id=&#34;deploy&#34;&gt;&lt;code&gt;deploy&lt;/code&gt;&lt;/h3&gt;
&lt;p&gt;The command &lt;code&gt;agc context deploy -c &amp;lt;context-name&amp;gt; [flags]&lt;/code&gt; is used to deploy the cloud infrastructure required by the context.
If the context is already running the existing infrastructure will be updated to reflect changes in project YAML. For example
if you added another &lt;code&gt;data&lt;/code&gt; definition in your project and run &lt;code&gt;agc context deploy -c &amp;lt;context-name&amp;gt;&lt;/code&gt; then the deployed context
will be updated to allow access to the new data.&lt;/p&gt;
&lt;p&gt;All contexts defined in the project YAML can be deployed or updated using the &lt;code&gt;--all&lt;/code&gt; flag.&lt;/p&gt;
&lt;p&gt;Individually named contexts can be deployed or updated as positional arguments. For example: &lt;code&gt;acg context deploy -c ctx1 -c ctx2&lt;/code&gt;
will deploy the contexts &lt;code&gt;ctx1&lt;/code&gt; and &lt;code&gt;ctx2&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;The inclusion of the &lt;code&gt;--verbose&lt;/code&gt; flag will show the full CloudFormation output of the context deployment.&lt;/p&gt;
&lt;h3 id=&#34;destroy&#34;&gt;&lt;code&gt;destroy&lt;/code&gt;&lt;/h3&gt;
&lt;p&gt;A contexts cloud resources can be &amp;ldquo;destroyed&amp;rdquo; using the &lt;code&gt;agc context destroy -c &amp;lt;context-name&amp;gt;&lt;/code&gt; command. This will remove any
infrastructure artifacts associated with the context unless they are defined as being retained. Typically, things like logs
and workflow outputs on S3 are retained when a context is destroyed.&lt;/p&gt;
&lt;p&gt;All deployed contexts can be destroyed using the &lt;code&gt;--all&lt;/code&gt; flag.&lt;/p&gt;
&lt;p&gt;Multiple contexts can be destroyed in a single command using positional arguments. For example: &lt;code&gt;acg context destroy -c ctx1 -c ctx2&lt;/code&gt;
will destroy the contexts &lt;code&gt;ctx1&lt;/code&gt; and &lt;code&gt;ctx2&lt;/code&gt;.&lt;/p&gt;
&lt;h3 id=&#34;status&#34;&gt;&lt;code&gt;status&lt;/code&gt;&lt;/h3&gt;
&lt;p&gt;The status command is used to determine the status of a &lt;em&gt;deployed&lt;/em&gt; context or context instance. This can be useful to determine
if an instance of a particular context is already deployed. It can be used to determine if the deployed context is
consistent with the defined context in the project YAML file. For example, if you deploy a context instance and later
change the definition of the context in the project YAML file then the running instance will no longer reflect the definition.
In this case you may choose to update the deployed instance using the &lt;code&gt;agc context deploy&lt;/code&gt; command.&lt;/p&gt;
&lt;p&gt;Status will only be shown for contexts for the current user in the current AWS region for the current project. To show
contexts for another project, issue the command from that project&amp;rsquo;s home folder (or subfolder). To display contexts for
another AWS region, you can use a different AWS CLI profile or set the &lt;code&gt;AWS_PROFILE&lt;/code&gt; environment variable to the
desired region (e.g &lt;code&gt;export AWS_REGION=us-west-2&lt;/code&gt;).&lt;/p&gt;


&lt;div class=&#34;alert alert-warning&#34; role=&#34;alert&#34;&gt;
&lt;h4 class=&#34;alert-heading&#34;&gt;Warning&lt;/h4&gt;

    Because the &lt;code&gt;status&lt;/code&gt; command will only show contexts that are listed in the project YAML you should take care to &lt;code&gt;destroy&lt;/code&gt;
any running contexts before deleting them from the project YAML.

&lt;/div&gt;

&lt;h2 id=&#34;costs&#34;&gt;Costs&lt;/h2&gt;
&lt;p&gt;Infrastructure deployed for a context is tagged with the context name as well as username and project name. These tags
can be used with AWS CostExplorer to identify the costs associated with running contexts.&lt;/p&gt;
&lt;p&gt;A deployed context will incur charges based on the resources being used by the context. If a workflow is running this
will include compute costs for running the workflow tasks but some contexts may include infrastructure that is always
&amp;ldquo;on&amp;rdquo; and will incur costs even when no workflow is running. If you no longer need a context we recommend pausing or
destroying it.&lt;/p&gt;
&lt;p&gt;If &lt;code&gt;requestSpotInstances&lt;/code&gt; is true, the context will use spot instances for compute tasks. The context will set the max
price to 100% although if the current price is lower you will pay the lower price. Note that even at 100% spot instances
can still be interrupted if total demand for on demand instances in an availability zone exceeds the available pool. For
full details see &lt;a href=&#34;https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/spot-interruptions.html&#34;&gt;Spot Instance Interruptions&lt;/a&gt;
and &lt;a href=&#34;https://aws.amazon.com/ec2/spot/pricing/&#34;&gt;EC2 Spot Pricing&lt;/a&gt;.&lt;/p&gt;
&lt;h3 id=&#34;tags&#34;&gt;Tags&lt;/h3&gt;
&lt;p&gt;All context infrastructure is &lt;a href=&#34;/docs/concepts/namespaces/#tags&#34;&gt;tagged&lt;/a&gt; with the context name, username and project name. These tags may be used to help
differentiate costs.&lt;/p&gt;
&lt;h2 id=&#34;technical-details&#34;&gt;Technical Details&lt;/h2&gt;
&lt;p&gt;Context infrastructure is defined as code as &lt;a href=&#34;https://aws.amazon.com/cdk/&#34;&gt;AWS CDK&lt;/a&gt; apps. For examples, take a look at the &lt;code&gt;packages/cdk&lt;/code&gt; folder. When
deployed a context will produce one or more stacks in Cloudformation. Details can be viewed in the Cloudformation console
or with the AWS CLI.&lt;/p&gt;
&lt;p&gt;A context includes an endpoint compliant with the &lt;a href=&#34;https://ga4gh.github.io/workflow-execution-service-schemas/docs/&#34;&gt;GA4GH WES API&lt;/a&gt;. This API is how Amazon Genomics CLI submits workflows to the context. The
context also contains one or more workflow engines. These may either be deployed as long-running services as is the case
with Cromwell or as &amp;ldquo;head&amp;rdquo; jobs that are responsible for a single workflow, as is the case for NextFlow. Engines run as
&amp;ldquo;head&amp;rdquo; jobs are started and stopped on demand thereby saving resources.&lt;/p&gt;
&lt;h3 id=&#34;updating-launch-templates&#34;&gt;Updating Launch Templates&lt;/h3&gt;
&lt;p&gt;Changes to EC2 LaunchTemplates in CDK result in a new LaunchTemplate version when the infrastructure is updated. Currently,
CDK is unable to also update the default version of the template. In addition, any existing AWS Batch Compute Environments
will not be updated to use the new LaunchTemplate version. Because of this, whenever a LaunchTemplate is updated in CDK
code we recommend destroying any relevant running contexts and redeploying them. An update will &lt;em&gt;NOT&lt;/em&gt; be sufficient.&lt;/p&gt;

      </description>
    </item>
    
    <item>
      <title>Docs: Data</title>
      <link>/docs/concepts/data/</link>
      <pubDate>Tue, 31 Aug 2021 17:27:22 -0400</pubDate>
      
      <guid>/docs/concepts/data/</guid>
      <description>
        
        
        &lt;p&gt;To run an analysis you need data. In the &lt;code&gt;agc-project.yaml&lt;/code&gt; file of an Amazon Genomics CLI &lt;a href=&#34;/docs/concepts/projects/&#34;&gt;project&lt;/a&gt; &lt;code&gt;data&lt;/code&gt; is a list of data locations
which can be used by the &lt;a href=&#34;/docs/concepts/contexts/&#34;&gt;contexts&lt;/a&gt; of the project.&lt;/p&gt;
&lt;p&gt;In the example data definition below we are declaring that the project&amp;rsquo;s contexts will be allowed to access the three
listed S3 bucket URIs.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-yaml&#34; data-lang=&#34;yaml&#34;&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;data&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;  &lt;/span&gt;- &lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;location&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;s3://gatk-test-data&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;    &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;readOnly&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;true&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;  &lt;/span&gt;- &lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;location&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;s3://broad-references&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;    &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;readOnly&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;true&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;  &lt;/span&gt;- &lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;location&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;s3://1000genomes-dragen-3.7.6&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;    &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;readOnly&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;true&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;The contexts of the project will be &lt;em&gt;denied&lt;/em&gt; access to all other S3 location except for the S3 bucket created or associated
when the &lt;a href=&#34;/docs/concepts/accounts/&#34;&gt;account&lt;/a&gt; was initialized by Amazon Genomics CLI.&lt;/p&gt;
&lt;p&gt;Declaring access in the project will only ensure your infrastructure is correctly configured to access the bucket. If
the target bucket is further restricted, such as by an access control list or bucket policy, you will still be denied access.
In these cases you should work with the bucket owner to facilitate access.&lt;/p&gt;
&lt;h3 id=&#34;read-and-write&#34;&gt;Read and Write&lt;/h3&gt;
&lt;p&gt;The default value of &lt;code&gt;readOnly&lt;/code&gt; is &lt;code&gt;true&lt;/code&gt;. At the time of writing, write access is not supported (except for the Amazon Genomics CLI core S3 bucket)&lt;/p&gt;
&lt;h3 id=&#34;access-to-a-prefix&#34;&gt;Access to a Prefix&lt;/h3&gt;
&lt;p&gt;The above examples will grant read access to an entire bucket. You can grant more granular access to a prefix within a bucket,
for example:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-yaml&#34; data-lang=&#34;yaml&#34;&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;data&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;  &lt;/span&gt;- &lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;location&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;s3://my-bucket/my/prefix/&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h3 id=&#34;cross-account-access&#34;&gt;Cross Account Access&lt;/h3&gt;
&lt;p&gt;A bucket in another AWS account can be accessed if the owner has set up access, and you are using a role that is allowed access.
See &lt;a href=&#34;https://aws.amazon.com/premiumsupport/knowledge-center/cross-account-access-s3/&#34;&gt;cross account access&lt;/a&gt; for details.&lt;/p&gt;
&lt;h2 id=&#34;updating-data-sources&#34;&gt;Updating Data Sources&lt;/h2&gt;
&lt;p&gt;If data definitions are added to or removed from a project definition the change will &lt;em&gt;not&lt;/em&gt; be reflected in deployed contexts
until they are updated. This can be done with &lt;code&gt;agc context deploy --all&lt;/code&gt; for all contexts or by using a context name to update
only one. See &lt;a href=&#34;/docs/concepts/contexts/#deploy&#34;&gt;&lt;code&gt;context deploy&lt;/code&gt;&lt;/a&gt; for details.&lt;/p&gt;


&lt;div class=&#34;alert alert-warning&#34; role=&#34;alert&#34;&gt;
&lt;h4 class=&#34;alert-heading&#34;&gt;Warning&lt;/h4&gt;

    Removing access to S3 buckets while there are running workflows in a project may cause the workflow to fail if it depends
on access to data in those buckets.

&lt;/div&gt;

&lt;h2 id=&#34;technical-details&#34;&gt;Technical Details&lt;/h2&gt;
&lt;p&gt;When a context is deployed, IAM roles used by the infrastructure of the context will be granted s3 permissions to perform
some S3 read (or read and write) actions on the listed locations. The permissions are defined in CDK code in &lt;code&gt;/packages/cdk/apps/&lt;/code&gt;.
The CDK code does not modify any data in the buckets or any other bucket policies or configurations.&lt;/p&gt;

      </description>
    </item>
    
    <item>
      <title>Docs: Workflows</title>
      <link>/docs/concepts/workflows/</link>
      <pubDate>Tue, 31 Aug 2021 17:27:16 -0400</pubDate>
      
      <guid>/docs/concepts/workflows/</guid>
      <description>
        
        
        &lt;p&gt;A Workflow is a series of steps or tasks to be executed as part of an analysis. To run a workflow using Amazon Genomics CLI, first you must
have deployed a context with suitable compute resources and with a workflow engine that can interpret the language of
the workflow.&lt;/p&gt;
&lt;h2 id=&#34;specification-in-project-yaml&#34;&gt;Specification in Project YAML&lt;/h2&gt;
&lt;p&gt;In an Amazon Genomics CLI project you can specify multiple workflows in a YAML map. The following example defines four WDL version 1.0
workflows. The &lt;code&gt;sourceURL&lt;/code&gt; property defines the location of the workflow file. If the location is relative then the
relevant file is assumed to be relative to the location of the project YAML file. Absolute file locations are also possible
although this may reduce the portability of a project if it is intended to be shared. Web URLS are supported as locations
of the workflow definition file.&lt;/p&gt;
&lt;p&gt;At this time Amazon Genomics CLI does &lt;em&gt;not&lt;/em&gt; resolve path aliases so, for example, a &lt;code&gt;sourceURL&lt;/code&gt; like &lt;code&gt;~/workflows/worklfow.wdl&lt;/code&gt; is not
supported.&lt;/p&gt;
&lt;p&gt;The &lt;code&gt;type&lt;/code&gt; object declares the &lt;code&gt;language&lt;/code&gt; of the workflow (eg, wdl, nextflow etc). The run a workflow there must be a
deployed &lt;a href=&#34;/docs/concepts/contexts/&#34;&gt;context&lt;/a&gt; with a matching language. The &lt;code&gt;version&lt;/code&gt; property refers to the workflow language version.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-yaml&#34; data-lang=&#34;yaml&#34;&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;workflows&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;  &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;hello&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;    &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;type&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;      &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;language&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;wdl&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;      &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;version&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#0000cf;font-weight:bold&#34;&gt;1.0&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;    &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;sourceURL&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;workflows/hello.wdl&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;  &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;read&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;    &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;type&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;      &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;language&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;wdl&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;      &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;version&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#0000cf;font-weight:bold&#34;&gt;1.0&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;    &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;sourceURL&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;workflows/read.wdl&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;  &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;haplotype&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;    &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;type&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;      &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;language&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;wdl&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;      &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;version&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#0000cf;font-weight:bold&#34;&gt;1.0&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;    &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;sourceURL&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;workflows/haplotypecaller-gvcf-gatk4.wdl&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;  &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;words-with-vowels&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;    &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;type&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;      &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;language&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;wdl&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;      &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;version&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#0000cf;font-weight:bold&#34;&gt;1.0&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;    &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;sourceURL&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;workflows/words-with-vowels.wdl&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h3 id=&#34;multi-file-workflows&#34;&gt;Multi-file Workflows&lt;/h3&gt;
&lt;p&gt;Some workflow languages allow for the import of other workflows. To accommodate this, Amazon Genomics CLI supports using a directory as
a source URL. When a directory is supplied as the &lt;code&gt;sourceURL&lt;/code&gt;, Amazon Genomics CLI uses the following rules to determine the name of
the main workflow file and any supporting files:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;If the source URL resolves to a single non-zipped file, then the file is assumed to be a workflow file. Dependent resources (if any) are hardcoded in the file and must be resolvable by the Wes adapter or implicitly the workflow engine (e.g the Wes adapter figures out if the engine can resolve them and if not it resolves them itself).&lt;/li&gt;
&lt;li&gt;The source URL resolves to a zipped file (&lt;code&gt;.zip&lt;/code&gt;).  The zip may contain a manifest.
&lt;ol&gt;
&lt;li&gt;If the zip file does &lt;em&gt;not&lt;/em&gt; contain a file named &lt;code&gt;MANIFEST.json&lt;/code&gt;:
&lt;ol&gt;
&lt;li&gt;The zip file must contain one workflow file with the prefix main followed by the conventional suffix for the workflow, e.g. &lt;code&gt;main.wdl&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Any subworkflows or tasks referenced by the main workflow must either be in the zip at the appropriate relative path or they must be referenced by URLs that are resolvable by the workflow engine. The WesAdapter may attempt to resolve them for the engine but this is a convenience and not required.&lt;/li&gt;
&lt;li&gt;Any variables not defined in the workflows must be provided in an inputs file named with the prefix inputs and the conventional suffix for the workflow engine (e.g &lt;code&gt;inputs.json&lt;/code&gt;). For workflow engines that support multiple input files an index suffix must be provided (e.g. inputs_a.json or inputs_1.json) if there is more than one inputs file.&lt;/li&gt;
&lt;li&gt;A workflow options file may be included and must be named with the options prefix followed by the conventional suffix of the workflow. The WesAdapter may chose to make use of this depending on the context of the workflow engine. It may also choose to pass this to the workflow engine or pass a modified copy to the workflow engine.&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;li&gt;If the zip file &lt;em&gt;does&lt;/em&gt; contain a manifest:
&lt;ol&gt;
&lt;li&gt;The manifest must contain a parameter called mainWorkflowURL. If it does then the value of the parameter must either be a URL or the name of a file present in the zip archive. Any subworkflows or tasks imported by the main workflow must either be referenced as URLs in the workflow or be present in the archive as described above.&lt;/li&gt;
&lt;li&gt;The manifest may contain an array of URLs to inputs files called inputFileURLs. The WesAdapter must decide if it should resolve these or let the workflow engine resolve them.&lt;/li&gt;
&lt;li&gt;The manifest may contain a URL reference to an options files name optionFileURL. The WesAdapter may chose to make use of this depending on the context of the workflow engine. It may also choose to pass this to the workflow engine or pass a modified copy to the workflow engine.&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;The following snippet demonstrates the declaration of a mutlifile workflow:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-yaml&#34; data-lang=&#34;yaml&#34;&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;workflows&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;  &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;gatk4-data-processing&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;    &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;type&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;      &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;langauge&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;wdl&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;      &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;version&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#0000cf;font-weight:bold&#34;&gt;1.0&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;    &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;sourceURL&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;./gatk4-data-processing&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;The following snippet demonstrates a valid &lt;code&gt;MANIFEST.json&lt;/code&gt; file:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-json5&#34; data-lang=&#34;json5&#34;&gt;{
  &amp;quot;mainWorkflowURL&amp;quot;: &amp;quot;processing-for-variant-discovery-gatk4.wdl&amp;quot;,
  &amp;quot;inputFileURLs&amp;quot;: [
    &amp;quot;processing-for-variant-discovery-gatk4.hg38.wgs.inputs.json&amp;quot;
  ],
  &amp;quot;optionFileURL&amp;quot;: &amp;quot;options.json&amp;quot;
}
&lt;/code&gt;&lt;/pre&gt;&lt;h2 id=&#34;engine-selection&#34;&gt;Engine Selection&lt;/h2&gt;
&lt;p&gt;When a workflow is submitted to run, Amazon Genomics CLI will match the workflow type with the map of engines in the context. For example,
if the workflow &lt;code&gt;type&lt;/code&gt; is &lt;code&gt;wdl&lt;/code&gt; Amazon Genomics CLI will attempt to identify and engine designated as the engine for that type. There
may only be one engine per type. If no suitable engine is found in the context an error will be reported.&lt;/p&gt;
&lt;h2 id=&#34;workflow-instances&#34;&gt;Workflow Instances&lt;/h2&gt;
&lt;p&gt;Any defined project workflow can be run multiple times. Each run is called an instance and assigned a unique instance ID.
When referring to a specific run of a workflow you should use the instance ID rather than the workflow name. It is possible
to submit multiple instances of the same workflow and to have these run concurrently.&lt;/p&gt;
&lt;h2 id=&#34;context&#34;&gt;Context&lt;/h2&gt;
&lt;p&gt;All workflows are coordinated by the engine, they are submitted to and executed in the context that is specified at submission time.
The workflow engine decides how the workflow is to be run and the context provides compute resources to run the workflow.&lt;/p&gt;
&lt;h2 id=&#34;commands&#34;&gt;Commands&lt;/h2&gt;
&lt;p&gt;A full reference of workflow commands is available &lt;a href=&#34;/docs/reference/agc_workflow/&#34;&gt;here&lt;/a&gt;&lt;/p&gt;
&lt;h3 id=&#34;run&#34;&gt;&lt;code&gt;run&lt;/code&gt;&lt;/h3&gt;
&lt;p&gt;Invoking &lt;code&gt;agc workflow run &amp;lt;workflow-name&amp;gt; -c &amp;lt;context-name&amp;gt;&lt;/code&gt; will run the named workflow in a specific context. The
unique ID of that workflow instance run will be returned if the submission is successful.&lt;/p&gt;
&lt;h4 id=&#34;workflow-arguments&#34;&gt;&lt;code&gt;workflow arguments&lt;/code&gt;&lt;/h4&gt;
&lt;p&gt;Workflow arguments such as options files can be specified at submission time using the &lt;code&gt;a&lt;/code&gt; or &lt;code&gt;--args&lt;/code&gt; flag. For
example:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-shell&#34; data-lang=&#34;shell&#34;&gt;agc workflow run my-workflow --args inputs.json
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;If the inputs file references local files, these will be synced with S3 and those files in S3 will be used when the workflow
instance is run.&lt;/p&gt;
&lt;h3 id=&#34;list&#34;&gt;&lt;code&gt;list&lt;/code&gt;&lt;/h3&gt;
&lt;p&gt;The &lt;code&gt;agc workflow list&lt;/code&gt; command can be used to list all workflows that are specified in the current project.&lt;/p&gt;
&lt;h3 id=&#34;describe&#34;&gt;&lt;code&gt;describe&lt;/code&gt;&lt;/h3&gt;
&lt;p&gt;The &lt;code&gt;agc workflow describe &amp;lt;workflow-name&amp;gt;&lt;/code&gt; command will return detailed information about the named workflow based on
the specification in the current project YAML file.&lt;/p&gt;
&lt;h3 id=&#34;status&#34;&gt;&lt;code&gt;status&lt;/code&gt;&lt;/h3&gt;
&lt;p&gt;To find out the status of workflow instances that are running, or have been run you can use the &lt;code&gt;agc workflow status&lt;/code&gt; command.
This will display details on 20 recent workflows from the project, to display more, or fewer you can use the &lt;code&gt;--limit number&lt;/code&gt; flag
where the &lt;code&gt;number&lt;/code&gt; may be as many as 1000.&lt;/p&gt;
&lt;p&gt;To list the status of workflows run or running in a specific context use the &lt;code&gt;--context-name&lt;/code&gt; flag and provide the name
of one of the contexts of the project.&lt;/p&gt;
&lt;p&gt;You may get the status of workflow instances by workflow name using the &lt;code&gt;--workflow-name&lt;/code&gt; flag.&lt;/p&gt;
&lt;p&gt;To display the status of a specific workflow instance you can provide the id of the desired workflow instance with the &lt;code&gt;--instance-id&lt;/code&gt; flag.&lt;/p&gt;
&lt;h3 id=&#34;stop&#34;&gt;&lt;code&gt;stop&lt;/code&gt;&lt;/h3&gt;
&lt;p&gt;A running workflow &lt;em&gt;instance&lt;/em&gt; can be stopped at any time using the &lt;code&gt;agc workflow stop &amp;lt;instance-id&amp;gt;&lt;/code&gt; command. When issued,
Amazon Genomics CLI will look up the appropriate context and engine using the &lt;code&gt;instance-id&lt;/code&gt; of the workflow and instruct the engine to
stop the workflow. What happens next depends on the actual workflow engine. For example, in the case of the Cromwell WDL
engine, any currently executing tasks will halt, any pending tasks will be removed from the work queue and no further
tasks will be started for that workflow instance.&lt;/p&gt;
&lt;h2 id=&#34;cost&#34;&gt;Cost&lt;/h2&gt;
&lt;p&gt;Your account will be charged based on actual resource usage including compute time, storage, data transfer charges etc.
The resources used will depend on the resources requested in your workflow definition as interpreted by the workflow engine
according the resources made available in the context in which the workflow is run. If a spot context is used then the costs
of the spot instances will be determined by the rules governing spot instance charges.&lt;/p&gt;
&lt;h3 id=&#34;tags&#34;&gt;Tags&lt;/h3&gt;
&lt;p&gt;Resources used by Amazon Genomics CLI are tagged including the username, project name and the context name. Currently, tagging is &lt;em&gt;not&lt;/em&gt;
possible at the level of an individual workflow.&lt;/p&gt;

      </description>
    </item>
    
    <item>
      <title>Docs: Engines</title>
      <link>/docs/concepts/engines/</link>
      <pubDate>Tue, 31 Aug 2021 17:28:39 -0400</pubDate>
      
      <guid>/docs/concepts/engines/</guid>
      <description>
        
        
        &lt;p&gt;A workflow engine is defined as part of a &lt;a href=&#34;/docs/concepts/contexts/&#34;&gt;context&lt;/a&gt;. A context is currently limited to one workflow engine. The workflow engine will manage the execution of any &lt;a href=&#34;/docs/concepts/workflows/&#34;&gt;workflows&lt;/a&gt; submitted
by Amazon Genomics CLI. When the context is deployed, an endpoint will be made available
to Amazon Genomics CLI through which it will submit workflows and workflow commands to the engine according to the WES API specification.&lt;/p&gt;
&lt;h2 id=&#34;supported-engines-and-workflow-languages&#34;&gt;Supported Engines and Workflow Languages&lt;/h2&gt;
&lt;p&gt;Currently, Amazon Genomics CLI&amp;rsquo;s officially supported engines can be used to run the following workflows:&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Engine&lt;/th&gt;
&lt;th&gt;Language&lt;/th&gt;
&lt;th&gt;Language Versions&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href=&#34;https://cromwell.readthedocs.io/en/stable/&#34;&gt;Cromwell&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href=&#34;https://openwdl.org&#34;&gt;WDL&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;All versions up to 1.0&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href=&#34;https://www.nextflow.io&#34;&gt;Nextflow&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href=&#34;https://www.nextflow.io/docs/latest/script.html&#34;&gt;Nextflow DSL&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Standard and DSL 2&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;Overtime we plan to add additional engine and language support and provide the ability for third party developers to
develop engine plugins.&lt;/p&gt;
&lt;h2 id=&#34;engine-definition&#34;&gt;Engine Definition&lt;/h2&gt;
&lt;p&gt;An engine is defined within a &lt;code&gt;context&lt;/code&gt; definition of the &lt;a href=&#34;/docs/concepts/projects/#project-file-structure&#34;&gt;project YAML file&lt;/a&gt; file as a map. For example, the following snippet
defines a WDL engine of type &lt;code&gt;cromwell&lt;/code&gt; as part of the context named &lt;code&gt;onDemandCtx&lt;/code&gt;. There may be one engine defined
for each supported language.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-yaml&#34; data-lang=&#34;yaml&#34;&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;contexts&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;  &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;onDemandCtx&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;    &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;requestSpotInstances&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;false&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;    &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;engines&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;      &lt;/span&gt;- &lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;type&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;wdl&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;        &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;engine&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;cromwell&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h2 id=&#34;commands&#34;&gt;Commands&lt;/h2&gt;
&lt;p&gt;There are no commands specific to engines. Engines are &lt;a href=&#34;/docs/concepts/contexts/#deploy&#34;&gt;deployed&lt;/a&gt; along with contexts by the &lt;a href=&#34;/docs/concepts/contexts/#context-commands&#34;&gt;&lt;code&gt;context&lt;/code&gt; commands&lt;/a&gt; and workflows
are run using the &lt;a href=&#34;/docs/concepts/workflows/#commands&#34;&gt;&lt;code&gt;workflow&lt;/code&gt; commands&lt;/a&gt;.&lt;/p&gt;
&lt;h2 id=&#34;costs&#34;&gt;Costs&lt;/h2&gt;
&lt;p&gt;The costs associated with an engine depend on the actual infrastructure required by the engine. In the case of the Cromwell,
the engine runs in &amp;ldquo;server&amp;rdquo; mode as an &lt;a href=&#34;https://docs.aws.amazon.com/AmazonECS/latest/userguide/index.html&#34;&gt;AWS ECS Fargate&lt;/a&gt; container using an
&lt;a href=&#34;https://docs.aws.amazon.com/efs/latest/ug/index.html&#34;&gt;Amazon Elastic File System&lt;/a&gt; for metadata storage. The container
will be running for the entire time the context is deployed, even when no workflows are running. To avoid this cost we
recommend destroying the context when it is not needed. The Nextflow engine runs as a single batch job per workflow instance
and is only running when workflows are running.&lt;/p&gt;
&lt;p&gt;In both cases a serverless WES API endpoint is deployed through &lt;a href=&#34;https://docs.aws.amazon.com/apigatewayv2/latest/api-reference/&#34;&gt;Amazon API Gateway&lt;/a&gt; to act as the interface between Amazon Genomics CLI and
the engine.&lt;/p&gt;
&lt;h3 id=&#34;tags&#34;&gt;Tags&lt;/h3&gt;
&lt;p&gt;Being part of a context, engine related infrastructure is &lt;a href=&#34;/docs/concepts/namespaces/#tags&#34;&gt;tagged&lt;/a&gt; with the context name, username and project name. These tags may be used to help
differentiate costs.&lt;/p&gt;
&lt;h2 id=&#34;technical-details&#34;&gt;Technical Details&lt;/h2&gt;
&lt;p&gt;Supported engines are currently deployed with configurations that allow them to make use of files in S3 and submit workflows
as jobs to AWS Batch. Because the current generation of engines we support do not directly support the &lt;a href=&#34;https://ga4gh.github.io/workflow-execution-service-schemas/docs/&#34;&gt;WES API&lt;/a&gt;, adapters
are deployed as Fargate container tasks. AWS API Gateway is used to provide a gateway between Amazon Genomics CLI and the WES adapters.&lt;/p&gt;
&lt;p&gt;When &lt;code&gt;workflow&lt;/code&gt; commands are issued on Amazon Genomics CLI, it will send WES API calls to the appropriate endpoint. The adapter mapped
to that endpoint will then translate the WES command and either send the command to the engines REST API for Cromwell, or
spawn a Nextflow engine task and submit the workflow with that task. At this point the engine is responsible for creating
controlling and destroying the resources that will be used for task execution.&lt;/p&gt;

      </description>
    </item>
    
    <item>
      <title>Docs: Logs</title>
      <link>/docs/concepts/logs/</link>
      <pubDate>Tue, 31 Aug 2021 17:30:49 -0400</pubDate>
      
      <guid>/docs/concepts/logs/</guid>
      <description>
        
        
        &lt;p&gt;The infrastructure deployed by Amazon Genomics CLI records logs for many activities including the workflow runs, workflow
engines as well as infrastructure. The logs are recorded in CloudWatch but are accessible through the CLI.&lt;/p&gt;
&lt;p&gt;When debugging or reviewing a workflow run, the engine logs and workflow logs will be the most useful. For diagnosing
infrastructure or access problems the adapter logs and access logs will be informative.&lt;/p&gt;
&lt;h2 id=&#34;engine-logs&#34;&gt;Engine Logs&lt;/h2&gt;
&lt;p&gt;Engine logs are the logs produced by a workflow engine in a context. The logs produced depend on the engine implementation.
Engines that run in &amp;ldquo;server&amp;rdquo; mode, such as Cromwell, produce a single log for the lifetime of the context that encompass
all workflows run through that engine. Engines that run as &amp;ldquo;head node&amp;rdquo; will produce discrete engine logs for each run.&lt;/p&gt;
&lt;h2 id=&#34;workflow-logs&#34;&gt;Workflow Logs&lt;/h2&gt;
&lt;p&gt;Workflow logs are the aggregate logs for all steps in a workflow run (instance). Any workflow steps that are retrieved from
a call cache are not run so there will be no workflow logs for these steps. Consulting the engine logs may show details of
the call cache. If a previously successful workflow is run with no changes in inputs or parameters it may have all steps
retrieved from the cache in which case there will be no workflow logs although the workflow instance will be marked as a
success and engine logs will be produced. The outputs for a completely cached workflow will also be available.&lt;/p&gt;
&lt;h2 id=&#34;adapter-logs&#34;&gt;Adapter Logs&lt;/h2&gt;
&lt;p&gt;Adapter logs consist of any logs produced by a WES adapter for a workflow engine. They can reveal information such as
the WES API calls that are made to the engine by Amazon Genomics CLI and any errors that may have occurred.&lt;/p&gt;
&lt;h2 id=&#34;access-logs&#34;&gt;Access Logs&lt;/h2&gt;
&lt;p&gt;Amazon Genomics CLI talks to an engine via
API Gateway which routes to the WES adapter. If an expected call does not appear in the adapter logs it may have been
blocked or incorrectly routed in the API Gateway. The API Gateway access logs may be informative in this case.&lt;/p&gt;
&lt;h2 id=&#34;commands&#34;&gt;Commands&lt;/h2&gt;
&lt;p&gt;A full reference of Amazon Genomics CLI &lt;code&gt;logs&lt;/code&gt; commands are available &lt;a href=&#34;/docs/reference/agc_logs/&#34;&gt;here&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&#34;costs&#34;&gt;Costs&lt;/h2&gt;
&lt;p&gt;Amazon Genomics CLI logs are stored in CloudWatch and accessed using the CloudWatch APIs. Standard CloudWatch charges apply.
All logs are retained permanently, even after a context is destroyed and other Amazon Genomics CLI infrastructure is
removed from an account. If they are no longer needed they may be removed using the AWS Console or the AWS CLI.&lt;/p&gt;

      </description>
    </item>
    
    <item>
      <title>Docs: Namespaces</title>
      <link>/docs/concepts/namespaces/</link>
      <pubDate>Tue, 31 Aug 2021 17:26:20 -0400</pubDate>
      
      <guid>/docs/concepts/namespaces/</guid>
      <description>
        
        
        &lt;p&gt;Amazon Genomics CLI uses namespacing to prevent conflicts when there are multiple &lt;a href=&#34;/docs/concepts/users/&#34;&gt;users&lt;/a&gt;, &lt;a href=&#34;/docs/concepts/contexts/&#34;&gt;contexts&lt;/a&gt;, and &lt;a href=&#34;/docs/concepts/projects/&#34;&gt;projects&lt;/a&gt; in the same AWS account and region.&lt;/p&gt;
&lt;p&gt;In any given account and region, an individual user may have many projects with many deployed contexts all running at the
same time without conflict as long as:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;No other user with the same Amazon Genomics CLI username exists in the same account and region.&lt;/li&gt;
&lt;li&gt;All projects, used by that user, have a unique name.&lt;/li&gt;
&lt;li&gt;All contexts within a project have a unique name.&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;shared-project-definitions&#34;&gt;Shared Project Definitions&lt;/h2&gt;
&lt;p&gt;Project definitions can be shared between users. A simple way to achieve this is by putting the project YAML file and associated
workflow definitions into a source control system like Git. If two users in the same account and region start contexts
from the same project definition, these contexts are discrete and include the Amazon Genomics CLI username in the names of their respective
infrastructures.&lt;/p&gt;
&lt;p&gt;Therefore, the following combination are allowed:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;userA -uses-&amp;gt; ProjectA -to-deploy-&amp;gt; ContextA
userB -uses-&amp;gt; ProjectA -to-deploy-&amp;gt; ContextA
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;In the above example it is useful to think of these as two instances of Context A. Both share the same definition but the
instances do not have the same infrastructure.&lt;/p&gt;
&lt;h2 id=&#34;tags&#34;&gt;Tags&lt;/h2&gt;
&lt;p&gt;All Amazon Genomics CLI infrastructure is tagged with the &lt;code&gt;application-name&lt;/code&gt; key and a value of &lt;code&gt;agc&lt;/code&gt;
Aside from the core account infrastructure, all deployed infrastructure is tagged with the following key value pairs:&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Key&lt;/th&gt;
&lt;th&gt;Value&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;agc-project&lt;/td&gt;
&lt;td&gt;The name of the project in which the context is defined&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;agc-user-id&lt;/td&gt;
&lt;td&gt;The unique username&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;agc-user-email&lt;/td&gt;
&lt;td&gt;The users email&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;agc-context&lt;/td&gt;
&lt;td&gt;The name of the context in which the infrastructure is deployed&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;

      </description>
    </item>
    
  </channel>
</rss>
