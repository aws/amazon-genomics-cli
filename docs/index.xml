<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Amazon Genomics CLI ‚Äì Documentation</title>
    <link>https://aws.github.io/amazon-genomics-cli/docs/</link>
    <description>Recent content in Documentation on Amazon Genomics CLI</description>
    <generator>Hugo -- gohugo.io</generator>
    
	  <atom:link href="https://aws.github.io/amazon-genomics-cli/docs/index.xml" rel="self" type="application/rss+xml" />
    
    
      
        
      
    
    
    <item>
      <title>Docs: Accounts</title>
      <link>https://aws.github.io/amazon-genomics-cli/docs/concepts/accounts/</link>
      <pubDate>Thu, 02 Sep 2021 13:52:05 -0400</pubDate>
      
      <guid>https://aws.github.io/amazon-genomics-cli/docs/concepts/accounts/</guid>
      <description>
        
        
        &lt;p&gt;Amazon Genomics CLI requires an AWS account in which to deploy the cloud infrastructure required to run and manage workflows. To begin
working with Amazon Genomics CLI and account must be &amp;ldquo;Activated&amp;rdquo; by the Amazon Genomics CLI application using the &lt;a href=&#34;#activate&#34;&gt;account activate&lt;/a&gt; command.&lt;/p&gt;
&lt;h2 id=&#34;which-aws-account-is-used-by-amazon-genomics-cli&#34;&gt;Which AWS Account is Used by Amazon Genomics CLI?&lt;/h2&gt;
&lt;p&gt;Amazon Genomics CLI uses the same &lt;a href=&#34;https://docs.aws.amazon.com/cli/latest/userguide/cli-configure-quickstart.html#cli-configure-quickstart-precedence&#34;&gt;AWS credential chain&lt;/a&gt;
used by the AWS CLI to determine what account should be used and with what credentials.
All that is required is that you have an existing AWS account (or create a new one) which contains at least one IAM Principal
(User/ Role) that you have can access.&lt;/p&gt;
&lt;h2 id=&#34;which-region-is-used-by-amazon-genomics-cli&#34;&gt;Which Region is Used by Amazon Genomics CLI?&lt;/h2&gt;
&lt;p&gt;Much like accounts and credentials, Amazon Genomics CLI uses the same chain used by the AWS CLI to determine the region that is being targeted.
For example, if your AWS profile uses &lt;code&gt;us-east-1&lt;/code&gt; then Amazon Genomics CLI will use the same. Likewise, if you set the &lt;code&gt;AWS_REGION&lt;/code&gt; environment
variable to &lt;code&gt;eu-west-1&lt;/code&gt; then that region will be used by Amazon Genomics CLI for all subsequent commands in that shell.&lt;/p&gt;
&lt;h2 id=&#34;shared-infrastructure&#34;&gt;Shared Infrastructure&lt;/h2&gt;
&lt;p&gt;When a region is first activated for Amazon Genomics CLI, some basic infrastructure is deployed including a
&lt;a href=&#34;https://docs.aws.amazon.com/vpc/latest/userguide/index.html&#34;&gt;VPC&lt;/a&gt;, which is used for the compute infrastructure that will be deployed in a &lt;a href=&#34;https://aws.github.io/amazon-genomics-cli/amazon-genomics-cli/docs/concepts/contexts/&#34;&gt;context&lt;/a&gt;,
and an &lt;a href=&#34;https://docs.aws.amazon.com/AmazonS3/latest/userguide/index.html&#34;&gt;S3&lt;/a&gt; bucket which will be used to store workflow intermediates and results. This
core infrastructure will be shared by all Amazon Genomics CLI users and projects in that region.&lt;/p&gt;
&lt;p&gt;The following diagram shows the infrastructure deployed when the command &lt;code&gt;agc account activate&lt;/code&gt; is run:&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;AccountActivateArchitecture.png&#34; alt=&#34;Image of shared infrastructure&#34; title=&#34;Shared Infrastructure Components&#34;&gt;&lt;/p&gt;
&lt;p&gt;Note that context specific infrastructure is not shared and is unique and namespaced by user and project.&lt;/p&gt;
&lt;h2 id=&#34;bring-your-own-vpc-and-s3-bucket&#34;&gt;Bring your Own VPC and S3 Bucket&lt;/h2&gt;
&lt;p&gt;During account &lt;a href=&#34;#activate&#34;&gt;activation&lt;/a&gt; you may specify an existing VPC ID or S3 bucket name for use by Amazon Genomics CLI. If you do not these will
be created for you. Although we use AWS best practices for these, if your organization has specific security requirements
for networking and storage this may be the easiest way to activate Amazon Genomics CLI in your environment.&lt;/p&gt;
&lt;h2 id=&#34;account-commands&#34;&gt;Account Commands&lt;/h2&gt;
&lt;p&gt;A full reference of the account commands is &lt;a href=&#34;https://aws.github.io/amazon-genomics-cli/amazon-genomics-cli/docs/reference/agc_account/&#34;&gt;here&lt;/a&gt;&lt;/p&gt;
&lt;h3 id=&#34;activate&#34;&gt;&lt;code&gt;activate&lt;/code&gt;&lt;/h3&gt;
&lt;p&gt;You can activate an account using &lt;code&gt;agc account activate&lt;/code&gt;. An account must be activated before any contexts can be deployed
or workflows run.&lt;/p&gt;
&lt;p&gt;Activating an account will also bootstrap the AWS Environment for CDK app deployments.&lt;/p&gt;
&lt;h4 id=&#34;using-an-existing-s3-bucket&#34;&gt;Using an Existing S3 Bucket&lt;/h4&gt;
&lt;p&gt;Amazon Genomics CLI requires an S3 bucket to store workflow results and associated information. If you prefer to use an existing bucket
you can use the form  &lt;code&gt;agc account activate --bucket my-existing-bucket&lt;/code&gt;. If you do this the AWS &lt;a href=&#34;https://docs.aws.amazon.com/IAM/latest/UserGuide/index.html&#34;&gt;IAM&lt;/a&gt; role used to run
Amazon Genomics CLI must be able to write to that bucket.&lt;/p&gt;
&lt;h4 id=&#34;using-an-existing-vpc&#34;&gt;Using an Existing VPC&lt;/h4&gt;
&lt;p&gt;To use an existing VPC you can use the form  &lt;code&gt;agc account activate --vpc my-existing-vpc-id&lt;/code&gt;. This VPC must have at least
3 availability zones each with at least one private subnet. The private subnets must have connectivity to the internet,
such as via a NAT gateway, and connectivity to AWS services either through VPC endpoints or the internet. Amazon Genomics CLI will not
modify the network topology of the specified VPC.&lt;/p&gt;
&lt;h4 id=&#34;specifying-subnets&#34;&gt;Specifying Subnets&lt;/h4&gt;
&lt;p&gt;When using an existing VPC you may need to specify which subnets of the VPC can be used for infrastructure. This is useful
when only some private subnets have internet routing. To do this you can supply a comma separated list of subnet IDs using
the &lt;code&gt;--subnets&lt;/code&gt; flag, or repeat the flag multiple times. For example:&lt;/p&gt;
&lt;p&gt;&lt;code&gt;agc account activate --vpc my-existing-vpc-id --subnets subnet-id-1,subnet-id-2 --subnets subnet-id-3&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;We recommend a minimum of 3 subnets across availability zones to take advantage of EC2 instance availability and to
ensure high availability of infrastructure.&lt;/p&gt;
&lt;h4 id=&#34;using-a-specific-ami-for-compute-environments&#34;&gt;Using a Specific AMI for Compute Environments&lt;/h4&gt;
&lt;p&gt;Some organizations restrict the use of AMIs to a pre-approved list. By default, Amazon Genomics CLI uses the most recent
version of the Amazon Linux 2 ECS Optimized AMI. To change this behavior you can supply the ID of an alternative AMI at
account activation. This AMI will then be used for all compute environments used by all newly deployed contexts.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-shell&#34; data-lang=&#34;shell&#34;&gt;agc account activate --ami &amp;lt;ami-id&amp;gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;There are some specific requirements that the AMI must comply with. It must be a private AMI from the same account that
you will use for deploying Amazon Genomics CLI infrastructure. It must also be capable of successfully running all parts
of the &lt;a href=&#34;https://github.com/aws/amazon-genomics-cli/blob/main/packages/cdk/lib/constructs/launch-template-data.ts&#34;&gt;LaunchTemplate&lt;/a&gt;
executed at startup time including the &lt;a href=&#34;https://github.com/aws/amazon-genomics-cli/tree/main/packages/cdk/lib/artifacts/batch-artifacts/ecs-additions&#34;&gt;ecs-additions&lt;/a&gt;
dependencies. We recommend an ECS optimized image based on Amazon Linux 2, RHEL, Fedora or similar.&lt;/p&gt;
&lt;p&gt;If the LaunchTemplate cannot complete successfully it will result in an EC2 instance that cannot join a
compute-cluster and cannot complete workflow tasks. A common symptom of this is workflow tasks that become stuck in a &amp;ldquo;runnable&amp;rdquo;
state but are never assigned to a cluster node.&lt;/p&gt;
&lt;h4 id=&#34;using-only-public-subnets&#34;&gt;Using Only Public Subnets&lt;/h4&gt;
&lt;p&gt;Amazon Genomics CLI can create a new VPC with only public subnets to use for its infrastructure using the &lt;code&gt;--usePublicSubnets&lt;/code&gt; flag.&lt;/p&gt;
&lt;p&gt;&lt;code&gt;agc account activate --usePublicSubnets&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;This can reduce costs by removing the need for NAT Gateways and VPC Gateway Endpoints to route internet traffic from private subnets.
It can also reduce the number of Elastic IP Addresses consumed by your infrastructure.&lt;/p&gt;


&lt;div class=&#34;alert alert-warning&#34; role=&#34;alert&#34;&gt;
&lt;h4 class=&#34;alert-heading&#34;&gt;Warning&lt;/h4&gt;

    When using a VPC with only public subnets, you will need to ensure that the contexts defined in &lt;code&gt;agc-project.yaml&lt;/code&gt; files declare that they
will use public subnets. For example:

&lt;/div&gt;

&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-yaml&#34; data-lang=&#34;yaml&#34;&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;contexts&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;  &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;myContext&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;    &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;usePublicSubnets&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;true&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;    &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;engines&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;      &lt;/span&gt;- &lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;type&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;nextflow&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;        &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;engine&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;nextflow&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;div class=&#34;alert alert-warning&#34; role=&#34;alert&#34;&gt;
&lt;h4 class=&#34;alert-heading&#34;&gt;Warning&lt;/h4&gt;

    Currently, use of public subnets is only supported for contexts that use the Nextflow engine. Use of public IPs with the
Cromwell server creates a security risk and will fail. Assignment of public IPs to AWS Batch Fargate tasks (as used by miniwdl and SnakeMake)
is possible but will require changes to the WES adapters of those engines. If you need this please file a &lt;a href=&#34;https://github.com/aws/amazon-genomics-cli/issues/new?labels=enhancement&#34;&gt;feature request&lt;/a&gt; with your use case

&lt;/div&gt;

&lt;h5 id=&#34;security-considerations&#34;&gt;Security Considerations&lt;/h5&gt;
&lt;p&gt;Although your infrastructure will be protected by security groups you should be aware that any manual modification of these may result in exposing your
infrastructure to the internet. For this reason &lt;em&gt;we do &lt;strong&gt;not&lt;/strong&gt; recommend using this configuration in production
or with sensitive data&lt;/em&gt;.&lt;/p&gt;
&lt;h4 id=&#34;updating&#34;&gt;Updating&lt;/h4&gt;
&lt;p&gt;Issuing &lt;code&gt;account activate&lt;/code&gt; commands more than once effectively updates the core infrastructure with the difference between
the two commands according to the rules below.&lt;/p&gt;
&lt;h5 id=&#34;updating-the-vpc&#34;&gt;Updating the VPC&lt;/h5&gt;
&lt;p&gt;You may change the VPC used by issuing the command &lt;code&gt;agc account activate --vpc &amp;lt;vpc-id&amp;gt;&lt;/code&gt;. If a &lt;code&gt;--vpc&lt;/code&gt; argument is &lt;em&gt;not&lt;/em&gt;
provided as part of an &lt;code&gt;agc account activate&lt;/code&gt; command then the last VPC used will be &amp;lsquo;remembered&amp;rsquo; and used by default.&lt;/p&gt;
&lt;p&gt;If you wish to change to use a new default VPC created by Amazon Genomics CLI you must deactivate (&lt;code&gt;agc account deactivate&lt;/code&gt;)
and reactivate with no &lt;code&gt;--vpc&lt;/code&gt; flag.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-shell&#34; data-lang=&#34;shell&#34;&gt;agc account activate               &lt;span style=&#34;color:#8f5902;font-style:italic&#34;&gt;# VPC 1 created.&lt;/span&gt;
agc account activate --vpc-id abc  &lt;span style=&#34;color:#8f5902;font-style:italic&#34;&gt;# VPC 1 destroyed and customer VPC abc used. &lt;/span&gt;
agc account activate               &lt;span style=&#34;color:#8f5902;font-style:italic&#34;&gt;# VPC 2 created. Customer VPC retained.&lt;/span&gt;
agc account deactivate             &lt;span style=&#34;color:#8f5902;font-style:italic&#34;&gt;# AGC core infrastructure destroyed. Customer VPC abc retained.&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h5 id=&#34;updating-to-use-public-subnets-only&#34;&gt;Updating to Use Public Subnets Only&lt;/h5&gt;
&lt;p&gt;If you wish to change the VPC to use public subnets only, or change it from public subnets to private subnets you must
deactivate the account and reactivate it with (or without) the &lt;code&gt;--usePublicSubnets&lt;/code&gt; flag. For example:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-shell&#34; data-lang=&#34;shell&#34;&gt;agc account activate --usePublicSubnets &lt;span style=&#34;color:#8f5902;font-style:italic&#34;&gt;# New VPC with only public subnets&lt;/span&gt;
agc account deactivate                  &lt;span style=&#34;color:#8f5902;font-style:italic&#34;&gt;# VPC destroyed&lt;/span&gt;
agc account activate                    &lt;span style=&#34;color:#8f5902;font-style:italic&#34;&gt;# New VPC with private subnets&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h5 id=&#34;updating-selected-subnets&#34;&gt;Updating Selected Subnets&lt;/h5&gt;
&lt;p&gt;To change a VPC to use a different selection of subnets you must supply both the VPC id and the required subnet IDs.
If you omit the &lt;code&gt;--subnets&lt;/code&gt; flag, then future context deployments will use &lt;em&gt;all&lt;/em&gt; private subnets of the VPC.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-shell&#34; data-lang=&#34;shell&#34;&gt;agc account activate --vpc &amp;lt;vpc-id&amp;gt; --subnets &amp;lt;subnet1,subnet2&amp;gt; &lt;span style=&#34;color:#8f5902;font-style:italic&#34;&gt;# use subnets 1 and 2 of vpc-id &lt;/span&gt;
agc account activate --vpc &amp;lt;vpc-id&amp;gt; --subnets &amp;lt;subnet1,subnet4&amp;gt; &lt;span style=&#34;color:#8f5902;font-style:italic&#34;&gt;# use subnets 1 and 4 of vpc-id&lt;/span&gt;
agc account activate --vpc &amp;lt;vpc-id&amp;gt;                             &lt;span style=&#34;color:#8f5902;font-style:italic&#34;&gt;# use all subnets of vpc-id&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h5 id=&#34;updating-the-compute-environment-ami&#34;&gt;Updating the Compute-Environment AMI&lt;/h5&gt;
&lt;p&gt;The compute-environment AMI can be changed by re-issuing the &lt;code&gt;account activate&lt;/code&gt; command with (or without) the &lt;code&gt;--ami&lt;/code&gt; flag.
If the flag is not provided the latest Amazon Linux 2 ECS optimized image will be used.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-shell&#34; data-lang=&#34;shell&#34;&gt;agc account activate                    &lt;span style=&#34;color:#8f5902;font-style:italic&#34;&gt;# Latest Amazon Linux ECS Optimized AMI used for all contexts&lt;/span&gt;
agc account activate --ami &amp;lt;ami-1234&amp;gt;   &lt;span style=&#34;color:#8f5902;font-style:italic&#34;&gt;# AMI 1234 used for new contexts&lt;/span&gt;
agc account activate                    &lt;span style=&#34;color:#8f5902;font-style:italic&#34;&gt;# Latest Amazon Linux ECS Optimized AMI used for new contexts&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h3 id=&#34;deactivate&#34;&gt;&lt;code&gt;deactivate&lt;/code&gt;&lt;/h3&gt;
&lt;p&gt;The &lt;code&gt;deactivate&lt;/code&gt; command is used to remove the core infrastructure deployed by Amazon Genomics CLI in the current region when an
account is activated. The S3 bucket deployed by Amazon Genomics CLI and its contents are retained. If a VPC and/ or S3 bucket were
specified by the user during account activation these will also be retained. Any CloudWatch logs produced by Amazon Genomics CLI will
also be retained.&lt;/p&gt;
&lt;p&gt;If there are existing deployed contexts the command will fail, however, you can force the removal of these at the same
time with the &lt;code&gt;--force&lt;/code&gt; flag. Note that this will also interrupt any running workflow of any user in that region.&lt;/p&gt;
&lt;p&gt;The deactivate command will only operate on infrastructure in the current region.&lt;/p&gt;
&lt;p&gt;If the deployed infrastructure has been modified through the console or the AWS CLI rather than through Amazon Genomics CLI deactivation
may fail due to the infrastructure state being inconsistent with the &lt;a href=&#34;https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/index.html&#34;&gt;CloudFormation&lt;/a&gt; state. If this happens you may need
to manually clean up through the CloudFormation console.&lt;/p&gt;
&lt;h2 id=&#34;costs&#34;&gt;Costs&lt;/h2&gt;
&lt;p&gt;Core infrastructure deployed for Amazon Genomics CLI is &lt;a href=&#34;https://aws.github.io/amazon-genomics-cli/amazon-genomics-cli/docs/concepts/namespaces/#tags&#34;&gt;tagged&lt;/a&gt; with the &lt;code&gt;application-name: agc&lt;/code&gt; tag. This tag can be activated for cost
tracking in &lt;a href=&#34;https://docs.aws.amazon.com/awsaccountbilling/latest/aboutv2/ce-what-is.html&#34;&gt;AWS CostExplorer&lt;/a&gt;. The core infrastructure is shared and &lt;em&gt;not&lt;/em&gt; tagged with any username, context name or
project name.&lt;/p&gt;
&lt;p&gt;While an account region is activated there will be ongoing charges from the core infrastructure deployed including things such
as VPC NAT gateways and VPC Endpoints. If you no longer use Amazon Genomics CLI in a region we recommend you deactivate it. You may also
wish to remove the S3 bucket along with its objects as well as the &lt;a href=&#34;https://docs.aws.amazon.com/AmazonCloudWatch/latest/monitoring/index.html&#34;&gt;CloudWatch&lt;/a&gt; logs produced by Amazon Genomics CLI. These are retained
by default so that you can view workflow results and logs even after deactivation.&lt;/p&gt;
&lt;p&gt;However, if you wish to have this infrastructure remain deployed, you are able to significantly reduce ongoing costs by using &lt;code&gt;agc account activate --usePublicSubnets&lt;/code&gt;.
This prevents the creation of private subnets with NAT gateways, and the use of VPC endpoints, both of which have associated ongoing costs.
Please note that &lt;strong&gt;you must also set &lt;code&gt;usePublicSubnets: true&lt;/code&gt; in your &lt;code&gt;agc-config.yaml&lt;/code&gt; if you choose to use this option&lt;/strong&gt;.
Please also note that this is not recommended for security-critical deployments, as it means that any edits to the stack security groups risk exposing worker nodes to the public internet.&lt;/p&gt;
&lt;h3 id=&#34;network-traffic&#34;&gt;Network traffic&lt;/h3&gt;
&lt;p&gt;When running genomics workflows, network traffic can become a significant expense when the traffic is routed
through NAT gateways into private subnets (where worker nodes are usually located). To minimize these costs we recommend
the use of VPC Enpoints &lt;a href=&#34;#VPC Endpoints&#34;&gt;(see below)&lt;/a&gt; as well as activating Amazon Genomics CLI and running your workflows in the same region as your S3
bucket holding your genome files. VPC Gateway endpoints are regional so cross region S3 access will &lt;em&gt;not&lt;/em&gt; be routed through
a VPC gateway.&lt;/p&gt;
&lt;p&gt;If you make use of large container images in your workflows (such as the GATK images) we recommend copying these to a
private &lt;a href=&#34;https://docs.aws.amazon.com/AmazonECR/latest/userguide/index.html&#34;&gt;ECR&lt;/a&gt; repository in the same region that you will run your analysis to use ECR endpoints and avoid traffic through
NAT gateways.&lt;/p&gt;
&lt;h3 id=&#34;vpc-endpoints&#34;&gt;VPC Endpoints&lt;/h3&gt;
&lt;p&gt;When Amazon Genomics CLI creates a VPC it creates the following VPC endpoints:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;com.amazonaws.{region}.dynamodb&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;com.amazonaws.{region}.ecr.api&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;com.amazonaws.{region}.ecr.dkr&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;com.amazonaws.{region}.ecs&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;com.amazonaws.{region}.ecs-agent&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;com.amazonaws.{region}.ecs-telemetry&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;com.amazonaws.{region}.logs&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;com.amazonaws.{region}.s3&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;com.amazonaws.{region}.ec2&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;If you provide your own VPC we recommend that the VPC has these endpoints. This will improve the security posture of
Amazon Genomics CLI in your VPC and will also reduce NAT gateway traffic charges which can be substantial for genomics analyses that use
large S3 objects and/ or large container images.&lt;/p&gt;
&lt;p&gt;If you are using Amazon Genomics CLI client on an EC2 instance in a subnet with no access to the internet you will need
to have a VPC endpoint to &lt;code&gt;com.amazonaws.{region}.execute-api&lt;/code&gt; so that the client can make calls to the REST services
deployed during account activation.&lt;/p&gt;
&lt;h2 id=&#34;technical-details&#34;&gt;Technical Details.&lt;/h2&gt;
&lt;p&gt;Amazon Genomics CLI core infrastructure is defined in code and deployed by &lt;a href=&#34;https://aws.amazon.com/cdk/&#34;&gt;AWS CDK&lt;/a&gt;. The CDK app responsible for creating the core
infrastructure can be found in &lt;a href=&#34;https://github.com/aws/amazon-genomics-cli/tree/main/packages/cdk/apps/core&#34;&gt;&lt;code&gt;packages/cdk/apps/core/&lt;/code&gt;&lt;/a&gt;.&lt;/p&gt;

      </description>
    </item>
    
    <item>
      <title>Docs: Users</title>
      <link>https://aws.github.io/amazon-genomics-cli/docs/concepts/users/</link>
      <pubDate>Fri, 03 Sep 2021 09:59:23 -0400</pubDate>
      
      <guid>https://aws.github.io/amazon-genomics-cli/docs/concepts/users/</guid>
      <description>
        
        
        &lt;p&gt;When the CLI is set up, the user of the CLI is defined using the &lt;code&gt;agc configure email&lt;/code&gt; command. This email should be
unique to the individual user. This email address is used to determine a unique user ID which will be used to uniquely
identify infrastructure belonging to that user.&lt;/p&gt;
&lt;h2 id=&#34;amazon-genomics-cli-users-are-not-iam-users-or-principals&#34;&gt;Amazon Genomics CLI Users are Not IAM Users (or Principals)&lt;/h2&gt;
&lt;p&gt;Amazon Genomics CLI users are primarily used for identification and as a component of namespacing. They are not a security measure, nor
are they related to IAM users or roles. All AWS activities carried out by Amazon Genomics CLI will be done using the AWS credentials in
the environment where the CLI is installed and are &lt;em&gt;not&lt;/em&gt; based on the Amazon Genomics CLI username.&lt;/p&gt;
&lt;p&gt;For example. If Amazon Genomics CLI is installed on an EC2 instance and configured with the email &lt;code&gt;someone@company.com&lt;/code&gt; Amazon Genomics CLI will interact
with AWS resources based solely on the IAM Role assigned to that EC2 via it&amp;rsquo;s instance profile. Like wise if you use Amazon Genomics CLI
on your laptop then the IAM role that you use will be determined by the same process as is used by the AWS CLI.&lt;/p&gt;
&lt;h2 id=&#34;who-am-i&#34;&gt;Who am I?&lt;/h2&gt;
&lt;p&gt;To find out what username and email has been configured in your current environment you can use the following command:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-shell&#34; data-lang=&#34;shell&#34;&gt;agc configure describe
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h2 id=&#34;changing-user&#34;&gt;Changing user&lt;/h2&gt;
&lt;p&gt;If you update your configured email, a new user identity is generated. If this is done while infrastructure is deployed,
Amazon Genomics CLI may no longer be able to identify that infrastructure as belonging to your project. We strongly
recommend stopping all running workflows and destroying all your deployed contexts from &lt;em&gt;all&lt;/em&gt; projects before changing user.
If you do not do this, you or an account administrator will need to identify any un-needed infrastructure in the CloudFormation
console and remove it from there.&lt;/p&gt;

      </description>
    </item>
    
    <item>
      <title>Docs: miniwdl</title>
      <link>https://aws.github.io/amazon-genomics-cli/docs/workflow-engines/miniwdl/</link>
      <pubDate>Fri, 01 Oct 2021 17:27:31 -0400</pubDate>
      
      <guid>https://aws.github.io/amazon-genomics-cli/docs/workflow-engines/miniwdl/</guid>
      <description>
        
        
        &lt;h2 id=&#34;description&#34;&gt;Description&lt;/h2&gt;
&lt;p&gt;&lt;a href=&#34;https://miniwdl.readthedocs.io/en/latest/index.html&#34;&gt;miniwdl&lt;/a&gt; is free open source software distributed under the MIT licence
developed by the &lt;a href=&#34;https://chanzuckerberg.com/&#34;&gt;Chan Zuckerberg Initiative&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;The source code for miniwdl is available on &lt;a href=&#34;https://github.com/chanzuckerberg/miniwdl&#34;&gt;GitHub&lt;/a&gt;. When deployed with
Amazon Genomics CLI miniwdl makes use of the &lt;a href=&#34;https://github.com/miniwdl-ext/miniwdl-aws&#34;&gt;miniwdl-aws extension&lt;/a&gt; which is
also distributed under the MIT licence.&lt;/p&gt;
&lt;h2 id=&#34;architecture&#34;&gt;Architecture&lt;/h2&gt;
&lt;p&gt;There are four components of a miniwdl engine as deployed in an Amazon Genomics CLI context:&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;MiniWDLContextArch.png&#34; alt=&#34;Image of infrastructure deployed in a miniwdl context&#34; title=&#34;miniWDL Context Architecture&#34;&gt;&lt;/p&gt;
&lt;h3 id=&#34;wes-adapter&#34;&gt;WES Adapter&lt;/h3&gt;
&lt;p&gt;Amazon Genomics CLI communicates with the miniwdl engine via a GA4GH &lt;a href=&#34;https://github.com/ga4gh/workflow-execution-service-schemas&#34;&gt;WES&lt;/a&gt; REST service. The WES Adapter implements
the WES standard and translates WES calls into calls to the miniwdl head process.&lt;/p&gt;
&lt;h3 id=&#34;head-compute-environment&#34;&gt;Head Compute Environment&lt;/h3&gt;
&lt;p&gt;For every workflow submitted, the WES adapter will create a new AWS Batch Job that contains the miniwdl process responsible
for running that workflow. These miniwdl &amp;ldquo;head&amp;rdquo; jobs are run in an &amp;ldquo;On-demand&amp;rdquo; AWS Fargate compute environment even when the actual workflow
tasks run in a Spot environment. This is to prevent Spot interruptions from terminating the workflow coordinator.&lt;/p&gt;
&lt;h3 id=&#34;task-compute-environment&#34;&gt;Task Compute Environment&lt;/h3&gt;
&lt;p&gt;Workflow tasks are submitted by the miniwdl head job to an AWS Batch queue and run in containers using an AWS Compute Environment.
Container characteristics are defined by the resources requested in the workflow configuration. AWS Batch coordinates the elastic provisioning of EC2 instances (container hosts)
based on the available work in the queue. Batch will place containers on container hosts as space allows.&lt;/p&gt;
&lt;h4 id=&#34;session-cache-and-input-localization&#34;&gt;Session Cache and Input Localization&lt;/h4&gt;
&lt;p&gt;Any context with a miniwdl engine will use an Amazon Elastic File System (EFS) volume as scratch space. Inputs from S3 are
localized to the volume by jobs that the miniwdl engine spawns to copy these files to the volume. Outputs are copied back
to S3 using a similar process. Workflow tasks access the EFS volume to obtain inputs and write intermediates and outputs.&lt;/p&gt;
&lt;p&gt;The EFS volume is used by all miniwdl engine &amp;ldquo;head&amp;rdquo; jobs to store metadata necessary for call caching.&lt;/p&gt;
&lt;p&gt;The EFS volume will remain in your account for the lifetime of the context and are destroyed when contexts are destroyed.
Because the volume will grow in size as you run more workflows we recommend destroying the context when done to avoid on going EFS
charges.&lt;/p&gt;
&lt;h2 id=&#34;using-miniwdl-as-a-context-engine&#34;&gt;Using miniwdl as a Context Engine&lt;/h2&gt;
&lt;p&gt;You may declare miniwdl to be the &lt;code&gt;engine&lt;/code&gt; for any contexts &lt;code&gt;wdl&lt;/code&gt; type engine. For example:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-yaml&#34; data-lang=&#34;yaml&#34;&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;contexts&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;  &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;onDemandCtx&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;    &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;requestSpotInstances&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;false&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;    &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;engines&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;      &lt;/span&gt;- &lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;type&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;wdl&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;        &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;engine&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;miniwdl&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h2 id=&#34;call-caching&#34;&gt;Call Caching&lt;/h2&gt;
&lt;p&gt;Call caching is enabled by default for miniwdl and because the metadata is stored in the contexts EFS volume call caching
will work across different engine &amp;ldquo;head&amp;rdquo; jobs.&lt;/p&gt;
&lt;p&gt;To disable call caching you can provide the &lt;code&gt;--no-cache&lt;/code&gt; engine option. You may do this in a workflows &lt;code&gt;MANIFEST.json&lt;/code&gt; by
adding the following key/ value pair.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;  &amp;quot;engineOptions&amp;quot;: &amp;quot;--no-cache&amp;quot;
&lt;/code&gt;&lt;/pre&gt;
      </description>
    </item>
    
    <item>
      <title>Docs: Walk through</title>
      <link>https://aws.github.io/amazon-genomics-cli/docs/tutorials/walkthrough/</link>
      <pubDate>Thu, 09 Sep 2021 10:16:57 -0400</pubDate>
      
      <guid>https://aws.github.io/amazon-genomics-cli/docs/tutorials/walkthrough/</guid>
      <description>
        
        
        &lt;h2 id=&#34;prerequisites&#34;&gt;Prerequisites&lt;/h2&gt;
&lt;p&gt;Ensure you have completed the &lt;a href=&#34;https://aws.github.io/amazon-genomics-cli/amazon-genomics-cli/docs/getting-started/prerequisites/&#34;&gt;prerequisites&lt;/a&gt; before beginning.&lt;/p&gt;
&lt;h2 id=&#34;download-and-install-amazon-genomics-cli&#34;&gt;Download and install Amazon Genomics CLI&lt;/h2&gt;
&lt;p&gt;Download the Amazon Genomics CLI according to the &lt;a href=&#34;https://aws.github.io/amazon-genomics-cli/amazon-genomics-cli/docs/getting-started/installation/&#34;&gt;installation&lt;/a&gt;
instructions.&lt;/p&gt;
&lt;h2 id=&#34;setup&#34;&gt;Setup&lt;/h2&gt;
&lt;p&gt;Ensure you have initialized your account and created a username by following the &lt;a href=&#34;https://aws.github.io/amazon-genomics-cli/amazon-genomics-cli/docs/getting-started/setup/&#34;&gt;setup&lt;/a&gt;
instructions.&lt;/p&gt;
&lt;h2 id=&#34;initialize-a-project&#34;&gt;Initialize a project&lt;/h2&gt;
&lt;p&gt;Amazon Genomics CLI uses local folders and config files to define projects. Projects contain configuration settings for contexts and workflows (more on these below). To create a new project for running WDL based workflows do the following:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-shell&#34; data-lang=&#34;shell&#34;&gt;mkdir myproject
&lt;span style=&#34;color:#204a87&#34;&gt;cd&lt;/span&gt; myproject
agc project init myproject --workflow-type wdl
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;blockquote&gt;
&lt;p&gt;NOTE: for a Nextflow based project you can substitute &lt;code&gt;--workflow-type wdl&lt;/code&gt; with &lt;code&gt;---workflow-type nextflow&lt;/code&gt;.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Projects may have workflows from different languages, so the &lt;code&gt;--workflow-type&lt;/code&gt; flag is simply to provide the stub for
an initial workflow engine.&lt;/p&gt;
&lt;p&gt;This will create a config file called  &lt;code&gt;agc-project.yaml&lt;/code&gt; with the following contents:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-yaml&#34; data-lang=&#34;yaml&#34;&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;name&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;myproject&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;schemaVersion&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#0000cf;font-weight:bold&#34;&gt;1&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;contexts&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;    &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;ctx1&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;        &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;engines&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;            &lt;/span&gt;- &lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;type&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;wdl&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;              &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;engine&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;cromwell&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;This config file will be used to define aspects of the project - e.g. the contexts and named workflows the project uses. For a
more representative project config, look at the projects in &lt;code&gt;~/agc/examples&lt;/code&gt;. Unless otherwise stated, command line activities for the remainder of this document will assume they are run from within the &lt;code&gt;~/agc/examples/demo-wdl-project/&lt;/code&gt; project folder.&lt;/p&gt;
&lt;h2 id=&#34;contexts&#34;&gt;Contexts&lt;/h2&gt;
&lt;p&gt;Amazon Genomics CLI uses a concept called ‚Äúcontexts‚Äù to run workflows. Contexts encapsulate and automate time-consuming tasks
like configuring and deploying workflow engines, creating data access policies, and tuning compute clusters for operation at scale.
In the &lt;code&gt;demo-wdl-project&lt;/code&gt; folder, after running the following:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-shell&#34; data-lang=&#34;shell&#34;&gt;agc context list
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;You should see something like:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;2021-09-22T01:15:41Z ùíä  Listing contexts.
CONTEXTNAME    cromwell    myContext
CONTEXTNAME    cromwell    spotCtx
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;In this project there are two contexts, one configured to run with On-Demand instances (myContext), and one configured to use SPOT instances (spotCtx).&lt;/p&gt;
&lt;p&gt;You need to have a context running to be able to run workflows. To deploy the context &lt;code&gt;myContext&lt;/code&gt; in the demo-wdl-project, run:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-shell&#34; data-lang=&#34;shell&#34;&gt;agc context deploy myContext
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;This will take 10-15min to complete.&lt;/p&gt;
&lt;p&gt;If you have more than one context configured, and want to deploy them all at once, you can run:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-shell&#34; data-lang=&#34;shell&#34;&gt;agc context deploy --all
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Contexts have read-write access to a context specific prefix in the S3 bucket Amazon Genomics CLI creates during account activation. You can check this for the &lt;code&gt;myContext&lt;/code&gt; context with:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-shell&#34; data-lang=&#34;shell&#34;&gt;agc context describe myContext
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;You should see something like:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;CONTEXT    myContext    false    STARTED
OUTPUTLOCATION    s3://agc-123456789012-us-east-2/project/Demo/userid/xxxxxxxxJKP3z/context/myContext
WESENDPOINT	  https://a1b2c3d4.execute-api.us-east-2.amazonaws.com/prod/ga4gh/wes/v1
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;You can add more data locations using the &lt;code&gt;data&lt;/code&gt; section of the &lt;code&gt;agc-project.yaml&lt;/code&gt; config file. All contexts will have an
appropriate access policy created for the data locations listed when they are deployed. For example, the following config adds three public buckets from the Registry of Open Data on AWS:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-yaml&#34; data-lang=&#34;yaml&#34;&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;name&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;myproject&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;data&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;  &lt;/span&gt;- &lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;location&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;s3://broad-references&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;    &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;readOnly&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;true&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;  &lt;/span&gt;- &lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;location&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;s3://gatk-test-data&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;    &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;readOnly&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;true&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;  &lt;/span&gt;- &lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;location&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;s3://1000genomes&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;    &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;readOnly&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;true&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Note, you need to redeploy any running contexts to update their access to data locations. Do this by simply (re)running.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-shell&#34; data-lang=&#34;shell&#34;&gt;agc context deploy myContext
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Contexts also define what types of compute your workflow will run on - i.e. if you want to run workflows using SPOT or On-demand instances.
By default, contexts use On-demand instances. The configuration for a context that uses SPOT instances looks like the following:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-yaml&#34; data-lang=&#34;yaml&#34;&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;contexts&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;  &lt;/span&gt;&lt;span style=&#34;color:#8f5902;font-style:italic&#34;&gt;# The spot context uses EC2 spot instances which are usually cheaper but may be interrupted&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;  &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;spotCtx&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;    &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;requestSpotInstances&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;true&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;You can also explicitly specify what instance types contexts will be able to use for workflow jobs. By default, Amazon Genomics CLI
will use a select set of instance types optimized for running genomics workflow jobs that balance data I/O performance and
mitigation of workflow failure due to SPOT reclamation. In short, Amazon Genomics CLI uses AWS Batch for job execution
and selects instance types based on the requirements of submitted jobs, up to &lt;code&gt;4xlarge&lt;/code&gt; instance types. If you have a use case
that requires a specific set of instance types, you can define them with something like:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-yaml&#34; data-lang=&#34;yaml&#34;&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;contexts&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;  &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;specialCtx&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;    &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;instanceTypes&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;      &lt;/span&gt;- &lt;span style=&#34;color:#000&#34;&gt;c5&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;      &lt;/span&gt;- &lt;span style=&#34;color:#000&#34;&gt;m5&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;      &lt;/span&gt;- &lt;span style=&#34;color:#000&#34;&gt;r5&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;The above will create a context called &lt;code&gt;specialCtx&lt;/code&gt; that will use any size of instances in the C5, M5, and R5 instance families.
Contexts are elastic with a minimum vCPU capacity of 0 and a maximum of 256. When all vCPUs are allocated to jobs, further
tasks will be queued.&lt;/p&gt;
&lt;p&gt;Contexts also launch an engine for specific workflow types. You can have one engine per context and, currently, engines for WDL and Nextflow are supported.&lt;/p&gt;
&lt;p&gt;A contexts configured with WDL and Nextflow engines respectively look like:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-yaml&#34; data-lang=&#34;yaml&#34;&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;contexts&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;  &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;wdlContext&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;    &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;engines&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;      &lt;/span&gt;- &lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;type&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;wdl&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;        &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;engine&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;cromwell&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;  &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;nfContext&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;    &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;engines&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;      &lt;/span&gt;- &lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;type&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;nextflow&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;        &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;engine&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;nextflow&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h2 id=&#34;workflows&#34;&gt;Workflows&lt;/h2&gt;
&lt;h3 id=&#34;add-a-workflow&#34;&gt;&lt;strong&gt;Add a workflow&lt;/strong&gt;&lt;/h3&gt;
&lt;p&gt;Bioinformatics workflows are written in languages like WDL and Nextflow in either single script files, or in packages of
multiple files (e.g. when there are multiple related workflows that leverage reusable elements). Currently, Amazon Genomics CLI supports both WDL and Nextflow.
To learn more about WDL workflows, we suggest resources like the &lt;a href=&#34;https://github.com/openwdl/learn-wdl&#34;&gt;OpenWDL - Learn WDL course&lt;/a&gt;. To learn more about Nextflow workflows, we suggest &lt;a href=&#34;https://nextflow.io/docs/latest/index.html&#34;&gt;Nextflow‚Äôs documentation&lt;/a&gt; and &lt;a href=&#34;https://nf-co.re/&#34;&gt;NF-Core&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;For clarity, we‚Äôll refer to these workflow script files as ‚Äúworkflow definitions‚Äù. A ‚Äúworkflow specification‚Äù for Amazon Genomics CLI references workflow definitions and combines it with additional metadata,
like the workflow language the definition is written in, which Amazon Genomics CLI will use to execute it on appropriate compute resources.&lt;/p&gt;
&lt;p&gt;There is a ‚Äúhello‚Äù workflow definition in the &lt;code&gt;~/agc/examples/demo-wdl-project/workflows/hello&lt;/code&gt; folder that looks like:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;version 1.0
workflow hello_agc {
    call hello {}
}
task hello {
    command { echo &amp;quot;Hello Amazon Genomics CLI!&amp;quot; }
    runtime {
        docker: &amp;quot;ubuntu:latest&amp;quot;
    }
    output { String out = read_string( stdout() ) }
}
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;The workflow specification for this workflow in the project config looks like:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-yaml&#34; data-lang=&#34;yaml&#34;&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;workflows&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;  &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;hello&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;    &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;type&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;      &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;language&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;wdl&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;      &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;version&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#0000cf;font-weight:bold&#34;&gt;1.0&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;    &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;sourceURL&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;workflows/hello.wdl&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Here the workflow is expected to conform to the &lt;code&gt;WDL-1.0&lt;/code&gt; specification. A specification for a ‚Äúhello‚Äù workflow written in Nextflow DSL1 would look like:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-yaml&#34; data-lang=&#34;yaml&#34;&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;workflows&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;  &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;hello&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;    &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;type&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;      &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;language&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;nextflow&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;      &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;version&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#0000cf;font-weight:bold&#34;&gt;1.0&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;    &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;sourceURL&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;workflows/hello&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;For Nextflow DSL2 workflows set &lt;code&gt;type.version&lt;/code&gt; to &lt;code&gt;dsl2&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;NOTE: When referring to local workflow definitions, &lt;code&gt;sourceURL&lt;/code&gt; must either be a full absolute path or a path relative to the &lt;code&gt;agc-project.yaml&lt;/code&gt; file. Path expansion is currently not supported.&lt;/p&gt;
&lt;p&gt;You can quickly get a list of available configured workflows with:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-shell&#34; data-lang=&#34;shell&#34;&gt;agc workflow list
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;For the &lt;code&gt;demo-wdl-project&lt;/code&gt;, this should return something like:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;2021-09-02T05:14:47Z ùíä  Listing workflows.
WORKFLOWNAME    hello
WORKFLOWNAME    read
WORKFLOWNAME    words-with-vowels
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;The &lt;code&gt;hello&lt;/code&gt; workflow specification points to a single-file workflow. Workflows can also be directories. For example, if you have a workflow that looks like:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;workflows/hello-dir
|-- inputs.json
`-- main.wdl
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;The workflow specification for the workflow above would simply point to the parent directory:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-yaml&#34; data-lang=&#34;yaml&#34;&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;workflows&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;  &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;hello-dir-abs&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;    &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;type&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;        &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;language&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;wdl&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;        &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;version&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#0000cf;font-weight:bold&#34;&gt;1.0&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;    &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;sourceURL&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;/abspath/to/hello-dir&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;  &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;hello-dir-rel&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;    &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;type&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;        &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;language&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;wdl&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;        &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;version&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#0000cf;font-weight:bold&#34;&gt;1.0&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;    &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;sourceURL&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;relpath/to/hello-dir&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;In this case, your workflow must be named &lt;code&gt;main.&amp;lt;workflow-type&amp;gt;&lt;/code&gt; - e.g. &lt;code&gt;main.wdl&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;You can also provide a &lt;code&gt;MANIFEST.json&lt;/code&gt; file that points to a specific workflow file to run. If you have a folder like:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;workflows/hello-manifest/
|-- MANIFEST.json
|-- hello.wdl
|-- inputs.json
`-- options.json
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;The &lt;code&gt;MANIFEST.json&lt;/code&gt; file would be:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-json5&#34; data-lang=&#34;json5&#34;&gt;{
    &amp;quot;mainWorkflowURL&amp;quot;: &amp;quot;hello.wdl&amp;quot;,
    &amp;quot;inputFileURLs&amp;quot;: [
        &amp;quot;inputs.json&amp;quot;
    ]
}
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;At minimum, MANIFEST files &lt;em&gt;must&lt;/em&gt; have a &lt;code&gt;mainWorkflowURL&lt;/code&gt; property which is a relative path to the workflow file in its parent directory.&lt;/p&gt;
&lt;p&gt;Workflows can also be from remote sources like GitHub:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-yaml&#34; data-lang=&#34;yaml&#34;&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;workflows&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;  &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;remote&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;    &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;type&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;        &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;language&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;wdl&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;        &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;version&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#0000cf;font-weight:bold&#34;&gt;1.0&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;  &lt;/span&gt;&lt;span style=&#34;color:#8f5902;font-style:italic&#34;&gt;# this is the WDL spec version&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;    &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;sourceURL&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;https://raw.githubusercontent.com/openwdl/learn-wdl/master/1_script_examples/1_hello_worlds/1_hello/hello.wdl&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;blockquote&gt;
&lt;p&gt;NOTE: remote sourceURLs for Nextflow workflows can be Git repo URLs like: &lt;a href=&#34;https://github.com/nextflow-io/rnaseq-nf.git&#34;&gt;https://github.com/nextflow-io/rnaseq-nf.git&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h3 id=&#34;running-a-workflow&#34;&gt;Running a workflow&lt;/h3&gt;
&lt;p&gt;To run a workflow you need a running context. See the section on contexts above if you need to start one. To run the ‚Äúhello‚Äù workflow in the ‚ÄúmyContext‚Äù context, run:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-shell&#34; data-lang=&#34;shell&#34;&gt;agc workflow run hello --context myContext
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;If you have another context in your project, for example one named ‚Äútest‚Äù, you can run the ‚Äúhello‚Äù workflow there with:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-shell&#34; data-lang=&#34;shell&#34;&gt;agc workflow run hello --context &lt;span style=&#34;color:#204a87&#34;&gt;test&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;If your workflow was successfully submitted you should get something like:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;2021-08-04T23:01:37Z ùíä  Running workflow. Workflow name: &#39;hello&#39;, InputsFile: &#39;&#39;, Context: &#39;myContext&#39;
&amp;quot;06604478-0897-462a-9ad1-47dd5c5717ca&amp;quot;
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;The last line is the workflow run id. You use this id to reference a specific workflow execution.&lt;/p&gt;
&lt;p&gt;Running workflows is an asynchronous process. After submitting a workflow from the CLI, it is handled entirely in the cloud.
You can now close your terminal session if needed. The workflow will still continue to run. You can also run multiple workflows at a time. The underlying compute resources will automatically scale. Try running multiple instances of the ‚Äúhello‚Äù workflow at once.&lt;/p&gt;
&lt;p&gt;You can check the status of all running workflows with:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-shell&#34; data-lang=&#34;shell&#34;&gt;agc workflow status
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;You should see something like this:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;WORKFLOWINSTANCE    myContext    66826672-778e-449d-8f28-2274d5b09f05    true    COMPLETE    2021-09-10T21:57:37Z    hello
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;By default, the &lt;code&gt;workflow status&lt;/code&gt; command will show the state of all workflows across all running contexts.&lt;/p&gt;
&lt;p&gt;To show only the status of workflow instances of a specific workflow you can use:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-shell&#34; data-lang=&#34;shell&#34;&gt;agc workflow status -n &amp;lt;workflow-name&amp;gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;To show only the status of workflows instances in a specific context you can use:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-shell&#34; data-lang=&#34;shell&#34;&gt;agc workflow status -c &amp;lt;context-name&amp;gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;If you want to check the status of a specific workflow you can do so by referencing the workflow execution by its run id:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-shell&#34; data-lang=&#34;shell&#34;&gt;agc workflow status -r &amp;lt;workflow-run-id&amp;gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;If you need to stop a running workflow instance, run:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-shell&#34; data-lang=&#34;shell&#34;&gt;agc workflow stop &amp;lt;workflow-run-id&amp;gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h3 id=&#34;using-workflow-inputs&#34;&gt;Using workflow inputs&lt;/h3&gt;
&lt;p&gt;You can provide runtime inputs to workflows at the command line. For example, the &lt;code&gt;demo-wdl-project&lt;/code&gt; has a workflow named &lt;code&gt;read&lt;/code&gt; that requires reading a data file.
The specification of read looks like:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;version 1.0
workflow ReadFile {
    input {
        File input_file
    }
    call read_file { input: input_file = input_file }
}

task read_file {
    input {
        File input_file
    }
    String content = read_string(input_file)

    command {
        echo &#39;~{content}&#39;
    }
    runtime {
        docker: &amp;quot;ubuntu:latest&amp;quot;
        memory: &amp;quot;4G&amp;quot;
    }

    output { String out = read_string( stdout() ) }
}
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;You can create an input file locally for this workflow:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-shell&#34; data-lang=&#34;shell&#34;&gt;mkdir inputs
&lt;span style=&#34;color:#204a87&#34;&gt;echo&lt;/span&gt; &lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#34;this is some data&amp;#34;&lt;/span&gt; &amp;gt; inputs/data.txt
cat &lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;lt;&amp;lt; EOF &amp;gt; inputs/read.inputs.json
&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;{&amp;#34;ReadFile.input_file&amp;#34;: &amp;#34;data.txt&amp;#34;}
&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;EOF&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Finally, you would submit the workflow with its corresponding inputs file with:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-shell&#34; data-lang=&#34;shell&#34;&gt;agc workflow run &lt;span style=&#34;color:#204a87&#34;&gt;read&lt;/span&gt; --inputsFile inputs/read.inputs.json
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Amazon Genomics CLI will scan the file provided to &lt;code&gt;--inputsFile&lt;/code&gt; for local paths, sync those files to S3, and rewrite the
inputs file in transit to point to the appropriate S3 locations. Paths in the &lt;code&gt;*.inputs.json&lt;/code&gt; file provided as &lt;code&gt;--inputsFile&lt;/code&gt;
are referenced relative to the &lt;code&gt;*.inputs.json&lt;/code&gt; file.&lt;/p&gt;
&lt;h3 id=&#34;accessing-workflow-results&#34;&gt;Accessing workflow results&lt;/h3&gt;
&lt;p&gt;Workflow results are written to an S3 bucket specified or created by Amazon Genomics CLI during account activation. See the section on account activation above for more details. You can list or retrieve the S3 URI for the bucket with:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-shell&#34; data-lang=&#34;shell&#34;&gt;&lt;span style=&#34;color:#000&#34;&gt;AGC_BUCKET&lt;/span&gt;&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;$(&lt;/span&gt;aws ssm get-parameter &lt;span style=&#34;color:#4e9a06&#34;&gt;\
&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&lt;/span&gt;    --name /agc/_common/bucket &lt;span style=&#34;color:#4e9a06&#34;&gt;\
&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&lt;/span&gt;    --query &lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#39;Parameter.Value&amp;#39;&lt;/span&gt; &lt;span style=&#34;color:#4e9a06&#34;&gt;\
&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&lt;/span&gt;    --output text&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;and then use &lt;code&gt;aws s3&lt;/code&gt; commands to explore and retrieve data from the bucket. For example, to list the bucket contents:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-shell&#34; data-lang=&#34;shell&#34;&gt;aws s3 ls &lt;span style=&#34;color:#000&#34;&gt;$AGC_BUCKET&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;You should see something like:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;PRE project/
PRE scripts/
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Data for multiple projects are kept in &lt;code&gt;project/&amp;lt;project-name&amp;gt;&lt;/code&gt; prefixes. Looking into one you should see:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;PRE cromwell-execution/
PRE workflow/
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;The &lt;code&gt;cromwell-execution&lt;/code&gt; prefix is specific to the engine Amazon Genomics CLI uses to run WDL workflows.
Workflow results will be in &lt;code&gt;cromwell-execution&lt;/code&gt; partitioned by workflow name, workflow run id, and task name. The &lt;code&gt;workflow&lt;/code&gt; prefix is where named workflows are cached when you run workflows definitions stored in your local environment.&lt;/p&gt;
&lt;p&gt;If a workflow declares workflow outputs then these can be obtained using &lt;code&gt;agc workflow output &amp;lt;run_id&amp;gt;&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;The following is example output from the &amp;ldquo;cram-to-bam&amp;rdquo; workflow&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;OUTPUT	id	aaba95e8-7512-48c3-9a61-1fd837ff6099
OUTPUT	outputs.CramToBamFlow.outputBai	s3://agc-123456789012-us-east-1/project/GATK/userid/mrschre4GqyMA/context/spotCtx/cromwell-execution/CramToBamFlow/aaba95e8-7512-48c3-9a61-1fd837ff6099/call-CramToBamTask/NA12878.bai
OUTPUT	outputs.CramToBamFlow.outputBam	s3://agc-123456789012-us-east-1/project/GATK/userid/mrschre4GqyMA/context/spotCtx/cromwell-execution/CramToBamFlow/aaba95e8-7512-48c3-9a61-1fd837ff6099/call-CramToBamTask/NA12878.bam
OUTPUT	outputs.CramToBamFlow.validation_report	s3://agc-123456789012-us-east-1/project/GATK/userid/mrschre4GqyMA/context/spotCtx/cromwell-execution/CramToBamFlow/aaba95e8-7512-48c3-9a61-1fd837ff6099/call-ValidateSamFile/NA12878.validation_report
&lt;/code&gt;&lt;/pre&gt;&lt;h3 id=&#34;accessing-workflow-logs&#34;&gt;Accessing workflow logs&lt;/h3&gt;
&lt;p&gt;You can get a summary of the log information for a workflow as follows:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-shell&#34; data-lang=&#34;shell&#34;&gt;agc logs workflow &amp;lt;workflow-name&amp;gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;This will return the logs for all runs of the workflow. If you just want the logs for a specific workflow run, you can use:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-shell&#34; data-lang=&#34;shell&#34;&gt;agc logs workflow &amp;lt;workflow-name&amp;gt; -r &amp;lt;workflow-instance-id&amp;gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;This will print out the &lt;code&gt;stdout&lt;/code&gt; generated by each workflow task.&lt;/p&gt;
&lt;p&gt;For the hello workflow above, this would look like:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;Fri, 10 Sep 2021 22:00:04 +0000    download: s3://agc-123456789012-us-east-2/scripts/3e129a27928c192b7804501aabdfc29e to tmp/tmp.BqCb2iaae/batch-file-temp
Fri, 10 Sep 2021 22:00:04 +0000    *** LOCALIZING INPUTS ***
Fri, 10 Sep 2021 22:00:05 +0000    download: s3://agc-123456789012-us-east-2/project/Demo/userid/xxxxxxxxJKP3z/context/myContext/cromwell-execution/hello_agc/66826672-778e-449d-8f28-2274d5b09f05/call-hello/script to agc-123456789012-us-east-2/project/Demo/userid/xxxxxxxxJKP3z/context/myContext/cromwell-execution/hello_agc/66826672-778e-449d-8f28-2274d5b09f05/call-hello/script
Fri, 10 Sep 2021 22:00:05 +0000    *** COMPLETED LOCALIZATION ***
Fri, 10 Sep 2021 22:00:05 +0000    Hello Amazon Genomics CLI!
Fri, 10 Sep 2021 22:00:05 +0000    *** DELOCALIZING OUTPUTS ***
Fri, 10 Sep 2021 22:00:05 +0000    upload: ./hello-rc.txt to s3://agc-123456789012-us-east-2/project/Demo/userid/xxxxxxxxJKP3z/context/myContext/cromwell-execution/hello_agc/66826672-778e-449d-8f28-2274d5b09f05/call-hello/hello-rc.txt
Fri, 10 Sep 2021 22:00:06 +0000    upload: ./hello-stderr.log to s3://agc-123456789012-us-east-2/project/Demo/userid/xxxxxxxxJKP3z/context/myContext/cromwell-execution/hello_agc/66826672-778e-449d-8f28-2274d5b09f05/call-hello/hello-stderr.log
Fri, 10 Sep 2021 22:00:06 +0000    upload: ./hello-stdout.log to s3://agc-123456789012-us-east-2/project/Demo/userid/xxxxxxxxJKP3z/context/myContext/cromwell-execution/hello_agc/66826672-778e-449d-8f28-2274d5b09f05/call-hello/hello-stdout.log
Fri, 10 Sep 2021 22:00:06 +0000    *** COMPLETED DELOCALIZATION ***
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;If your workflow fails, useful debug information is typically reported by the workflow engine logs. These are unique per context. To get those for a context named &lt;code&gt;myContext&lt;/code&gt;, you would run:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-shell&#34; data-lang=&#34;shell&#34;&gt;agc logs engine --context myContext
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;You should get something like:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;Fri, 10 Sep 2021 23:40:49 +0000    2021-09-10 23:40:49,421 cromwell-system-akka.dispatchers.api-dispatcher-175 INFO  - WDL (1.0) workflow 1473f547-85d8-4402-adfc-e741b7df69f2 submitted
Fri, 10 Sep 2021 23:40:52 +0000    2021-09-10 23:40:52,711 cromwell-system-akka.dispatchers.engine-dispatcher-30 INFO  - 1 new workflows fetched by cromid-2054603: 1473f547-85d8-4402-adfc-e741b7df69f2
Fri, 10 Sep 2021 23:40:52 +0000    2021-09-10 23:40:52,712 cromwell-system-akka.dispatchers.engine-dispatcher-14 INFO  - WorkflowManagerActor: Starting workflow UUID(1473f547-85d8-4402-adfc-e741b7df69f2)
Fri, 10 Sep 2021 23:40:52 +0000    2021-09-10 23:40:52,712 cromwell-system-akka.dispatchers.engine-dispatcher-14 INFO  - WorkflowManagerActor: Successfully started WorkflowActor-1473f547-85d8-4402-adfc-e741b7df69f2
Fri, 10 Sep 2021 23:40:52 +0000    2021-09-10 23:40:52,712 cromwell-system-akka.dispatchers.engine-dispatcher-14 INFO  - Retrieved 1 workflows from the WorkflowStoreActor
Fri, 10 Sep 2021 23:40:52 +0000    2021-09-10 23:40:52,716 cromwell-system-akka.dispatchers.engine-dispatcher-14 INFO  - MaterializeWorkflowDescriptorActor [UUID(1473f547)]: Parsing workflow as WDL 1.0
Fri, 10 Sep 2021 23:40:52 +0000    2021-09-10 23:40:52,721 cromwell-system-akka.dispatchers.engine-dispatcher-14 INFO  - MaterializeWorkflowDescriptorActor [UUID(1473f547)]: Call-to-Backend assignments: hello_agc.hello -&amp;gt; AWSBATCH
Fri, 10 Sep 2021 23:40:52 +0000    2021-09-10 23:40:52,722  WARN  - Unrecognized configuration key(s) for AwsBatch: auth, numCreateDefinitionAttempts, filesystems.s3.duplication-strategy, numSubmitAttempts, default-runtime-attributes.scriptBucketName
Fri, 10 Sep 2021 23:40:53 +0000    2021-09-10 23:40:53,741 cromwell-system-akka.dispatchers.engine-dispatcher-14 INFO  - WorkflowExecutionActor-1473f547-85d8-4402-adfc-e741b7df69f2 [UUID(1473f547)]: Starting hello_agc.hello
Fri, 10 Sep 2021 23:40:54 +0000    2021-09-10 23:40:54,030 cromwell-system-akka.dispatchers.engine-dispatcher-14 INFO  - Assigned new job execution tokens to the following groups: 1473f547: 1
Fri, 10 Sep 2021 23:40:55 +0000    2021-09-10 23:40:55,501 cromwell-system-akka.dispatchers.engine-dispatcher-4 INFO  - 1473f547-85d8-4402-adfc-e741b7df69f2-EngineJobExecutionActor-hello_agc.hello:NA:1 [UUID(1473f547)]: Call cache hit process had 0 total hit failures before completing successfully
Fri, 10 Sep 2021 23:40:56 +0000    2021-09-10 23:40:56,842 cromwell-system-akka.dispatchers.engine-dispatcher-31 INFO  - WorkflowExecutionActor-1473f547-85d8-4402-adfc-e741b7df69f2 [UUID(1473f547)]: Job results retrieved (CallCached): &#39;hello_agc.hello&#39; (scatter index: None, attempt 1)
Fri, 10 Sep 2021 23:40:57 +0000    2021-09-10 23:40:57,820 cromwell-system-akka.dispatchers.engine-dispatcher-4 INFO  - WorkflowExecutionActor-1473f547-85d8-4402-adfc-e741b7df69f2 [UUID(1473f547)]: Workflow hello_agc complete. Final Outputs:
Fri, 10 Sep 2021 23:40:57 +0000    {
Fri, 10 Sep 2021 23:40:57 +0000      &amp;quot;hello_agc.hello.out&amp;quot;: &amp;quot;Hello Amazon Genomics CLI!&amp;quot;
Fri, 10 Sep 2021 23:40:57 +0000    }
Fri, 10 Sep 2021 23:40:59 +0000    2021-09-10 23:40:59,826 cromwell-system-akka.dispatchers.engine-dispatcher-14 INFO  - WorkflowManagerActor: Workflow actor for 1473f547-85d8-4402-adfc-e741b7df69f2 completed with status &#39;Succeeded&#39;. The workflow will be removed from the workflow store.
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;You can filter logs with the &lt;code&gt;--filter&lt;/code&gt; flag. The filter syntax adheres to &lt;a href=&#34;https://docs.aws.amazon.com/AmazonCloudWatch/latest/logs/FilterAndPatternSyntax.html&#34;&gt;CloudWatch&amp;rsquo;s filter and pattern syntax&lt;/a&gt;.
For example, the following will give you all error logs from the workflow engine:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-shell&#34; data-lang=&#34;shell&#34;&gt;agc logs engine --context myContext --filter ERROR
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h3 id=&#34;additional-workflow-examples&#34;&gt;Additional workflow examples&lt;/h3&gt;
&lt;p&gt;The Amazon Genomics CLI installation also includes a set of typical genomics workflows for raw data processing, germline variant discovery, and joint genotyping based on &lt;a href=&#34;https://gatk.broadinstitute.org/hc/en-us&#34;&gt;GATK Best Practices&lt;/a&gt;, developed by the &lt;a href=&#34;https://www.broadinstitute.org/&#34;&gt;Broad Institute&lt;/a&gt;. More information on how these workflows work is available in the &lt;a href=&#34;https://github.com/gatk-workflows&#34;&gt;GATK Workflows Github repository&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;You can find these in:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-shell&#34; data-lang=&#34;shell&#34;&gt;~/agc/examples/gatk-best-practices-project
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;These workflows come pre-packaged with &lt;code&gt;MANIFEST.json&lt;/code&gt; files that specify example input data available publicly in the &lt;a href=&#34;https://registry.opendata.aws/&#34;&gt;AWS Registry of Open Data&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Note: these workflows take between 5 min to ~3hrs to complete.&lt;/p&gt;
&lt;h2 id=&#34;cleanup&#34;&gt;Cleanup&lt;/h2&gt;
&lt;p&gt;When you are done running workflows, it is recommended you stop all cloud resources to save costs.&lt;/p&gt;
&lt;p&gt;Stop a context with:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-shell&#34; data-lang=&#34;shell&#34;&gt;agc context destroy &amp;lt;context-name&amp;gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;This will destroy all compute resources in a context, but retain any data in S3. If you want to destroy all your running contexts at once, you can use:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-shell&#34; data-lang=&#34;shell&#34;&gt;agc context destroy --all
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Note, you will not be able to destroy a context that has a running workflow. Workflows will need to complete on their own or stopped before you can destroy the context.&lt;/p&gt;
&lt;p&gt;If you want stop using Amazon Genomics CLI in your AWS account entirely, you need to deactivate it:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-shell&#34; data-lang=&#34;shell&#34;&gt;agc account deactivate
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;This will remove Amazon Genomics CLI‚Äôs core infrastructure. If Amazon Genomics CLI created a VPC as part of the &lt;code&gt;activate&lt;/code&gt; process, it will be &lt;strong&gt;removed&lt;/strong&gt;. If Amazon Genomics CLI created an S3 bucket for you, it will be &lt;strong&gt;retained&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;To uninstall Amazon Genomics CLI from your local machine, run the following command:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-shell&#34; data-lang=&#34;shell&#34;&gt;./agc/uninstall.sh
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;blockquote&gt;
&lt;p&gt;Note uninstalling the CLI will not remove any resources or persistent data from your AWS account.&lt;/p&gt;
&lt;/blockquote&gt;

      </description>
    </item>
    
    <item>
      <title>Docs: Prerequisites</title>
      <link>https://aws.github.io/amazon-genomics-cli/docs/getting-started/prerequisites/</link>
      <pubDate>Tue, 07 Sep 2021 13:42:19 -0400</pubDate>
      
      <guid>https://aws.github.io/amazon-genomics-cli/docs/getting-started/prerequisites/</guid>
      <description>
        
        
        &lt;p&gt;To run Amazon Genomics CLI the following prerequisites must be met:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;A computer with one of the following operating systems:
&lt;ul&gt;
&lt;li&gt;macOS 10.14+&lt;/li&gt;
&lt;li&gt;Amazon Linux 2&lt;/li&gt;
&lt;li&gt;Ubuntu 20.04&lt;/li&gt;
&lt;li&gt;Windows 10 with a Windows subsystem running Ubuntu which runs the commands&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Internet access&lt;/li&gt;
&lt;li&gt;An AWS Account&lt;/li&gt;
&lt;li&gt;An AWS role with sufficient access. To generate the minimum required policies for admins and users, please follow the instructions &lt;a href=&#34;https://aws.github.io/amazon-genomics-cli/amazon-genomics-cli/docs/best-practices/iam-permissions/&#34;&gt;here&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Running Amazon Genomics CLI on Windows has not been tested, but it should run in WSL 2 with Ubuntu 20.04&lt;/p&gt;
&lt;h2 id=&#34;prerequisite-installation&#34;&gt;Prerequisite installation&lt;/h2&gt;
&lt;h3 id=&#34;ubuntu-2004&#34;&gt;Ubuntu 20.04&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Install node.js&lt;/li&gt;
&lt;/ul&gt;
&lt;pre&gt;&lt;code&gt;curl -fsSL https://deb.nodesource.com/setup_15.x | sudo -E bash -
sudo apt-get install -y nodejs
&lt;/code&gt;&lt;/pre&gt;&lt;ul&gt;
&lt;li&gt;Install and configure AWS CLI&lt;/li&gt;
&lt;/ul&gt;
&lt;pre&gt;&lt;code&gt;sudo apt install awscli
aws configure
# ... set access key ID, secret access key, and region
&lt;/code&gt;&lt;/pre&gt;&lt;h3 id=&#34;amazon-linux-2-eg-on-an-ec2-instance&#34;&gt;Amazon Linux 2 (e.g. on an EC2 instance)&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Install node&lt;/li&gt;
&lt;/ul&gt;
&lt;pre&gt;&lt;code&gt;curl -sL https://rpm.nodesource.com/setup_16.x | sudo -E bash -
sudo yum install -y nodejs
&lt;/code&gt;&lt;/pre&gt;&lt;ul&gt;
&lt;li&gt;If you have not already done so, configure your AWS credentials and default region&lt;/li&gt;
&lt;/ul&gt;
&lt;pre&gt;&lt;code&gt;aws configure
&lt;/code&gt;&lt;/pre&gt;&lt;h3 id=&#34;macos&#34;&gt;MacOS&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Install &lt;a href=&#34;https://brew.sh/&#34;&gt;Homebrew&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;pre&gt;&lt;code&gt;/bin/bash -c &amp;quot;$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/HEAD/install.sh)&amp;quot;
&lt;/code&gt;&lt;/pre&gt;&lt;ul&gt;
&lt;li&gt;Install node&lt;/li&gt;
&lt;/ul&gt;
&lt;pre&gt;&lt;code&gt;brew install node
&lt;/code&gt;&lt;/pre&gt;&lt;ul&gt;
&lt;li&gt;Install and configure AWS CLI&lt;/li&gt;
&lt;/ul&gt;
&lt;pre&gt;&lt;code&gt;brew install awscli
aws configure
# ... set access key ID, secret access key, and region
&lt;/code&gt;&lt;/pre&gt;
      </description>
    </item>
    
    <item>
      <title>Docs: Projects</title>
      <link>https://aws.github.io/amazon-genomics-cli/docs/concepts/projects/</link>
      <pubDate>Tue, 31 Aug 2021 17:27:06 -0400</pubDate>
      
      <guid>https://aws.github.io/amazon-genomics-cli/docs/concepts/projects/</guid>
      <description>
        
        
        &lt;p&gt;An Amazon Genomics CLI project defines the &lt;a href=&#34;https://aws.github.io/amazon-genomics-cli/amazon-genomics-cli/docs/concepts/projects/&#34;&gt;projects&lt;/a&gt;, &lt;a href=&#34;https://aws.github.io/amazon-genomics-cli/amazon-genomics-cli/docs/concepts/contexts/&#34;&gt;contexts&lt;/a&gt;, &lt;a href=&#34;https://aws.github.io/amazon-genomics-cli/amazon-genomics-cli/docs/concepts/data/&#34;&gt;data&lt;/a&gt; and &lt;a href=&#34;https://aws.github.io/amazon-genomics-cli/amazon-genomics-cli/docs/concepts/workflows/&#34;&gt;workflows&lt;/a&gt; that make up a genomics analysis. Each project is defined
in a project file named &lt;code&gt;agc-project.yaml&lt;/code&gt;.&lt;/p&gt;
&lt;h2 id=&#34;project-file-location&#34;&gt;Project File Location&lt;/h2&gt;
&lt;p&gt;To find the project definition, Amazon Genomics CLI will look for a file named &lt;code&gt;agc-project.yaml&lt;/code&gt; in the current working directory. If
the file is not found, Amazon Genomics CLI will traverse up the file hierarchy until the file is found or until the root of the file
system is reached. If no project definition can be found an error will be reported. All Amazon Genomics CLI commands operate on the project identified by the above process.&lt;/p&gt;
&lt;p&gt;Consider the example directory structure below:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;/
‚îú‚îÄ‚îÄ baa/
‚îÇ   ‚îú‚îÄ‚îÄ a/
‚îÇ   ‚îî‚îÄ‚îÄ agc-project.yaml
‚îú‚îÄ‚îÄ foo/
‚îî‚îÄ‚îÄ foz/
    ‚îî‚îÄ‚îÄ a/
        ‚îú‚îÄ‚îÄ agc-project.yaml
        ‚îî‚îÄ‚îÄ b/
            ‚îî‚îÄ‚îÄ c/
                ‚îî‚îÄ‚îÄ agc-project.yaml
&lt;/code&gt;&lt;/pre&gt;&lt;ul&gt;
&lt;li&gt;If the current working directory is &lt;code&gt;/baa&lt;/code&gt; or &lt;code&gt;/baa/a&lt;/code&gt; then &lt;code&gt;/baa/agc-project.yaml&lt;/code&gt; will be used for definitions,&lt;/li&gt;
&lt;li&gt;If the current working directory is &lt;code&gt;/foo&lt;/code&gt; an error will be reported as no project file is found before the root,&lt;/li&gt;
&lt;li&gt;If the current working directory is &lt;code&gt;/foz&lt;/code&gt; an error will be reported as no project file is found before the root,&lt;/li&gt;
&lt;li&gt;If the current working directory is &lt;code&gt;/foz/a&lt;/code&gt; or &lt;code&gt;/foz/a/b&lt;/code&gt; then &lt;code&gt;/foz/a/agc-project.yaml&lt;/code&gt; will be used for definitions.&lt;/li&gt;
&lt;li&gt;If the current working directory is &lt;code&gt;/foz/a/b/c&lt;/code&gt; then &lt;code&gt;/foz/a/b/c/agc-project.yaml&lt;/code&gt; will be used for definitions.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;relative-locations&#34;&gt;Relative Locations&lt;/h3&gt;
&lt;p&gt;The location of resources declared in a project file are resolved relative to the location of the project file &lt;em&gt;unless&lt;/em&gt;
they are declared using an absolute path. If the project file in &lt;code&gt;/baa&lt;/code&gt; declared that
there was a workflow definition in &lt;code&gt;a/b/&lt;/code&gt; then Amazon Genomics CLI will search for that definition in &lt;code&gt;/baa/a/b/&lt;/code&gt;.&lt;/p&gt;
&lt;h2 id=&#34;project-file-structure&#34;&gt;Project File Structure&lt;/h2&gt;
&lt;p&gt;A minimal project file can be generated using the &lt;code&gt;agc project init myProject --workflow-type nextflow&lt;/code&gt;. Using &lt;code&gt;myProject&lt;/code&gt; as a project name and workflow type &lt;code&gt;nextflow&lt;/code&gt; will result in the following:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-yaml&#34; data-lang=&#34;yaml&#34;&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;name&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;myProject&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;schemaVersion&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#0000cf;font-weight:bold&#34;&gt;1&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;contexts&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;  &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;ctx1&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;    &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;engines&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;      &lt;/span&gt;- &lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;type&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;nextflow&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;        &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;engine&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;nextflow&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;This is fully usable project called &amp;ldquo;myProject&amp;rdquo; with a single context named &amp;ldquo;ctx1&amp;rdquo;. At this point &amp;ldquo;ctx1&amp;rdquo; can be &lt;a href=&#34;https://aws.github.io/amazon-genomics-cli/amazon-genomics-cli/docs/concepts/contexts/#deploy&#34;&gt;deployed&lt;/a&gt;
however, there are currently no workflows defined.&lt;/p&gt;
&lt;h3 id=&#34;name&#34;&gt;&lt;code&gt;name&lt;/code&gt;&lt;/h3&gt;
&lt;p&gt;A string that identifies the project&lt;/p&gt;
&lt;h3 id=&#34;schemaversion&#34;&gt;&lt;code&gt;schemaVersion&lt;/code&gt;&lt;/h3&gt;
&lt;p&gt;An integer defining the schema version. Version numbers will be incremented when changes are made to the project schema
that are not backward compatible.&lt;/p&gt;
&lt;h3 id=&#34;contexts&#34;&gt;&lt;code&gt;contexts&lt;/code&gt;&lt;/h3&gt;
&lt;p&gt;A map of context names to context definitions. Each context in the project must have a unique name. The &lt;a href=&#34;https://aws.github.io/amazon-genomics-cli/amazon-genomics-cli/docs/concepts/contexts/&#34;&gt;contexts&lt;/a&gt;
documentation provides more details.&lt;/p&gt;
&lt;h3 id=&#34;workflows&#34;&gt;&lt;code&gt;workflows&lt;/code&gt;&lt;/h3&gt;
&lt;p&gt;A map of workflow names to workflow definitions. Workflow names must be unique in a project. The &lt;a href=&#34;https://aws.github.io/amazon-genomics-cli/amazon-genomics-cli/docs/concepts/workflows/&#34;&gt;workflows&lt;/a&gt;
documentation provides more details.&lt;/p&gt;
&lt;h3 id=&#34;data&#34;&gt;&lt;code&gt;data&lt;/code&gt;&lt;/h3&gt;
&lt;p&gt;An array of data sources that the contexts of the project have access to. For example:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-yaml&#34; data-lang=&#34;yaml&#34;&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;data&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;  &lt;/span&gt;- &lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;location&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;s3://gatk-test-data&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;    &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;readOnly&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;true&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;  &lt;/span&gt;- &lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;location&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;s3://broad-references&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;    &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;readOnly&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;true&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;  &lt;/span&gt;- &lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;location&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;s3://1000genomes-dragen-3.7.6&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;    &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;readOnly&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;true&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;You can use S3 prefixes to be more restrictive about access to data. For example, if you want to allow access to the
&lt;code&gt;foo&lt;/code&gt; folder of &lt;code&gt;my-bucket&lt;/code&gt; and it&amp;rsquo;s sub-folders you would declare the location as:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-yaml&#34; data-lang=&#34;yaml&#34;&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;data&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;  &lt;/span&gt;- &lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;location&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;s3://my-bucket/foo/*&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;You can also grant access to a specific object (only) by providing the full path of the object. For example:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-yaml&#34; data-lang=&#34;yaml&#34;&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;data&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;  &lt;/span&gt;- &lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;location&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;s3://my-bucket/foo/object&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h2 id=&#34;commands&#34;&gt;Commands&lt;/h2&gt;
&lt;p&gt;A full reference of project commands are available &lt;a href=&#34;https://aws.github.io/amazon-genomics-cli/amazon-genomics-cli/docs/reference/agc_project/&#34;&gt;here&lt;/a&gt;&lt;/p&gt;
&lt;h3 id=&#34;init&#34;&gt;&lt;code&gt;init&lt;/code&gt;&lt;/h3&gt;
&lt;p&gt;The &lt;code&gt;agc project init &amp;lt;project-name&amp;gt; --workflow-type &amp;lt;worklow-type&amp;gt;&lt;/code&gt; command can be used to initialize a minimal &lt;code&gt;agc-project.yaml&lt;/code&gt; file in the current
directory. Alternatively project yaml files can be created with any text editor.&lt;/p&gt;
&lt;h3 id=&#34;describe&#34;&gt;&lt;code&gt;describe&lt;/code&gt;&lt;/h3&gt;
&lt;p&gt;The &lt;code&gt;agc project describe &amp;lt;project-name&amp;gt;&lt;/code&gt; command will provide basic metadata about the &amp;lsquo;local&amp;rsquo; project file. See
&lt;a href=&#34;#project-file-location&#34;&gt;above&lt;/a&gt; for details on how project files are located.&lt;/p&gt;
&lt;h3 id=&#34;validate&#34;&gt;&lt;code&gt;validate&lt;/code&gt;&lt;/h3&gt;
&lt;p&gt;Using &lt;code&gt;agc project validate&lt;/code&gt; you can quickly identify any syntax errors in your local project file.&lt;/p&gt;
&lt;h2 id=&#34;versioning-and-sharing&#34;&gt;Versioning and Sharing&lt;/h2&gt;
&lt;p&gt;We recommend placing a project under source version control using a tool like &lt;a href=&#34;https://git-scm.com&#34;&gt;Git&lt;/a&gt;. The folder containing the &lt;code&gt;agc-project.yaml&lt;/code&gt;
file is a natural location for the root of a Git repository. Workflows relating to the project would naturally be located
in sub-folders of the same repository allowing those to be versioned as well. Alternatively, more advanced Git users may
consider storing workflows as a Git &lt;a href=&#34;https://git-scm.com/book/en/v2/Git-Tools-Submodules&#34;&gt;sub-module&lt;/a&gt; allowing them to
be independent of the project and reused among projects.&lt;/p&gt;
&lt;p&gt;Projects and associated workflows can then be shared by &amp;ldquo;pushing&amp;rdquo; the project&amp;rsquo;s Git repository to a website such
as &lt;a href=&#34;https://github.com&#34;&gt;GitHub&lt;/a&gt;, &lt;a href=&#34;https://gitlab.com&#34;&gt;GitLab&lt;/a&gt;, or &lt;a href=&#34;https://bitbucket.com&#34;&gt;BitBucket&lt;/a&gt; or hosted on a
private Git Server like &lt;a href=&#34;https://docs.aws.amazon.com/codecommit/latest/userguide/index.html&#34;&gt;AWS Code Commit&lt;/a&gt;. To facilitate sharing you should
ensure that any file paths in your definitions are relative to the project and not absolute. You will also need to make
sure that data locations are appropriately shared.&lt;/p&gt;
&lt;h2 id=&#34;costs&#34;&gt;Costs&lt;/h2&gt;
&lt;p&gt;A project itself doesn&amp;rsquo;t have infrastructure. It is not deployed and therefore has no direct costs. If the contexts defined
by an infrastructure are deployed or the workflows run then those &lt;em&gt;will&lt;/em&gt; incur costs.&lt;/p&gt;
&lt;h3 id=&#34;tags&#34;&gt;Tags&lt;/h3&gt;
&lt;p&gt;The project &lt;code&gt;name&lt;/code&gt; will be &lt;a href=&#34;https://aws.github.io/amazon-genomics-cli/amazon-genomics-cli/docs/concepts/namespaces/#tags&#34;&gt;tagged&lt;/a&gt;
on any deployed contexts or workflows defined in this project allowing costs to be aggregated to the project level.&lt;/p&gt;
&lt;h2 id=&#34;technical-details&#34;&gt;Technical Details&lt;/h2&gt;
&lt;p&gt;A project is purely a &lt;a href=&#34;https://en.wikipedia.org/wiki/YAML&#34;&gt;YAML&lt;/a&gt; definition. The values in the &lt;code&gt;agc-project.yaml&lt;/code&gt; file are used by CDK when Amazon Genomics CLI deploys contexts
and when Amazon Genomics CLI runs workflows. The project itself has no direct infrastructure. The project &lt;code&gt;name&lt;/code&gt; is used to help namespace
context infrastructure.&lt;/p&gt;

      </description>
    </item>
    
    <item>
      <title>Docs: Toil</title>
      <link>https://aws.github.io/amazon-genomics-cli/docs/workflow-engines/toil/</link>
      <pubDate>Tue, 26 Apr 2022 15:34:00 -0400</pubDate>
      
      <guid>https://aws.github.io/amazon-genomics-cli/docs/workflow-engines/toil/</guid>
      <description>
        
        
        &lt;h2 id=&#34;description&#34;&gt;Description&lt;/h2&gt;
&lt;p&gt;&lt;a href=&#34;http://toil.ucsc-cgl.org/&#34;&gt;Toil&lt;/a&gt; is a workflow engine developed by the
&lt;a href=&#34;https://cglgenomics.ucsc.edu/&#34;&gt;Computational Genomics Lab&lt;/a&gt; at the
&lt;a href=&#34;https://genomics.ucsc.edu/&#34;&gt;UC Santa Cruz Genomics Institute&lt;/a&gt;. In Amazon Genomics
CLI, Toil is an engine that can be deployed in a
&lt;a href=&#34;https://aws.github.io/amazon-genomics-cli/amazon-genomics-cli/docs/concepts/contexts/&#34;&gt;context&lt;/a&gt; as an
&lt;a href=&#34;https://aws.github.io/amazon-genomics-cli/amazon-genomics-cli/docs/concepts/engines/&#34;&gt;engine&lt;/a&gt; to run workflows written in the
&lt;a href=&#34;https://www.commonwl.org/&#34;&gt;Common Workflow Language&lt;/a&gt; (CWL) standard, version
&lt;a href=&#34;https://www.commonwl.org/v1.0/&#34;&gt;v1.0&lt;/a&gt;, &lt;a href=&#34;https://www.commonwl.org/v1.1/&#34;&gt;v1.1&lt;/a&gt;,
and &lt;a href=&#34;https://www.commonwl.org/v1.2/&#34;&gt;v1.2&lt;/a&gt; (or mixed versions).&lt;/p&gt;
&lt;p&gt;Toil is an open source project distributed by UC Santa Cruz under the &lt;a href=&#34;https://github.com/DataBiosphere/toil/blob/master/LICENSE&#34;&gt;Apache 2
license&lt;/a&gt; and
available on
&lt;a href=&#34;https://github.com/DataBiosphere/toil&#34;&gt;GitHub&lt;/a&gt;.&lt;/p&gt;
&lt;h2 id=&#34;architecture&#34;&gt;Architecture&lt;/h2&gt;
&lt;p&gt;There are two components of a Toil engine as deployed in an Amazon Genomics
CLI context:&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;ToilContextArch.png&#34; alt=&#34;Image of infrastructure deployed in a Toil context&#34; title=&#34;Toil Context Architecture&#34;&gt;&lt;/p&gt;
&lt;h3 id=&#34;toil-server&#34;&gt;Toil Server&lt;/h3&gt;
&lt;p&gt;The Toil engine is run in &amp;ldquo;server mode&amp;rdquo; as a container service in ECS. The
engine can run multiple workflows asynchronously. Workflow tasks are run in an
elastic &lt;a href=&#34;#compute-environment&#34;&gt;compute environment&lt;/a&gt; and monitored by Toil.
Amazon Genomics CLI communicates with the Toil engine via a GA4GH
&lt;a href=&#34;https://github.com/ga4gh/workflow-execution-service-schemas&#34;&gt;WES&lt;/a&gt; REST service
which the server offers, available via API Gateway.&lt;/p&gt;
&lt;h3 id=&#34;task-compute-environment&#34;&gt;Task Compute Environment&lt;/h3&gt;
&lt;p&gt;Workflow tasks are submitted by Toil to an AWS Batch queue and run in
Toil-provided containers using an AWS Compute Environment. Tasks which use the
&lt;a href=&#34;https://www.commonwl.org/user_guide/07-containers/index.html&#34;&gt;CWL &lt;code&gt;DockerRequirement&lt;/code&gt;&lt;/a&gt;
will additionally be run in sibling containers on the host Docker daemon. AWS
Batch coordinates the elastic provisioning of EC2 instances (container hosts)
based on the available work in the queue. Batch will place containers on
container hosts as space allows.&lt;/p&gt;
&lt;h4 id=&#34;disk-expansion&#34;&gt;Disk Expansion&lt;/h4&gt;
&lt;p&gt;Container hosts in the Batch compute environment use EBS volumes as local
scratch space. As an EBS volume approaches a capacity threshold, new EBS
volumes will be attached and merged into the file system. These volumes are
destroyed when AWS Batch terminates the container host. CWL disk space
requirements are ignored by Toil when running against AWS Batch.&lt;/p&gt;
&lt;p&gt;This setup means that workflows that succeed on AGC may fail on other CWL
runners (because they do not request enough disk space) and workflows that
succeed on other CWL runners may fail on AGC (because they allocate disk space
faster than the expansion process can react).&lt;/p&gt;

      </description>
    </item>
    
    <item>
      <title>Docs: Cromwell</title>
      <link>https://aws.github.io/amazon-genomics-cli/docs/workflow-engines/cromwell/</link>
      <pubDate>Fri, 01 Oct 2021 17:27:21 -0400</pubDate>
      
      <guid>https://aws.github.io/amazon-genomics-cli/docs/workflow-engines/cromwell/</guid>
      <description>
        
        
        &lt;h2 id=&#34;description&#34;&gt;Description&lt;/h2&gt;
&lt;p&gt;&lt;a href=&#34;https://cromwell.readthedocs.io/en/stable/&#34;&gt;Cromwell&lt;/a&gt; is a workflow engine developed by the &lt;a href=&#34;https://www.broadinstitute.org/&#34;&gt;Broad Institute&lt;/a&gt;.
In Amazon Genomics CLI, Cromwell is an engine that can be
deployed in a &lt;a href=&#34;https://aws.github.io/amazon-genomics-cli/amazon-genomics-cli/docs/concepts/contexts/&#34;&gt;context&lt;/a&gt; as an &lt;a href=&#34;https://aws.github.io/amazon-genomics-cli/amazon-genomics-cli/docs/concepts/engines/&#34;&gt;engine&lt;/a&gt;
to run workflows based on the &lt;a href=&#34;https://openwdl.org/&#34;&gt;WDL&lt;/a&gt; specification.&lt;/p&gt;
&lt;p&gt;Cromwell is an open source project distributed by the Broad Institute under the &lt;a href=&#34;https://github.com/broadinstitute/cromwell/blob/develop/LICENSE-ASL-2.0&#34;&gt;Apache 2 license&lt;/a&gt; and available on &lt;a href=&#34;https://github.com/broadinstitute/cromwell&#34;&gt;GitHub&lt;/a&gt;.&lt;/p&gt;
&lt;h3 id=&#34;customizations&#34;&gt;Customizations&lt;/h3&gt;
&lt;p&gt;Some minor customizations where made to the AWS Backend adapter for Cromwell to facilitate improved scalability and cross
region S3 bucket access when deployed with Amazon Genomics CLI. The fork containing these customizations is available &lt;a href=&#34;https://github.com/markjschreiber/cromwell&#34;&gt;here&lt;/a&gt;
and we are working to contribute these back to the main code base.&lt;/p&gt;
&lt;h2 id=&#34;architecture&#34;&gt;Architecture&lt;/h2&gt;
&lt;p&gt;There are four components of a Cromwell engine as deployed in an Amazon Genomics CLI context.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;CromwellContextArch.png&#34; alt=&#34;Image of infrastructure deployed in a Cromwell context&#34; title=&#34;Cromwell Context Architecture&#34;&gt;&lt;/p&gt;
&lt;h3 id=&#34;wes-adapter&#34;&gt;WES Adapter&lt;/h3&gt;
&lt;p&gt;Amazon Genomics CLI communicates with the Cromwell engine via a GA4GH &lt;a href=&#34;https://github.com/ga4gh/workflow-execution-service-schemas&#34;&gt;WES&lt;/a&gt; REST service. The WES Adapter implements
the WES standard and translates WES calls into calls to the &lt;a href=&#34;https://cromwell.readthedocs.io/en/stable/api/RESTAPI/&#34;&gt;Cromwell REST API&lt;/a&gt;. The adapter runs as an Amazon ECS service
available via API Gateway.&lt;/p&gt;
&lt;h3 id=&#34;cromwell-server&#34;&gt;Cromwell Server&lt;/h3&gt;
&lt;p&gt;The Cromwell engine is run in &amp;ldquo;server mode&amp;rdquo; as a container service in ECS and receives instructions from the WES Adapter. The
engine can run multiple workflows asynchronously. Workflow tasks are run in an elastic &lt;a href=&#34;#compute-environment&#34;&gt;compute environment&lt;/a&gt; and
monitored by Cromwell.&lt;/p&gt;
&lt;h3 id=&#34;session-cache&#34;&gt;Session Cache&lt;/h3&gt;
&lt;p&gt;Cromwell can use workflow run metadata to perform call caching. When deployed by Amazon Genomics CLI call caching is enabled
by default. Metadata is stored by an embedded HSQL DB with file storage in an attached EFS volume. The EFS volume
exists for the lifetime of the context the engine is deployed in so re-runs of workflows within the lifetime can benefit
from call caching.&lt;/p&gt;
&lt;h3 id=&#34;task-compute-environment&#34;&gt;Task Compute Environment&lt;/h3&gt;
&lt;p&gt;Workflow tasks are submitted by Cromwell to an AWS Batch queue and run in containers using an AWS Compute Environment.
Container characteristics are defined by the &lt;code&gt;runtime&lt;/code&gt;. AWS Batch coordinates the elastic provisioning of EC2 instances (container hosts)
based on the available work in the queue. Batch will place containers on container hosts as space allows.&lt;/p&gt;
&lt;h4 id=&#34;fetch-and-run-strategy&#34;&gt;Fetch and Run Strategy&lt;/h4&gt;
&lt;p&gt;Execution of workflow tasks uses a &amp;ldquo;Fetch and Run&amp;rdquo; strategy. The commands specified in the &lt;code&gt;command&lt;/code&gt; section of the WDL task
are written as a file to S3 and &amp;ldquo;fetched&amp;rdquo; into the container and run.
The script is &amp;ldquo;decorated&amp;rdquo; with instructions to fetch any &lt;code&gt;File&lt;/code&gt; inputs from S3 and to write any &lt;code&gt;File&lt;/code&gt; outputs back to S3.&lt;/p&gt;
&lt;h4 id=&#34;disk-expansion&#34;&gt;Disk Expansion&lt;/h4&gt;
&lt;p&gt;Container hosts in the Batch compute environment use EBS volumes as local scratch space. As an EBS volume approaches a
capacity threshold, new EBS volumes will be attached and merged into the file system. These volumes are destroyed when
AWS Batch terminates the container host. For this reason it is not necessary to specify disk requirements for the task
&lt;code&gt;runtime&lt;/code&gt; and these WDL directives will be ignored.&lt;/p&gt;
&lt;h4 id=&#34;aws-batch-retries&#34;&gt;AWS Batch Retries&lt;/h4&gt;
&lt;p&gt;The Cromwell AWS Batch backend supports AWS Batch&amp;rsquo;s task &lt;a href=&#34;https://docs.aws.amazon.com/batch/latest/APIReference/API_RetryStrategy.html&#34;&gt;retry&lt;/a&gt; option allowing failed tasks to attempt to run again. This
can be useful for adding resilience to a workflow from sporadic infrastructure failures. It is especially useful when using
an Amazon Genomics CLI &amp;ldquo;spot&amp;rdquo; context as spot instances can be terminated with minimal warning. To enable retries, add
the following option to your &lt;code&gt;runtime&lt;/code&gt; section of a task:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;runtime {
    ...
    awsBatchRetryAttempts: &amp;lt;int&amp;gt;
    ...
}
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;where &lt;code&gt;&amp;lt;int&amp;gt;&lt;/code&gt; is an integer specifying the number of retries up to a maximum of &lt;code&gt;10&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;Although similar to the WDL &lt;code&gt;preemptible&lt;/code&gt; option, &lt;code&gt;awsBatchRetryAttempts&lt;/code&gt; has differences in how retries are implemented. Notably,
the implementation falls back on the AWS Batch retry strategy and will retry a task that fails for &lt;strong&gt;any&lt;/strong&gt; reason; whereas the &lt;code&gt;preemptible&lt;/code&gt;
option is more specific to failures caused by preemption. At this time the &lt;code&gt;preemptible&lt;/code&gt; option is not supported by Amazon Genomics CLI
and is ignored.&lt;/p&gt;

      </description>
    </item>
    
    <item>
      <title>Docs: Installation</title>
      <link>https://aws.github.io/amazon-genomics-cli/docs/getting-started/installation/</link>
      <pubDate>Tue, 07 Sep 2021 13:42:31 -0400</pubDate>
      
      <guid>https://aws.github.io/amazon-genomics-cli/docs/getting-started/installation/</guid>
      <description>
        
        
        &lt;h2 id=&#34;download-and-install-amazon-genomics-cli&#34;&gt;Download and install Amazon Genomics CLI&lt;/h2&gt;
&lt;p&gt;Download the Amazon Genomics CLI zip, unzip its contents, and run the &lt;code&gt;install.sh&lt;/code&gt; script:&lt;/p&gt;
&lt;p&gt;To download a specific release, see &lt;a href=&#34;https://github.com/aws/amazon-genomics-cli/releases&#34;&gt;releases page&lt;/a&gt; of our Github repo.&lt;/p&gt;
&lt;p&gt;To download the latest release navigate to &lt;a href=&#34;https://github.com/aws/amazon-genomics-cli/releases/&#34;&gt;https://github.com/aws/amazon-genomics-cli/releases/&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Once you have downloaded a release, type the following to install:&lt;/p&gt;
&lt;p&gt;The latest nightly build can be accessed here: &lt;code&gt;s3://healthai-public-assets-us-east-1/amazon-genomics-cli/nightly-build/amazon-genomics-cli.zip&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;You can download the nightly by running the following:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-shell&#34; data-lang=&#34;shell&#34;&gt;aws s3api get-object --bucket healthai-public-assets-us-east-1 --key amazon-genomics-cli/nightly-build/amazon-genomics-cli.zip amazon-genomics-cli.zip
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-shell&#34; data-lang=&#34;shell&#34;&gt;unzip amazon-genomics-cli-&amp;lt;version&amp;gt;.zip
&lt;span style=&#34;color:#204a87&#34;&gt;cd&lt;/span&gt; amazon-genomics-cli/ 
./install.sh
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;This will place the &lt;code&gt;agc&lt;/code&gt; command in &lt;code&gt;$HOME/bin&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;The Amazon Genomics CLI is a statically compiled Go binary. It should run in your environment natively without any additional setup. Test the CLI with:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ agc --help

üß¨ Launch and manage genomics workloads on AWS.

Commands
  Getting Started üå±
    account     Commands for AWS account setup.
                Install or remove AGC from your account.

  Contexts
    context     Commands for contexts.
                Contexts specify workflow engines and computational fleets to use when running a workflow.

  Logs
    logs        Commands for various logs.

  Projects
    project     Commands to interact with projects.

  Workflows
    workflow    Commands for workflows.
                Workflows are potentially-dynamic graphs of computational tasks to execute.

  Settings ‚öôÔ∏è
    configure   Commands for configuration.
                Configuration is stored per user.

Flags
      --format string   Format option for output. Valid options are: text, table, json (default &amp;quot;text&amp;quot;)
  -h, --help            help for agc
      --silent          Suppresses all diagnostic information.
  -v, --verbose         Display verbose diagnostic information.
      --version         version for agc
Examples
  Displays the help menu for the specified sub-command.
  `$ agc account --help`
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;If this doesn&amp;rsquo;t work immediately, try:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;start a new terminal shell&lt;/li&gt;
&lt;li&gt;modifying your &lt;code&gt;$HOME/.bashrc&lt;/code&gt; (or equivalent file) appending the following line and restarting your shell:&lt;/li&gt;
&lt;/ul&gt;
&lt;pre&gt;&lt;code&gt;export PATH=$HOME/bin:$PATH
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;If you are running this on MacOS, you may see this below popup window when you initially run any agc commands due to Apple&amp;rsquo;s security restrictions.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;agc-cannot-open-popup.png&#34; alt=&#34;image of cannot open popup&#34;&gt;&lt;/p&gt;
&lt;p&gt;Click Cancel and navigate to Apple&amp;rsquo;s System Preferences, click Security &amp;amp; Privacy, then click General. Near the bottom, you will see a line indicating &lt;code&gt;&amp;quot;agc&amp;quot; was blocked from use because it is not from an identified developer.&lt;/code&gt; To the right, click Allow Anyway.&lt;/p&gt;
&lt;p&gt;Now go back to the terminal and run &lt;code&gt;agc --help&lt;/code&gt; again. You will see this new popup window below asking you to override the system security.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;agc-cannot-verify-developer-popup.png&#34; alt=&#34;image of cannot verify developer popup&#34;&gt;&lt;/p&gt;
&lt;p&gt;Click Open and now your &lt;code&gt;agc&lt;/code&gt; is correctly installed.&lt;/p&gt;
&lt;p&gt;Verify that you have the latest version of Amazon Genomics CLI with:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;agc --version
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;If you do not, you may need to uninstall any previous versions of Amazon Genomics CLI and reinstall the latest.&lt;/p&gt;
&lt;h2 id=&#34;command-completion&#34;&gt;Command Completion&lt;/h2&gt;
&lt;p&gt;Amazon Genomics CLI can generate shell completion scripts that enable &amp;lsquo;Tab&amp;rsquo; completion of commands.
Command completion is optional and not required to use Amazon Genomics CLI. To generate a completion script you can use:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-shell&#34; data-lang=&#34;shell&#34;&gt; agc completion &amp;lt;shell&amp;gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;where &amp;ldquo;shell&amp;rdquo; is one of:&lt;/p&gt;
&lt;h3 id=&#34;bash&#34;&gt;Bash&lt;/h3&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-shell&#34; data-lang=&#34;shell&#34;&gt;&lt;span style=&#34;color:#204a87&#34;&gt;source&lt;/span&gt; &amp;lt;&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;(&lt;/span&gt;agc completion bash&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;To load completions for each session, execute once:&lt;/p&gt;
&lt;h4 id=&#34;linux&#34;&gt;Linux:&lt;/h4&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-shell&#34; data-lang=&#34;shell&#34;&gt;agc completion bash &amp;gt; /etc/bash_completion.d/agc
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h4 id=&#34;macos&#34;&gt;macOS:&lt;/h4&gt;
&lt;p&gt;If you haven&amp;rsquo;t already installed &lt;code&gt;bash-completion&lt;/code&gt;, execute the following once&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-shell&#34; data-lang=&#34;shell&#34;&gt;brew install bash-completion
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;and then, add the following line to your ~/.bash_profile:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-shell&#34; data-lang=&#34;shell&#34;&gt;&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;[[&lt;/span&gt; -r &lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#34;/usr/local/etc/profile.d/bash_completion.sh&amp;#34;&lt;/span&gt; &lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;]]&lt;/span&gt; &lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;&amp;amp;&amp;amp;&lt;/span&gt; . &lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#34;/usr/local/etc/profile.d/bash_completion.sh&amp;#34;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Once bash completion is installed&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-shell&#34; data-lang=&#34;shell&#34;&gt;agc completion bash &amp;gt; /usr/local/etc/bash_completion.d/agc
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h3 id=&#34;zsh&#34;&gt;Zsh:&lt;/h3&gt;
&lt;p&gt;If shell completion is not already enabled in your environment, you will need to enable it.  You can execute the following once:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-shell&#34; data-lang=&#34;shell&#34;&gt;&lt;span style=&#34;color:#204a87&#34;&gt;echo&lt;/span&gt; &lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#34;autoload -U compinit; compinit&amp;#34;&lt;/span&gt; &amp;gt;&amp;gt; ~/.zshrc
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;To load completions for each session, execute once:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-shell&#34; data-lang=&#34;shell&#34;&gt;agc completion zsh &amp;gt; &lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;${&lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;fpath&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;[1]&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;}&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;/_agc&amp;#34;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;You will need to start a new shell for this setup to take effect.&lt;/p&gt;
&lt;h3 id=&#34;fish&#34;&gt;fish:&lt;/h3&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-shell&#34; data-lang=&#34;shell&#34;&gt;agc completion fish &lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;|&lt;/span&gt; &lt;span style=&#34;color:#204a87&#34;&gt;source&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;To load completions for each session, execute once:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-shell&#34; data-lang=&#34;shell&#34;&gt;agc completion fish &amp;gt; ~/.config/fish/completions/agc.fish
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;PowerShell:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-shell&#34; data-lang=&#34;shell&#34;&gt;agc completion powershell &lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;|&lt;/span&gt; Out-String &lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;|&lt;/span&gt; Invoke-Expression
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;To load completions for every new session, run:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-shell&#34; data-lang=&#34;shell&#34;&gt;agc completion powershell &amp;gt; agc.ps1
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;and source this file from your PowerShell profile.&lt;/p&gt;

      </description>
    </item>
    
    <item>
      <title>Docs: Contexts</title>
      <link>https://aws.github.io/amazon-genomics-cli/docs/concepts/contexts/</link>
      <pubDate>Tue, 31 Aug 2021 17:26:49 -0400</pubDate>
      
      <guid>https://aws.github.io/amazon-genomics-cli/docs/concepts/contexts/</guid>
      <description>
        
        
        &lt;h2 id=&#34;what-is-a-context&#34;&gt;What is a Context?&lt;/h2&gt;
&lt;p&gt;A context is a set of cloud resources. Amazon Genomics CLI runs &lt;a href=&#34;https://aws.github.io/amazon-genomics-cli/amazon-genomics-cli/docs/concepts/workflows/&#34;&gt;workflows&lt;/a&gt; in a context. A deployed context will include an
&lt;a href=&#34;https://aws.github.io/amazon-genomics-cli/amazon-genomics-cli/docs/concepts/engines/&#34;&gt;engine&lt;/a&gt; that can interpret
and manage the running of a workflow along with compute resources that will run the individual tasks of the workflow. The
deployed context will also contain any resources needed by the engine or compute resources including any security, permissions
and &lt;a href=&#34;https://aws.github.io/amazon-genomics-cli/amazon-genomics-cli/docs/concepts/logs/&#34;&gt;logging&lt;/a&gt; capabilities. Deployed contexts are &lt;a href=&#34;https://aws.github.io/amazon-genomics-cli/amazon-genomics-cli/docs/concepts/namespaces/&#34;&gt;namespaced&lt;/a&gt; based on the user, project and context name so that resources
are isolated, preventing collisions.&lt;/p&gt;
&lt;p&gt;When a workflow is run the user will decide which context will run it. For example, you might choose to submit a workflow
to a context that uses &amp;ldquo;Spot priced&amp;rdquo; resources or one that uses &amp;ldquo;On Demand&amp;rdquo; priced resources.&lt;/p&gt;
&lt;p&gt;When deployed context resources that require a VPC will be deployed into the VPC that was specified when the &lt;a href=&#34;https://aws.github.io/amazon-genomics-cli/amazon-genomics-cli/docs/concepts/accounts/&#34;&gt;account&lt;/a&gt; was
activated.&lt;/p&gt;
&lt;h2 id=&#34;how-is-a-context-defined&#34;&gt;How is a Context Defined?&lt;/h2&gt;
&lt;p&gt;A context is defined in the YAML file that defines the &lt;a href=&#34;https://aws.github.io/amazon-genomics-cli/amazon-genomics-cli/docs/concepts/projects/&#34;&gt;project&lt;/a&gt;. A project has at least one context but may have many.
Contexts must have unique names and are defined as YAML maps.&lt;/p&gt;
&lt;p&gt;A context may request use of &lt;a href=&#34;https://aws.amazon.com/ec2/spot/pricing/&#34;&gt;Spot priced&lt;/a&gt; compute resources with &lt;code&gt;requestSpotInstances: true&lt;/code&gt;. The default value is &lt;code&gt;false&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;A context must define an array of one or more &lt;code&gt;engines&lt;/code&gt;. Each engine definition must specify the workflow language that it
will interpret. For each language Amazon Genomics CLI has a default engine however, users may specify the exact engine in the &lt;code&gt;engine&lt;/code&gt;
parameter.&lt;/p&gt;
&lt;h2 id=&#34;general-architecture-of-a-context&#34;&gt;General Architecture of a Context&lt;/h2&gt;
&lt;p&gt;The exact architecture of a context will depend on the context properties described below and defined in their &lt;code&gt;agc-project.yaml&lt;/code&gt;. However, the architecture deployed on execution of &lt;code&gt;agc context deploy&lt;/code&gt; is shown in the following diagram:&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;ContextGeneralArchitecture.png&#34; alt=&#34;Image of the general architecture of a context&#34; title=&#34;General Architecture of a Context&#34;&gt;&lt;/p&gt;
&lt;h2 id=&#34;context-properties&#34;&gt;Context Properties&lt;/h2&gt;
&lt;h3 id=&#34;instance-types&#34;&gt;Instance Types&lt;/h3&gt;
&lt;p&gt;You may optionally specify the instance types to be used in a context. This can be a specific type such as &lt;code&gt;r5.2xlarge&lt;/code&gt;
or it can be an instance family such as &lt;code&gt;c5&lt;/code&gt; or a combination. By default, a context will use instance types up to &lt;code&gt;4xlarge&lt;/code&gt;&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Note, if you only specify large instance types you will be using those instances for running even the smallest tasks so
we recommend including smaller types as well.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Ensure that any custom types you list are available in the region that you&amp;rsquo;re using with Amazon Genomics CLI or the
context will fail to deploy. You can obtain a list using the following command&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-shell&#34; data-lang=&#34;shell&#34;&gt;aws ec2 describe-instance-type-offerings &lt;span style=&#34;color:#4e9a06&#34;&gt;\
&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&lt;/span&gt;    --region &amp;lt;region_name&amp;gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h4 id=&#34;examples&#34;&gt;Examples&lt;/h4&gt;
&lt;p&gt;The following snippet defines two contexts, one that uses spot resources and one that uses on demand. Both contain a
WDL engine.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-yaml&#34; data-lang=&#34;yaml&#34;&gt;&lt;span style=&#34;color:#000&#34;&gt;...&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;contexts&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;  &lt;/span&gt;&lt;span style=&#34;color:#8f5902;font-style:italic&#34;&gt;# The on demand context uses on demand EC2 instances which may be more expensive but will not be interrupted&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;  &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;onDemandCtx&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;    &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;requestSpotInstances&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;false&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;    &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;engines&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;      &lt;/span&gt;- &lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;type&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;wdl&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;        &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;engine&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;cromwell&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-yaml&#34; data-lang=&#34;yaml&#34;&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;  &lt;/span&gt;&lt;span style=&#34;color:#8f5902;font-style:italic&#34;&gt;# The spot context uses EC2 spot instances which are usually cheaper but may be interrupted&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;  &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;spotCtx&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;    &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;requestSpotInstances&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;true&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;    &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;engines&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;      &lt;/span&gt;- &lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;type&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;wdl&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;        &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;engine&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;cromwell&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;...&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;The following context may use any instance type from the &lt;code&gt;m5&lt;/code&gt;, &lt;code&gt;c5&lt;/code&gt; or &lt;code&gt;r5&lt;/code&gt; families&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-yaml&#34; data-lang=&#34;yaml&#34;&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;contexts&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;  &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;nfLargeCtx&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;    &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;instanceTypes&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;[&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#34;c5&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;,&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#34;m5&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;,&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#34;r5&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;]&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;    &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;engines&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;      &lt;/span&gt;- &lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;type&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;nextflow&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;        &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;engine&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;nextflow&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h3 id=&#34;max-vcpus&#34;&gt;Max vCpus&lt;/h3&gt;
&lt;p&gt;&lt;em&gt;default:&lt;/em&gt; 256&lt;/p&gt;
&lt;p&gt;You may optionally specify the maximum number of vCpus used in a context. This is the max total amount of vCpus of all the jobs currently
running within a context. When the max has been reached, additional jobs will be queued.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;note:&lt;/em&gt; if your vCPU limit is lower than maxVCpus then you won&amp;rsquo;t get as many as requested and would need to make a limit increase.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-yaml&#34; data-lang=&#34;yaml&#34;&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;contexts&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;  &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;largeCtx&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;    &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;maxVCpus&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#0000cf;font-weight:bold&#34;&gt;2000&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;    &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;engines&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;      &lt;/span&gt;- &lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;type&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;nextflow&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;        &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;engine&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;nextflow&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h3 id=&#34;public-subnets&#34;&gt;Public Subnets&lt;/h3&gt;
&lt;p&gt;In the interest of saving money, in particular if you intend to have the AGC stack deployed for a long period, you may choose to deploy in &amp;ldquo;public subnet&amp;rdquo; mode.
To do this, you must first set up the core stack using &lt;code&gt;aws configure --usePublicSubnets&lt;/code&gt;, which will disable the creation of the NAT gateway and VPC endpoints which present an ongoing cost unrelated to your use of compute resources.
After you have done this, you must also set &lt;code&gt;usePublicSubnets: true&lt;/code&gt; in all contexts you use:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-yaml&#34; data-lang=&#34;yaml&#34;&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;contexts&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;  &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;someCtx&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;    &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;usePublicSubnets&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;true&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;    &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;engines&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;      &lt;/span&gt;- &lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;type&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;nextflow&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;        &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;engine&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;nextflow&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;This ensures that the AWS batch instances are deployed into a public subnet, which has no additional cost associated with it.
However note that while these instances are given a security group that will block all incoming traffic, this is not as secure as using the default private subnet mode.&lt;/p&gt;
&lt;h2 id=&#34;context-commands&#34;&gt;Context Commands&lt;/h2&gt;
&lt;p&gt;A full reference of context commands is &lt;a href=&#34;https://aws.github.io/amazon-genomics-cli/amazon-genomics-cli/docs/reference/agc_context/&#34;&gt;here&lt;/a&gt;&lt;/p&gt;
&lt;h3 id=&#34;describe&#34;&gt;&lt;code&gt;describe&lt;/code&gt;&lt;/h3&gt;
&lt;p&gt;The command &lt;code&gt;agc context describe &amp;lt;context-name&amp;gt; [flags]&lt;/code&gt; will describe the named context as defined in the project YAML
as well as other relevant account information.&lt;/p&gt;
&lt;h3 id=&#34;list&#34;&gt;&lt;code&gt;list&lt;/code&gt;&lt;/h3&gt;
&lt;p&gt;The command &lt;code&gt;agc context list [flags]&lt;/code&gt; will list the names of all contexts defined in the project YAML file along with the name of the engine used by the context.&lt;/p&gt;
&lt;h3 id=&#34;deploy&#34;&gt;&lt;code&gt;deploy&lt;/code&gt;&lt;/h3&gt;
&lt;p&gt;The command &lt;code&gt;agc context deploy &amp;lt;context-name&amp;gt; [flags]&lt;/code&gt; is used to deploy the cloud infrastructure required by the context.
If the context is already running the existing infrastructure will be updated to reflect changes in project YAML. For example
if you added another &lt;code&gt;data&lt;/code&gt; definition in your project and run &lt;code&gt;agc context deploy &amp;lt;context-name&amp;gt;&lt;/code&gt; then the deployed context
will be updated to allow access to the new data.&lt;/p&gt;
&lt;p&gt;All contexts defined in the project YAML can be deployed or updated using the &lt;code&gt;--all&lt;/code&gt; flag.&lt;/p&gt;
&lt;p&gt;Individually named contexts can be deployed or updated as positional arguments. For example: &lt;code&gt;agc context deploy ctx1 ctx2&lt;/code&gt;
will deploy the contexts &lt;code&gt;ctx1&lt;/code&gt; and &lt;code&gt;ctx2&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;The inclusion of the &lt;code&gt;--verbose&lt;/code&gt; flag will show the full CloudFormation output of the context deployment.&lt;/p&gt;
&lt;h3 id=&#34;destroy&#34;&gt;&lt;code&gt;destroy&lt;/code&gt;&lt;/h3&gt;
&lt;p&gt;A contexts cloud resources can be &amp;ldquo;destroyed&amp;rdquo; using the &lt;code&gt;agc context destroy &amp;lt;context-name&amp;gt;&lt;/code&gt; command. This will remove any
infrastructure artifacts associated with the context unless they are defined as being retained. Typically, things like logs
and workflow outputs on S3 are retained when a context is destroyed.&lt;/p&gt;
&lt;p&gt;All deployed contexts can be destroyed using the &lt;code&gt;--all&lt;/code&gt; flag.&lt;/p&gt;
&lt;p&gt;Multiple contexts can be destroyed in a single command using positional arguments. For example: &lt;code&gt;agc context destroy ctx1 ctx2&lt;/code&gt;
will destroy the contexts &lt;code&gt;ctx1&lt;/code&gt; and &lt;code&gt;ctx2&lt;/code&gt;.&lt;/p&gt;
&lt;h3 id=&#34;status&#34;&gt;&lt;code&gt;status&lt;/code&gt;&lt;/h3&gt;
&lt;p&gt;The status command is used to determine the status of a &lt;em&gt;deployed&lt;/em&gt; context or context instance. This can be useful to determine
if an instance of a particular context is already deployed. It can be used to determine if the deployed context is
consistent with the defined context in the project YAML file. For example, if you deploy a context instance and later
change the definition of the context in the project YAML file then the running instance will no longer reflect the definition.
In this case you may choose to update the deployed instance using the &lt;code&gt;agc context deploy&lt;/code&gt; command.&lt;/p&gt;
&lt;p&gt;Status will only be shown for contexts for the current user in the current AWS region for the current project. To show
contexts for another project, issue the command from that project&amp;rsquo;s home folder (or subfolder). To display contexts for
another AWS region, you can use a different AWS CLI profile or set the &lt;code&gt;AWS_PROFILE&lt;/code&gt; environment variable to the
desired region (e.g &lt;code&gt;export AWS_REGION=us-west-2&lt;/code&gt;).&lt;/p&gt;


&lt;div class=&#34;alert alert-warning&#34; role=&#34;alert&#34;&gt;
&lt;h4 class=&#34;alert-heading&#34;&gt;Warning&lt;/h4&gt;

    Because the &lt;code&gt;status&lt;/code&gt; command will only show contexts that are listed in the project YAML you should take care to &lt;code&gt;destroy&lt;/code&gt;
any running contexts before deleting them from the project YAML.

&lt;/div&gt;

&lt;h2 id=&#34;costs&#34;&gt;Costs&lt;/h2&gt;
&lt;p&gt;Infrastructure deployed for a context is tagged with the context name as well as username and project name. These tags
can be used with AWS CostExplorer to identify the costs associated with running contexts.&lt;/p&gt;
&lt;p&gt;A deployed context will incur charges based on the resources being used by the context. If a workflow is running this
will include compute costs for running the workflow tasks but some contexts may include infrastructure that is always
&amp;ldquo;on&amp;rdquo; and will incur costs even when no workflow is running. If you no longer need a context we recommend pausing or
destroying it.&lt;/p&gt;
&lt;p&gt;If &lt;code&gt;requestSpotInstances&lt;/code&gt; is true, the context will use spot instances for compute tasks. The context will set the max
price to 100% although if the current price is lower you will pay the lower price. Note that even at 100% spot instances
can still be interrupted if total demand for on demand instances in an availability zone exceeds the available pool. For
full details see &lt;a href=&#34;https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/spot-interruptions.html&#34;&gt;Spot Instance Interruptions&lt;/a&gt;
and &lt;a href=&#34;https://aws.amazon.com/ec2/spot/pricing/&#34;&gt;EC2 Spot Pricing&lt;/a&gt;.&lt;/p&gt;
&lt;h3 id=&#34;ongoing-costs&#34;&gt;Ongoing Costs&lt;/h3&gt;
&lt;p&gt;Until a context is destroyed resources that are deployed can incur ongoing costs even if a workflow is not running. The
exact costs depend on the configuration of the context.&lt;/p&gt;
&lt;p&gt;Amazon Genomics CLI version 1.0.1 and earlier used an AWS Fargate based WES service for each deployed context. The service
uses 0.5 vCPU, 4 GB memory and 20 GB base instance storage. Fargate pricing varies by region and is detailed &lt;a href=&#34;https://aws.amazon.com/fargate/pricing/&#34;&gt;here&lt;/a&gt;.
The estimated cost is available via &lt;a href=&#34;https://calculator.aws/#/estimate?id=9a67ba7845199cf108d85ae0f9b8176253266005&#34;&gt;this link&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;After version 1.0.1, the WES endpoints deployed by Amazon Genomics CLI are implemented with AWS Lambda and therefore use
a &lt;a href=&#34;https://aws.amazon.com/lambda/pricing/&#34;&gt;pricing model&lt;/a&gt; based on invocations.&lt;/p&gt;
&lt;p&gt;Contexts using a Cromwell engine run an additional AWS Fargate service for the engine with 2 vCPU, 16 GB RAM and 20 GB of
base storage. Additionally, Cromwell is deployed with a standard EFS volume for storage of metadata. EFS &lt;a href=&#34;https://aws.amazon.com/efs/pricing/&#34;&gt;costs&lt;/a&gt; are volume based. While
relatively small the amount of metadata will expand as more workflows are run. The volume is destroyed when the context is destroyed. An estimated
cost for both components is available via &lt;a href=&#34;https://calculator.aws/#/estimate?id=8ccc606c1b267e2933a6d683c0b98fcf11e4cbab&#34;&gt;this link&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Contexts using the &amp;ldquo;miniwdl&amp;rdquo; or &amp;ldquo;snakemake&amp;rdquo; engines use EFS volumes as scratch space for workflow intermediates, caches and temporary files. Because many genomics
workflows can accumulate several GB of intermediates per run we recommend destroying these contexts when not in use. An estimated cost assuming a
total of 500 GB of workflow artifacts is available via &lt;a href=&#34;https://calculator.aws/#/estimate?id=4d19b43aa86fcc3af199c425bfcc55193592cbb4&#34;&gt;this link&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Refer to the &lt;a href=&#34;#public-subnets&#34;&gt;public subnets section&lt;/a&gt; if you are concerned about reducing these ongoing costs.&lt;/p&gt;
&lt;h3 id=&#34;tags&#34;&gt;Tags&lt;/h3&gt;
&lt;p&gt;All context infrastructure is &lt;a href=&#34;https://aws.github.io/amazon-genomics-cli/amazon-genomics-cli/docs/concepts/namespaces/#tags&#34;&gt;tagged&lt;/a&gt; with the context name, username and project name. These tags may be used to help
differentiate costs.&lt;/p&gt;
&lt;h2 id=&#34;technical-details&#34;&gt;Technical Details&lt;/h2&gt;
&lt;p&gt;Context infrastructure is defined as code as &lt;a href=&#34;https://aws.amazon.com/cdk/&#34;&gt;AWS CDK&lt;/a&gt; apps. For examples, take a look at the &lt;code&gt;packages/cdk&lt;/code&gt; folder. When
deployed a context will produce one or more stacks in Cloudformation. Details can be viewed in the Cloudformation console
or with the AWS CLI.&lt;/p&gt;
&lt;p&gt;A context includes an endpoint compliant with the &lt;a href=&#34;https://ga4gh.github.io/workflow-execution-service-schemas/docs/&#34;&gt;GA4GH WES API&lt;/a&gt;. This API is how Amazon Genomics CLI submits workflows to the context. The
context also contains one or more workflow engines. These may either be deployed as long-running services as is the case
with Cromwell or as &amp;ldquo;head&amp;rdquo; jobs that are responsible for a single workflow, as is the case for NextFlow. Engines run as
&amp;ldquo;head&amp;rdquo; jobs are started and stopped on demand thereby saving resources.&lt;/p&gt;
&lt;h3 id=&#34;updating-launch-templates&#34;&gt;Updating Launch Templates&lt;/h3&gt;
&lt;p&gt;Changes to EC2 LaunchTemplates in CDK result in a new LaunchTemplate version when the infrastructure is updated. Currently,
CDK is unable to also update the default version of the template. In addition, any existing AWS Batch Compute Environments
will not be updated to use the new LaunchTemplate version. Because of this, whenever a LaunchTemplate is updated in CDK
code we recommend destroying any relevant running contexts and redeploying them. An update will &lt;em&gt;NOT&lt;/em&gt; be sufficient.&lt;/p&gt;

      </description>
    </item>
    
    <item>
      <title>Docs: Setup</title>
      <link>https://aws.github.io/amazon-genomics-cli/docs/getting-started/setup/</link>
      <pubDate>Tue, 07 Sep 2021 13:42:50 -0400</pubDate>
      
      <guid>https://aws.github.io/amazon-genomics-cli/docs/getting-started/setup/</guid>
      <description>
        
        
        &lt;h2 id=&#34;account-activation&#34;&gt;Account activation&lt;/h2&gt;
&lt;p&gt;To start using Amazon Genomics CLI with your AWS account, you need to activate it.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;agc account activate
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;This will create the core infrastructure that Amazon Genomics CLI needs to operate, which includes a DynamoDB table, an S3 bucket and a VPC. This will take ~5min to complete. You only need to do this once per account region.&lt;/p&gt;
&lt;p&gt;The DynamoDB table is used by the CLI for persistent state. The S3 bucket is used for durable workflow data and Amazon Genomics CLI metadata and the VPC is used to isolate compute resources. You can specify your own preexisting S3 Bucket or VPC if needed using &lt;code&gt;--bucket&lt;/code&gt; and &lt;code&gt;--vpc&lt;/code&gt; options.&lt;/p&gt;
&lt;h3 id=&#34;cdk-bootstrap&#34;&gt;CDK Bootstrap&lt;/h3&gt;


&lt;div class=&#34;alert alert-warning&#34; role=&#34;alert&#34;&gt;
&lt;h4 class=&#34;alert-heading&#34;&gt;Attention&lt;/h4&gt;

    This step is NOT required when using Amazon Genomics CLI version 1.2 or above

&lt;/div&gt;

&lt;p&gt;Amazon Genomics CLI uses AWS CDK to deploy infrastructure. Activating an account will bootstrap the AWS Environment for CDK app deployments.
CDK Bootstrap deploys the infrastructure needed to allow CDK to deploy CDK defined infrastructure. Full details are available
&lt;a href=&#34;https://docs.aws.amazon.com/cdk/latest/guide/bootstrapping.html&#34;&gt;here&lt;/a&gt;.&lt;/p&gt;
&lt;h2 id=&#34;define-a-username&#34;&gt;Define a username&lt;/h2&gt;
&lt;p&gt;Amazon Genomics CLI requires that you define a username and email. You can do this using the following command:&lt;/p&gt;
&lt;p&gt;&lt;code&gt;agc configure email you@youremail.com&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;The username only needs to be configured once per computer that you use Amazon Genomics CLI from.&lt;/p&gt;

      </description>
    </item>
    
    <item>
      <title>Docs: Data</title>
      <link>https://aws.github.io/amazon-genomics-cli/docs/concepts/data/</link>
      <pubDate>Tue, 31 Aug 2021 17:27:22 -0400</pubDate>
      
      <guid>https://aws.github.io/amazon-genomics-cli/docs/concepts/data/</guid>
      <description>
        
        
        &lt;p&gt;To run an analysis you need data. In the &lt;code&gt;agc-project.yaml&lt;/code&gt; file of an Amazon Genomics CLI &lt;a href=&#34;https://aws.github.io/amazon-genomics-cli/amazon-genomics-cli/docs/concepts/projects/&#34;&gt;project&lt;/a&gt; &lt;code&gt;data&lt;/code&gt; is a list of data locations
which can be used by the &lt;a href=&#34;https://aws.github.io/amazon-genomics-cli/amazon-genomics-cli/docs/concepts/contexts/&#34;&gt;contexts&lt;/a&gt; of the project.&lt;/p&gt;
&lt;p&gt;In the example data definition below we are declaring that the project&amp;rsquo;s contexts will be allowed to access the three
listed S3 bucket URIs.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-yaml&#34; data-lang=&#34;yaml&#34;&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;data&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;  &lt;/span&gt;- &lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;location&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;s3://gatk-test-data&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;    &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;readOnly&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;true&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;  &lt;/span&gt;- &lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;location&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;s3://broad-references&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;    &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;readOnly&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;true&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;  &lt;/span&gt;- &lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;location&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;s3://1000genomes-dragen-3.7.6&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;    &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;readOnly&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;true&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;The contexts of the project will be &lt;em&gt;denied&lt;/em&gt; access to all other S3 location except for the S3 bucket created or associated
when the &lt;a href=&#34;https://aws.github.io/amazon-genomics-cli/amazon-genomics-cli/docs/concepts/accounts/&#34;&gt;account&lt;/a&gt; was initialized by Amazon Genomics CLI.&lt;/p&gt;
&lt;p&gt;Declaring access in the project will only ensure your infrastructure is correctly configured to access the bucket. If
the target bucket is further restricted, such as by an access control list or bucket policy, you will still be denied access.
In these cases you should work with the bucket owner to facilitate access.&lt;/p&gt;
&lt;h3 id=&#34;read-and-write&#34;&gt;Read and Write&lt;/h3&gt;
&lt;p&gt;The default value of &lt;code&gt;readOnly&lt;/code&gt; is &lt;code&gt;true&lt;/code&gt;. At the time of writing, write access is not supported (except for the Amazon Genomics CLI core S3 bucket)&lt;/p&gt;
&lt;h3 id=&#34;access-to-a-prefix&#34;&gt;Access to a Prefix&lt;/h3&gt;
&lt;p&gt;The above examples will grant read access to an entire bucket. You can grant more granular access to a prefix within a bucket,
for example:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-yaml&#34; data-lang=&#34;yaml&#34;&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;data&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;  &lt;/span&gt;- &lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;location&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;s3://my-bucket/my/prefix/&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h3 id=&#34;cross-account-access&#34;&gt;Cross Account Access&lt;/h3&gt;
&lt;p&gt;A bucket in another AWS account can be accessed if the owner has set up access, and you are using a role that is allowed access.
See &lt;a href=&#34;https://aws.amazon.com/premiumsupport/knowledge-center/cross-account-access-s3/&#34;&gt;cross account access&lt;/a&gt; for details.&lt;/p&gt;
&lt;h2 id=&#34;updating-data-sources&#34;&gt;Updating Data Sources&lt;/h2&gt;
&lt;p&gt;If data definitions are added to or removed from a project definition the change will &lt;em&gt;not&lt;/em&gt; be reflected in deployed contexts
until they are updated. This can be done with &lt;code&gt;agc context deploy --all&lt;/code&gt; for all contexts or by using a context name to update
only one. See &lt;a href=&#34;https://aws.github.io/amazon-genomics-cli/amazon-genomics-cli/docs/concepts/contexts/#deploy&#34;&gt;&lt;code&gt;context deploy&lt;/code&gt;&lt;/a&gt; for details.&lt;/p&gt;


&lt;div class=&#34;alert alert-warning&#34; role=&#34;alert&#34;&gt;
&lt;h4 class=&#34;alert-heading&#34;&gt;Warning&lt;/h4&gt;

    Removing access to S3 buckets while there are running workflows in a project may cause the workflow to fail if it depends
on access to data in those buckets.

&lt;/div&gt;

&lt;h2 id=&#34;technical-details&#34;&gt;Technical Details&lt;/h2&gt;
&lt;p&gt;When a context is deployed, IAM roles used by the infrastructure of the context will be granted s3 permissions to perform
some S3 read (or read and write) actions on the listed locations. The permissions are defined in CDK code in &lt;code&gt;/packages/cdk/apps/&lt;/code&gt;.
The CDK code does not modify any data in the buckets or any other bucket policies or configurations.&lt;/p&gt;

      </description>
    </item>
    
    <item>
      <title>Docs: Nextflow</title>
      <link>https://aws.github.io/amazon-genomics-cli/docs/workflow-engines/nextflow/</link>
      <pubDate>Fri, 01 Oct 2021 17:27:31 -0400</pubDate>
      
      <guid>https://aws.github.io/amazon-genomics-cli/docs/workflow-engines/nextflow/</guid>
      <description>
        
        
        &lt;h2 id=&#34;description&#34;&gt;Description&lt;/h2&gt;
&lt;p&gt;&lt;a href=&#34;https://www.nextflow.io/&#34;&gt;Nextflow&lt;/a&gt; is free open source software distributed under the Apache 2.0 licence
developed by &lt;a href=&#34;http://www.seqera.io/&#34;&gt;Seqera&lt;/a&gt; Labs.
The project was started in the Notredame Lab at the &lt;a href=&#34;http://www.crg.eu/&#34;&gt;Centre for Genomic Regulation (CRG)&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;The source code for Nextflow is available on &lt;a href=&#34;https://github.com/nextflow-io/nextflow&#34;&gt;GitHub&lt;/a&gt;.&lt;/p&gt;
&lt;h2 id=&#34;architecture&#34;&gt;Architecture&lt;/h2&gt;
&lt;p&gt;There are four components of a Nextflow engine as deployed in an Amazon Genomics CLI context:&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;NextflowContextArch.png&#34; alt=&#34;Image of infrastructure deployed in a Nextflow context&#34; title=&#34;Nextflow Context Architecture&#34;&gt;&lt;/p&gt;
&lt;h3 id=&#34;wes-adapter&#34;&gt;WES Adapter&lt;/h3&gt;
&lt;p&gt;Amazon Genomics CLI communicates with the Nextflow engine via a GA4GH &lt;a href=&#34;https://github.com/ga4gh/workflow-execution-service-schemas&#34;&gt;WES&lt;/a&gt; REST service. The WES Adapter implements
the WES standard and translates WES calls into calls to the Nextflow head process.&lt;/p&gt;
&lt;h3 id=&#34;head-compute-environment&#34;&gt;Head Compute Environment&lt;/h3&gt;
&lt;p&gt;For every workflow submitted, the WES adapter will create a new AWS Batch Job that contains the Nextflow process responsible
for running that workflow. These Nextflow &amp;ldquo;head&amp;rdquo; jobs are run in an &amp;ldquo;On-demand&amp;rdquo; compute environment even when the actual workflow
tasks run in a Spot environment. This is to prevent Spot interruptions from terminating the workflow coordinator.&lt;/p&gt;
&lt;h3 id=&#34;task-compute-environment&#34;&gt;Task Compute Environment&lt;/h3&gt;
&lt;p&gt;Workflow tasks are submitted by the Nextflow head job to an AWS Batch queue and run in containers using an AWS Compute Environment.
Container characteristics are defined by the resources requested in the workflow configuration. AWS Batch coordinates the elastic provisioning of EC2 instances (container hosts)
based on the available work in the queue. Batch will place containers on container hosts as space allows.&lt;/p&gt;
&lt;h4 id=&#34;fetch-and-run-strategy&#34;&gt;Fetch and Run Strategy&lt;/h4&gt;
&lt;p&gt;Execution of workflow tasks uses a &amp;ldquo;Fetch and Run&amp;rdquo; strategy. Input files required by a workflow task are fetched from
S3 into the task container. Output files are copied out of the container to S3.&lt;/p&gt;
&lt;h4 id=&#34;disk-expansion&#34;&gt;Disk Expansion&lt;/h4&gt;
&lt;p&gt;Container hosts in the Batch compute environment use EBS volumes as local scratch space. As an EBS volume approaches a
capacity threshold, new EBS volumes will be attached and merged into the file system. These volumes are destroyed when
AWS Batch terminates the container host.&lt;/p&gt;

      </description>
    </item>
    
    <item>
      <title>Docs: Snakemake</title>
      <link>https://aws.github.io/amazon-genomics-cli/docs/workflow-engines/snakemake/</link>
      <pubDate>Fri, 01 Oct 2021 17:27:31 -0400</pubDate>
      
      <guid>https://aws.github.io/amazon-genomics-cli/docs/workflow-engines/snakemake/</guid>
      <description>
        
        
        &lt;h2 id=&#34;description&#34;&gt;Description&lt;/h2&gt;
&lt;p&gt;&lt;a href=&#34;https://snakemake.readthedocs.io/en/stable/&#34;&gt;Snakemake&lt;/a&gt; is free open source software distributed under the MIT licence
developed by &lt;a href=&#34;https://snakemake.readthedocs.io/en/stable/project_info/authors.html&#34;&gt;Johannes K√∂ster and their team&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;The source code for snakemake is available on &lt;a href=&#34;https://github.com/snakemake/snakemake&#34;&gt;GitHub&lt;/a&gt;. When deployed with
Amazon Genomics CLI snakemake uses Batch to distribute the underlying tasks.&lt;/p&gt;
&lt;h2 id=&#34;architecture&#34;&gt;Architecture&lt;/h2&gt;
&lt;p&gt;There are four components of a snakemake engine as deployed in an Amazon Genomics CLI context:&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;SnakeMakeContextArch.png&#34; alt=&#34;Image of infrastructure deployed in a SnakeMake context&#34; title=&#34;SnakeMake Context Architecture&#34;&gt;&lt;/p&gt;
&lt;h3 id=&#34;wes-adapter&#34;&gt;WES Adapter&lt;/h3&gt;
&lt;p&gt;Amazon Genomics CLI communicates with the snakemake engine via a GA4GH &lt;a href=&#34;https://github.com/ga4gh/workflow-execution-service-schemas&#34;&gt;WES&lt;/a&gt; REST service. The WES Adapter implements
the WES standard and translates WES calls into calls to the snakemake head process.&lt;/p&gt;
&lt;h3 id=&#34;head-compute-environment&#34;&gt;Head Compute Environment&lt;/h3&gt;
&lt;p&gt;For every workflow submitted, the WES adapter will create a new AWS Batch Job that contains the snakemake process responsible
for running that workflow. These snakemake &amp;ldquo;head&amp;rdquo; jobs are run in an &amp;ldquo;On-demand&amp;rdquo; AWS Fargate compute environment even when the actual workflow
tasks run in a Spot environment. This is to prevent Spot interruptions from terminating the workflow coordinator.&lt;/p&gt;
&lt;h3 id=&#34;task-compute-environment&#34;&gt;Task Compute Environment&lt;/h3&gt;
&lt;p&gt;Workflow tasks are submitted by the snakemake head job to an AWS Batch queue and run in containers using an AWS Compute Environment.
Container characteristics are defined by the resources requested in the workflow configuration. AWS Batch coordinates the elastic provisioning of EC2 instances (container hosts)
based on the available work in the queue. Batch will place containers on container hosts as space allows.&lt;/p&gt;
&lt;h4 id=&#34;session-cache-and-input-localization&#34;&gt;Session Cache and Input Localization&lt;/h4&gt;
&lt;p&gt;Any context with a snakemake engine will use an Amazon Elastic File System (EFS) volume as scratch space. Inputs from the workflow
are localized to the volume by jobs that the snakemake engine spawns to copy these files to the volume. Outputs are copied back
to S3 after the workflow is complete. Workflow tasks access the EFS volume to obtain inputs and write intermediates and outputs.&lt;/p&gt;
&lt;p&gt;The EFS volume can used by all snakemake engine &amp;ldquo;head&amp;rdquo; jobs to store metadata necessary for dependency caching by specifying an argument
for the conda workspace that is common across all executions. An example of this is &lt;code&gt;--conda-prefix /mnt/efs/snakemake/conda&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;The EFS volume will remain in your account for the lifetime of the context and are destroyed when contexts are destroyed.
Because the volume will grow in size as you run more workflows we recommend destroying the context when done to avoid on going EFS
charges.&lt;/p&gt;
&lt;h2 id=&#34;using-snakemake-as-a-context-engine&#34;&gt;Using Snakemake as a Context Engine&lt;/h2&gt;
&lt;p&gt;You may declare snakemake to be the &lt;code&gt;engine&lt;/code&gt; for any contexts &lt;code&gt;snakemake&lt;/code&gt; type engine. For example:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-yaml&#34; data-lang=&#34;yaml&#34;&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;contexts&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;  &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;onDemandCtx&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;    &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;requestSpotInstances&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;false&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;    &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;engines&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;      &lt;/span&gt;- &lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;type&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;snakemake&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;        &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;engine&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;snakemake&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h2 id=&#34;conda-dependency-caching&#34;&gt;Conda Dependency Caching&lt;/h2&gt;
&lt;p&gt;Dependency caching is disabled by default so that each workflow can be run independently. If you would like workflow
runs to re-use the Conda cache then please specify a folder under &amp;ldquo;/mnt/efs&amp;rdquo; which is where the EFS storage space is
attached. This will enable snakemake to re-use the dependency which will decrease the time that subsequent workflow runs
will take.&lt;/p&gt;
&lt;p&gt;To disable call caching you can provide the &lt;code&gt;--conda-prefix&lt;/code&gt; engine option. You may do this in a workflows &lt;code&gt;MANIFEST.json&lt;/code&gt; by
adding the following key/ value pair.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;  &amp;quot;engineOptions&amp;quot;: &amp;quot;-j 10 --conda-prefix /mnt/efs/snakemake/conda&amp;quot;
&lt;/code&gt;&lt;/pre&gt;
      </description>
    </item>
    
    <item>
      <title>Docs: Hello world</title>
      <link>https://aws.github.io/amazon-genomics-cli/docs/getting-started/helloworld/</link>
      <pubDate>Tue, 07 Sep 2021 14:01:59 -0400</pubDate>
      
      <guid>https://aws.github.io/amazon-genomics-cli/docs/getting-started/helloworld/</guid>
      <description>
        
        
        &lt;p&gt;When you install Amazon Genomics CLI it will create a folder named &lt;code&gt;agc&lt;/code&gt;. Inside there is an &lt;code&gt;examples/demo-project&lt;/code&gt; folder containing an &lt;code&gt;agc-project.yaml&lt;/code&gt;
with some demo projects including a simple &amp;ldquo;hello world&amp;rdquo; workflow.&lt;/p&gt;
&lt;h2 id=&#34;running-hello-world&#34;&gt;Running Hello World&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;Ensure you have met the &lt;a href=&#34;https://aws.github.io/amazon-genomics-cli/amazon-genomics-cli/docs/getting-started/prerequisites/&#34;&gt;prerequisites&lt;/a&gt; and &lt;a href=&#34;https://aws.github.io/amazon-genomics-cli/amazon-genomics-cli/docs/getting-started/installation/&#34;&gt;installed&lt;/a&gt; Amazon Genomics CLI&lt;/li&gt;
&lt;li&gt;Ensure you have followed the &lt;a href=&#34;https://aws.github.io/amazon-genomics-cli/amazon-genomics-cli/docs/getting-started/setup/&#34;&gt;activation&lt;/a&gt; steps&lt;/li&gt;
&lt;li&gt;&lt;code&gt;cd ~/amazon-genomics-cli/examples/demo-wdl-project&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;agc context deploy --context myContext&lt;/code&gt;, this step takes approximately 5 minutes to deploy the infrastructure&lt;/li&gt;
&lt;li&gt;&lt;code&gt;agc workflow run hello --context myContext&lt;/code&gt;, take note of the returned workflow instance ID.&lt;/li&gt;
&lt;li&gt;Check on the status of the workflow &lt;code&gt;agc workflow status -r &amp;lt;workflow-instance-id&amp;gt;&lt;/code&gt;. Initially you will see status like &lt;code&gt;SUBMITTED&lt;/code&gt; but after the elastic compute resources have been spun up and the workflow runs you should see something like the following: &lt;code&gt;WORKFLOWINSTANCE    myContext    9ff7600a-6d6e-4bda-9ab6-c615f5d90734    COMPLETE    2021-09-01T20:17:49Z&lt;/code&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Congratulations! You have just run your first workflow in the cloud using Amazon Genomics CLI! At this point you can run additional workflows, including submitting several instances of the &amp;ldquo;hello world&amp;rdquo; workflow.
The elastic compute resources will expand and contract as necessary to accommodate the backlog of submitted workflows.&lt;/p&gt;
&lt;h2 id=&#34;reviewing-the-results&#34;&gt;Reviewing the Results&lt;/h2&gt;
&lt;p&gt;Workflow results are written to an S3 bucket specified or created by Amazon Genomics CLI during account activation.
You can list or retrieve the S3 URI for the bucket with:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-shell&#34; data-lang=&#34;shell&#34;&gt;&lt;span style=&#34;color:#000&#34;&gt;AGC_BUCKET&lt;/span&gt;&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;$(&lt;/span&gt;aws ssm get-parameter &lt;span style=&#34;color:#4e9a06&#34;&gt;\
&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&lt;/span&gt;    --name /agc/_common/bucket &lt;span style=&#34;color:#4e9a06&#34;&gt;\
&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&lt;/span&gt;    --query &lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#39;Parameter.Value&amp;#39;&lt;/span&gt; &lt;span style=&#34;color:#4e9a06&#34;&gt;\
&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&lt;/span&gt;    --output text&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;and then use &lt;code&gt;aws s3&lt;/code&gt; commands to explore and retrieve data from the bucket. Workflow output will be in the
&lt;code&gt;s3://agc-&amp;lt;account-num&amp;gt;-&amp;lt;region&amp;gt;/project/&amp;lt;project-name&amp;gt;/userid/&amp;lt;user-id&amp;gt;/context/&amp;lt;context-name&amp;gt;/workflow/&amp;lt;workflow-name&amp;gt;/&lt;/code&gt;
path. The rest of the path depends on the engine used to run the workflow. For Cromwell it will continue with:
&lt;code&gt;.../cromwell-execution/&amp;lt;wdl-wf-name&amp;gt;/&amp;lt;workflow-run-id&amp;gt;/&amp;lt;task-name&amp;gt;&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;If a workflow declares outputs then you may obtain these using the command:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-shell&#34; data-lang=&#34;shell&#34;&gt;agc workflow output &amp;lt;workflow_run_id&amp;gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;You should see a response similar to:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-shell&#34; data-lang=&#34;shell&#34;&gt;OUTPUT	id	6cc6f742-dc87-4649-b319-1af45c4c09c6
OUTPUT	outputs.hello_agc.hello.out	Hello Amazon Genomics CLI!
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;You can also obtain task logs for a workflow using the following form &lt;code&gt;agc logs workflow &amp;lt;workflow-name&amp;gt; -r &amp;lt;instance-id&amp;gt;&lt;/code&gt;.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Note, if the workflow did not actually run any tasks due to call caching then there will be no output from this command.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2 id=&#34;cleaning-up&#34;&gt;Cleaning Up&lt;/h2&gt;
&lt;p&gt;Once you are done with &lt;code&gt;myContext&lt;/code&gt; you can destroy it with:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-shell&#34; data-lang=&#34;shell&#34;&gt;agc context destroy myContext
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;This will remove the cloud resources associated with the named context, but will keep any S3 outputs and CloudWatch logs.&lt;/p&gt;
&lt;p&gt;If you want stop using Amazon Genomics CLI in your AWS account entirely, you need to deactivate it:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-shell&#34; data-lang=&#34;shell&#34;&gt;agc account deactivate
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;This will remove Amazon Genomics CLI‚Äôs core infrastructure. If Amazon Genomics CLI created a VPC as part of the activate process, it will be &lt;em&gt;removed&lt;/em&gt;. If Amazon Genomics CLI created an S3 bucket for you, it will be &lt;em&gt;retained&lt;/em&gt;.&lt;/p&gt;
&lt;p&gt;To uninstall Amazon Genomics CLI from your local machine, run the following command:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-shell&#34; data-lang=&#34;shell&#34;&gt;./agc/uninstall.sh

&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Note uninstalling the CLI will &lt;em&gt;not&lt;/em&gt; remove any resources or persistent data from your AWS account.&lt;/p&gt;
&lt;h2 id=&#34;next-steps&#34;&gt;Next Steps&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Familiarize yourself with &lt;a href=&#34;https://aws.github.io/amazon-genomics-cli/docs/concepts/&#34;&gt;Amazon Genomics CLI Concepts&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Try some &lt;a href=&#34;https://aws.github.io/amazon-genomics-cli/docs/tutorials/&#34;&gt;tutorials&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

      </description>
    </item>
    
    <item>
      <title>Docs: Workflows</title>
      <link>https://aws.github.io/amazon-genomics-cli/docs/concepts/workflows/</link>
      <pubDate>Tue, 31 Aug 2021 17:27:16 -0400</pubDate>
      
      <guid>https://aws.github.io/amazon-genomics-cli/docs/concepts/workflows/</guid>
      <description>
        
        
        &lt;p&gt;A Workflow is a series of steps or tasks to be executed as part of an analysis. To run a workflow using Amazon Genomics CLI, first you must
have deployed a context with suitable compute resources and with a workflow engine that can interpret the language of
the workflow.&lt;/p&gt;
&lt;h2 id=&#34;specification-in-project-yaml&#34;&gt;Specification in Project YAML&lt;/h2&gt;
&lt;p&gt;In an Amazon Genomics CLI project you can specify multiple workflows in a YAML map. The following example defines four WDL version 1.0
workflows. The &lt;code&gt;sourceURL&lt;/code&gt; property defines the location of the workflow file. If the location is relative then the
relevant file is assumed to be relative to the location of the project YAML file. Absolute file locations are also possible
although this may reduce the portability of a project if it is intended to be shared. Web URLS are supported as locations
of the workflow definition file.&lt;/p&gt;
&lt;p&gt;At this time Amazon Genomics CLI does &lt;em&gt;not&lt;/em&gt; resolve path aliases so, for example, a &lt;code&gt;sourceURL&lt;/code&gt; like &lt;code&gt;~/workflows/worklfow.wdl&lt;/code&gt; is not
supported.&lt;/p&gt;
&lt;p&gt;The &lt;code&gt;type&lt;/code&gt; object declares the &lt;code&gt;language&lt;/code&gt; of the workflow (eg, wdl, nextflow etc). The run a workflow there must be a
deployed &lt;a href=&#34;https://aws.github.io/amazon-genomics-cli/amazon-genomics-cli/docs/concepts/contexts/&#34;&gt;context&lt;/a&gt; with a matching language. The &lt;code&gt;version&lt;/code&gt; property refers to the workflow language version.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-yaml&#34; data-lang=&#34;yaml&#34;&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;workflows&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;  &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;hello&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;    &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;type&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;      &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;language&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;wdl&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;      &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;version&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#0000cf;font-weight:bold&#34;&gt;1.0&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;    &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;sourceURL&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;workflows/hello.wdl&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;  &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;read&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;    &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;type&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;      &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;language&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;wdl&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;      &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;version&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#0000cf;font-weight:bold&#34;&gt;1.0&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;    &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;sourceURL&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;workflows/read.wdl&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;  &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;words-with-vowels&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;    &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;type&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;      &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;language&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;wdl&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;      &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;version&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#0000cf;font-weight:bold&#34;&gt;1.0&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;    &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;sourceURL&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;workflows/words-with-vowels.wdl&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h3 id=&#34;multi-file-workflows&#34;&gt;Multi-file Workflows&lt;/h3&gt;
&lt;p&gt;Some workflow languages allow for the import of other workflows. To accommodate this, Amazon Genomics CLI supports using a directory as
a source URL. When a directory is supplied as the &lt;code&gt;sourceURL&lt;/code&gt;, Amazon Genomics CLI uses the following rules to determine the name of
the main workflow file and any supporting files:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;If the source URL resolves to a single non-zipped file, then the file is assumed to be a workflow file. Dependent resources (if any) are hardcoded in the file and must be resolvable by the Wes adapter or implicitly the workflow engine (e.g the Wes adapter figures out if the engine can resolve them and if not it resolves them itself).&lt;/li&gt;
&lt;li&gt;The source URL resolves to a zipped file (&lt;code&gt;.zip&lt;/code&gt;).  The zip may contain a manifest.
&lt;ol&gt;
&lt;li&gt;If the zip file does &lt;em&gt;not&lt;/em&gt; contain a file named &lt;code&gt;MANIFEST.json&lt;/code&gt;:
&lt;ol&gt;
&lt;li&gt;The zip file must contain one workflow file with the prefix main followed by the conventional suffix for the workflow, e.g. &lt;code&gt;main.wdl&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Any sub-workflows or tasks referenced by the main workflow must either be in the zip at the appropriate relative path or they must be referenced by URLs that are resolvable by the workflow engine. The WesAdapter may attempt to resolve them for the engine but this is a convenience and not required.&lt;/li&gt;
&lt;li&gt;Any variables not defined in the workflows must be provided in an inputs file that is referenced via the input argument in AGC. For workflow engines that support multiple input files an index suffix must be provided (e.g. inputs_a.json or inputs_1.json) if there is more than one inputs file.&lt;/li&gt;
&lt;li&gt;A workflow options file may be included and must be named with the options prefix followed by the conventional suffix of the workflow. The WesAdapter may chose to make use of this depending on the context of the workflow engine. It may also choose to pass this to the workflow engine or pass a modified copy to the workflow engine.&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;li&gt;If the zip file &lt;em&gt;does&lt;/em&gt; contain a manifest:
&lt;ol&gt;
&lt;li&gt;The manifest must contain a parameter called mainWorkflowURL. If it does then the value of the parameter must either be a URL, including the relevant protocol, or the name of a file present in the zip archive. Any subworkflows or tasks imported by the main workflow must either be referenced as URLs in the workflow or be present in the archive as described above.&lt;/li&gt;
&lt;li&gt;The manifest may contain an array of URLs to inputs files called inputFileURLs. The WesAdapter must decide if it should resolve these or let the workflow engine resolve them.&lt;/li&gt;
&lt;li&gt;The manifest may contain a URL reference to an options files name optionFileURL. The WesAdapter may choose to make use of this depending on the context of the workflow engine. It may also choose to pass this to the workflow engine or pass a modified copy to the workflow engine.&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;li&gt;If the source URL points to a directory then Amazon Genomics CLI will zip the directory before uploading it. The directory must follow the same conventions stated above for zip files.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;The following snippet demonstrates a possible declaration of a multi-file workflow:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-yaml&#34; data-lang=&#34;yaml&#34;&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;workflows&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;  &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;gatk4-data-processing&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;    &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;type&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;      &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;langauge&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;wdl&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;      &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;version&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#0000cf;font-weight:bold&#34;&gt;1.0&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;    &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;sourceURL&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;./gatk4-data-processing&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;The following snippet demonstrates a valid &lt;code&gt;MANIFEST.json&lt;/code&gt; file:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-json5&#34; data-lang=&#34;json5&#34;&gt;{
  &amp;quot;mainWorkflowURL&amp;quot;: &amp;quot;processing-for-variant-discovery-gatk4.wdl&amp;quot;,
  &amp;quot;inputFileURLs&amp;quot;: [
    &amp;quot;processing-for-variant-discovery-gatk4.hg38.wgs.inputs.json&amp;quot;
  ],
  &amp;quot;optionFileURL&amp;quot;: &amp;quot;options.json&amp;quot;
}
&lt;/code&gt;&lt;/pre&gt;&lt;h4 id=&#34;manifestjson-structure&#34;&gt;&lt;code&gt;MANIFEST.json&lt;/code&gt; Structure&lt;/h4&gt;
&lt;p&gt;The following keys are allowed in the &lt;code&gt;MANIFEST.json&lt;/code&gt;&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Key&lt;/th&gt;
&lt;th&gt;Required&lt;/th&gt;
&lt;th&gt;Purpose&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;&lt;code&gt;mainWorkflowURL&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;Yes&lt;/td&gt;
&lt;td&gt;Points to the workflow definition that is the main entrypoint of the workflow.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;code&gt;inputFileURLs&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;No&lt;/td&gt;
&lt;td&gt;An array of URLs to one or more JSON files that define the inputs to the workflow in the format expected by the relevant engine. inputFile URLs are resolved relative to the location of the &lt;code&gt;MANIFEST.json&lt;/code&gt;&lt;br/&gt;&lt;br/&gt; If multiple files are listed in inputFiles URLs, they will be passed to Cromwell in the order specified as workflowInput.json, workflowInput_1.json, &amp;hellip; , workflowInput_5.json. (Note: Cromwell only supports up to 5 input.json files). If there are any properties in common between the files, values in higher numbered files will take precedence. See: &lt;a href=&#34;https://cromwell.readthedocs.io/en/stable/api/RESTAPI/#submit-a-workflow-for-execution&#34; target=&#34;_blank&#34;&gt;Cromwell Docs&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;code&gt;optionFileURL&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;No&lt;/td&gt;
&lt;td&gt;A URL pointing to a JSON file containing engine options applied to a workflow instance. This is only used when engines run in &lt;a href=&#34;https://aws.github.io/amazon-genomics-cli/amazon-genomics-cli/docs/concepts/engines/#run-mode&#34;&gt;server mode&lt;/a&gt;. Options are interpreted by the engine and so must be in the form expected by the engine. The URL is resolved relative to the location of the &lt;code&gt;MANIFEST.json&lt;/code&gt;.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;code&gt;engineOptions&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;No&lt;/td&gt;
&lt;td&gt;A string appended to the command line of the engine&amp;rsquo;s run command. The string may contain any flags or parameters relevant to the engine of the context used to run the workflow. It should not be used to declare inputs (use &lt;code&gt;inputFileURLS&lt;/code&gt; instead). This parameter is only relevant for engines that run as &lt;a href=&#34;https://aws.github.io/amazon-genomics-cli/amazon-genomics-cli/docs/concepts/engines/#run-mode&#34;&gt;head processes&lt;/a&gt;.&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h2 id=&#34;engine-selection&#34;&gt;Engine Selection&lt;/h2&gt;
&lt;p&gt;When a workflow is submitted to run, Amazon Genomics CLI will match the workflow type with the map of engines in the context. For example,
if the workflow &lt;code&gt;type&lt;/code&gt; is &lt;code&gt;wdl&lt;/code&gt; Amazon Genomics CLI will attempt to identify and engine designated as the engine for that type. There
may only be one engine per type. If no suitable engine is found in the context an error will be reported.&lt;/p&gt;
&lt;h2 id=&#34;workflow-instances&#34;&gt;Workflow Instances&lt;/h2&gt;
&lt;p&gt;Any defined project workflow can be run multiple times. Each run is called an instance and assigned a unique instance ID.
When referring to a specific run of a workflow you should use the instance ID rather than the workflow name. It is possible
to submit multiple instances of the same workflow and to have these run concurrently.&lt;/p&gt;
&lt;h2 id=&#34;context&#34;&gt;Context&lt;/h2&gt;
&lt;p&gt;All workflows are coordinated by the engine, they are submitted to and executed in the context that is specified at submission time.
The workflow engine decides how the workflow is to be run and the context provides compute resources to run the workflow.&lt;/p&gt;
&lt;h2 id=&#34;commands&#34;&gt;Commands&lt;/h2&gt;
&lt;p&gt;A full reference of workflow commands is available &lt;a href=&#34;https://aws.github.io/amazon-genomics-cli/amazon-genomics-cli/docs/reference/agc_workflow/&#34;&gt;here&lt;/a&gt;&lt;/p&gt;
&lt;h3 id=&#34;run&#34;&gt;&lt;code&gt;run&lt;/code&gt;&lt;/h3&gt;
&lt;p&gt;Invoking &lt;code&gt;agc workflow run &amp;lt;workflow-name&amp;gt; -c &amp;lt;context-name&amp;gt;&lt;/code&gt; will run the named workflow in a specific context. The
unique ID of that workflow instance run will be returned if the submission is successful.&lt;/p&gt;
&lt;h4 id=&#34;workflow-arguments&#34;&gt;&lt;code&gt;workflow arguments&lt;/code&gt;&lt;/h4&gt;
&lt;p&gt;Workflow arguments such as inputs file can be specified at submission time using the &lt;code&gt;i&lt;/code&gt; or &lt;code&gt;--inputsFile&lt;/code&gt; flag. For
example:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-shell&#34; data-lang=&#34;shell&#34;&gt;agc workflow run my-workflow --inputsFile inputs.json
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;If the inputs file references local files, these will be synced with S3 and those files in S3 will be used when the workflow
instance is run.&lt;/p&gt;
&lt;h4 id=&#34;workflow-optionfileurl&#34;&gt;&lt;code&gt;workflow optionFileUrl&lt;/code&gt;&lt;/h4&gt;
&lt;p&gt;An additional optionFileUrl can be provided using the &amp;lsquo;o&amp;rsquo; or &amp;lsquo;&amp;ndash;optionFileUrl&amp;rsquo; flag. For example:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-shell&#34; data-lang=&#34;shell&#34;&gt;agc workflow run my-workflow --optionFileUrl optionFile.json
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;OptionFileUrl is only for use with engines that run in server mode (e.g. Cromwell).&lt;/p&gt;
&lt;p&gt;Example option.json&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-shell&#34; data-lang=&#34;shell&#34;&gt;&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;{&lt;/span&gt;
    &lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#34;option_name_1&amp;#34;&lt;/span&gt;: &lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#34;option value 1&amp;#34;&lt;/span&gt;,
    &lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#34;option_name_2&amp;#34;&lt;/span&gt;: &lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#34;option value 2&amp;#34;&lt;/span&gt;
&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h3 id=&#34;list&#34;&gt;&lt;code&gt;list&lt;/code&gt;&lt;/h3&gt;
&lt;p&gt;The &lt;code&gt;agc workflow list&lt;/code&gt; command can be used to list all workflows that are specified in the current project.&lt;/p&gt;
&lt;h3 id=&#34;describe&#34;&gt;&lt;code&gt;describe&lt;/code&gt;&lt;/h3&gt;
&lt;p&gt;The &lt;code&gt;agc workflow describe &amp;lt;workflow-name&amp;gt;&lt;/code&gt; command will return detailed information about the named workflow based on
the specification in the current project YAML file.&lt;/p&gt;
&lt;h3 id=&#34;status&#34;&gt;&lt;code&gt;status&lt;/code&gt;&lt;/h3&gt;
&lt;p&gt;To find out the status of workflow instances that are running, or have been run you can use the &lt;code&gt;agc workflow status&lt;/code&gt; command.
This will display details on 20 recent workflows from the project, to display more, or fewer you can use the &lt;code&gt;--limit number&lt;/code&gt; flag
where the &lt;code&gt;number&lt;/code&gt; may be as many as 1000.&lt;/p&gt;
&lt;p&gt;To list the status of workflows run or running in a specific context use the &lt;code&gt;--context-name&lt;/code&gt; flag and provide the name
of one of the contexts of the project.&lt;/p&gt;
&lt;p&gt;You may get the status of workflow instances by workflow name using the &lt;code&gt;--workflow-name&lt;/code&gt; flag.&lt;/p&gt;
&lt;p&gt;To display the status of a specific workflow instance you can provide the id of the desired workflow instance with the &lt;code&gt;--instance-id&lt;/code&gt; flag.&lt;/p&gt;
&lt;h3 id=&#34;stop&#34;&gt;&lt;code&gt;stop&lt;/code&gt;&lt;/h3&gt;
&lt;p&gt;A running workflow &lt;em&gt;instance&lt;/em&gt; can be stopped at any time using the &lt;code&gt;agc workflow stop &amp;lt;instance-id&amp;gt;&lt;/code&gt; command. When issued,
Amazon Genomics CLI will look up the appropriate context and engine using the &lt;code&gt;instance-id&lt;/code&gt; of the workflow and instruct the engine to
stop the workflow. What happens next depends on the actual workflow engine. For example, in the case of the Cromwell WDL
engine, any currently executing tasks will halt, any pending tasks will be removed from the work queue and no further
tasks will be started for that workflow instance.&lt;/p&gt;
&lt;h3 id=&#34;output&#34;&gt;&lt;code&gt;output&lt;/code&gt;&lt;/h3&gt;
&lt;p&gt;You can obtain the output (if any) of a completed workflow run using the output command and supplying the workflow run
id. Typically, this is useful for locating the files produced by a workflow, although the actual output generated depends on the workflow
specification and engine.&lt;/p&gt;
&lt;p&gt;If the workflow declares outputs you may also obtain these using the command:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-shell&#34; data-lang=&#34;shell&#34;&gt;agc workflow output &amp;lt;workflow_run_id&amp;gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;The following is an example of output from the &amp;ldquo;CramToBam&amp;rdquo; workflow run in a context using the Cromwell engine.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-shell&#34; data-lang=&#34;shell&#34;&gt;OUTPUT	id	aaba95e8-7512-48c3-9a61-1fd837ff6099
OUTPUT	outputs.CramToBamFlow.outputBai	s3://agc-123456789012-us-east-1/project/GATK/userid/mrschre4GqyMA/context/spotCtx/cromwell-execution/CramToBamFlow/aaba95e8-7512-48c3-9a61-1fd837ff6099/call-CramToBamTask/NA12878.bai
OUTPUT	outputs.CramToBamFlow.outputBam	s3://agc-123456789012-us-east-1/project/GATK/userid/mrschre4GqyMA/context/spotCtx/cromwell-execution/CramToBamFlow/aaba95e8-7512-48c3-9a61-1fd837ff6099/call-CramToBamTask/NA12878.bam
OUTPUT	outputs.CramToBamFlow.validation_report	s3://agc-123456789012-us-east-1/project/GATK/userid/mrschre4GqyMA/context/spotCtx/cromwell-execution/CramToBamFlow/aaba95e8-7512-48c3-9a61-1fd837ff6099/call-ValidateSamFile/NA12878.validation_report
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h2 id=&#34;cost&#34;&gt;Cost&lt;/h2&gt;
&lt;p&gt;Your account will be charged based on actual resource usage including compute time, storage, data transfer charges etc.
The resources used will depend on the resources requested in your workflow definition as interpreted by the workflow engine
according the resources made available in the context in which the workflow is run. If a spot context is used then the costs
of the spot instances will be determined by the rules governing spot instance charges.&lt;/p&gt;
&lt;h3 id=&#34;tags&#34;&gt;Tags&lt;/h3&gt;
&lt;p&gt;Resources used by Amazon Genomics CLI are tagged including the username, project name and the context name. Currently, tagging is &lt;em&gt;not&lt;/em&gt;
possible at the level of an individual workflow.&lt;/p&gt;

      </description>
    </item>
    
    <item>
      <title>Docs: Engines</title>
      <link>https://aws.github.io/amazon-genomics-cli/docs/concepts/engines/</link>
      <pubDate>Tue, 31 Aug 2021 17:28:39 -0400</pubDate>
      
      <guid>https://aws.github.io/amazon-genomics-cli/docs/concepts/engines/</guid>
      <description>
        
        
        &lt;p&gt;A workflow engine is defined as part of a &lt;a href=&#34;https://aws.github.io/amazon-genomics-cli/amazon-genomics-cli/docs/concepts/contexts/&#34;&gt;context&lt;/a&gt;. A context is currently limited to one workflow engine. The workflow engine will manage the execution of any &lt;a href=&#34;https://aws.github.io/amazon-genomics-cli/amazon-genomics-cli/docs/concepts/workflows/&#34;&gt;workflows&lt;/a&gt; submitted
by Amazon Genomics CLI. When the context is deployed, an endpoint will be made available
to Amazon Genomics CLI through which it will submit workflows and workflow commands to the engine according to the WES API specification.&lt;/p&gt;
&lt;h2 id=&#34;supported-engines-and-workflow-languages&#34;&gt;Supported Engines and Workflow Languages&lt;/h2&gt;
&lt;p&gt;Currently, Amazon Genomics CLI&amp;rsquo;s officially supported engines can be used to run the following workflows:&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Engine&lt;/th&gt;
&lt;th&gt;Language&lt;/th&gt;
&lt;th&gt;Language Versions&lt;/th&gt;
&lt;th&gt;Run Mode&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href=&#34;https://cromwell.readthedocs.io/en/stable/&#34;&gt;Cromwell&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href=&#34;https://openwdl.org&#34;&gt;WDL&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;All versions up to 1.0&lt;/td&gt;
&lt;td&gt;Server&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href=&#34;https://www.nextflow.io&#34;&gt;Nextflow&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href=&#34;https://www.nextflow.io/docs/latest/script.html&#34;&gt;Nextflow DSL&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Standard and DSL 2&lt;/td&gt;
&lt;td&gt;Head Process&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href=&#34;https://miniwdl.readthedocs.io/en/latest/&#34;&gt;miniwdl&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href=&#34;https://openwdl.org&#34;&gt;WDL&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href=&#34;https://miniwdl.readthedocs.io/en/latest/runner_reference.html?highlight=errata#wdl-interoperability&#34;&gt;documented here&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Head Process&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href=&#34;https://snakemake.readthedocs.io/en/stable/&#34;&gt;Snakemake&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href=&#34;https://snakemake.readthedocs.io/en/stable/snakefiles/writing_snakefiles.html&#34;&gt;Snakemake&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;All versions&lt;/td&gt;
&lt;td&gt;Head Process&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href=&#34;http://toil.ucsc-cgl.org/&#34;&gt;Toil&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href=&#34;https://www.commonwl.org/&#34;&gt;CWL&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;All versions up to 1.2&lt;/td&gt;
&lt;td&gt;Server&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;Overtime we plan to add additional engine and language support and provide the ability for third party developers to
develop engine plugins.&lt;/p&gt;
&lt;h3 id=&#34;run-mode&#34;&gt;Run Mode&lt;/h3&gt;
&lt;h4 id=&#34;server&#34;&gt;Server&lt;/h4&gt;
&lt;p&gt;In server mode the engine runs as a long-running process that exists for the lifetime of the context. All workflow instances sent to the context are handled by that server. The server resides on on-demand instances to prevent Spot interruption even if the workflow tasks are run on Spot instances&lt;/p&gt;
&lt;h4 id=&#34;head-process&#34;&gt;Head Process&lt;/h4&gt;
&lt;p&gt;Head process engines are run when a workflow is submitted, manage a single workflow and only run for the lifetime of the workflow. If multiple workflows are submitted to a context in parallel then multiple head processes are spawned. The head processes always run on on-demand resources to prevent Spot interruption even if the workflow tasks are run on Spot instances.&lt;/p&gt;
&lt;h2 id=&#34;engine-definition&#34;&gt;Engine Definition&lt;/h2&gt;
&lt;p&gt;An engine is defined within a &lt;code&gt;context&lt;/code&gt; definition of the &lt;a href=&#34;https://aws.github.io/amazon-genomics-cli/amazon-genomics-cli/docs/concepts/projects/#project-file-structure&#34;&gt;project YAML file&lt;/a&gt; file as a map. For example, the following snippet
defines a WDL engine of type &lt;code&gt;cromwell&lt;/code&gt; as part of the context named &lt;code&gt;onDemandCtx&lt;/code&gt;. There may be one engine defined
for each supported language.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-yaml&#34; data-lang=&#34;yaml&#34;&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;contexts&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;  &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;onDemandCtx&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;    &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;requestSpotInstances&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;false&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;    &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;engines&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;      &lt;/span&gt;- &lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;type&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;wdl&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;        &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;engine&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;cromwell&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h2 id=&#34;commands&#34;&gt;Commands&lt;/h2&gt;
&lt;p&gt;There are no commands specific to engines. Engines are &lt;a href=&#34;https://aws.github.io/amazon-genomics-cli/amazon-genomics-cli/docs/concepts/contexts/#deploy&#34;&gt;deployed&lt;/a&gt; along with contexts by the &lt;a href=&#34;https://aws.github.io/amazon-genomics-cli/amazon-genomics-cli/docs/concepts/contexts/#context-commands&#34;&gt;&lt;code&gt;context&lt;/code&gt; commands&lt;/a&gt; and workflows
are run using the &lt;a href=&#34;https://aws.github.io/amazon-genomics-cli/amazon-genomics-cli/docs/concepts/workflows/#commands&#34;&gt;&lt;code&gt;workflow&lt;/code&gt; commands&lt;/a&gt;.&lt;/p&gt;
&lt;h2 id=&#34;costs&#34;&gt;Costs&lt;/h2&gt;
&lt;p&gt;The costs associated with an engine depend on the actual infrastructure required by the engine. In the case of the Cromwell,
the engine runs in &amp;ldquo;server&amp;rdquo; mode as an &lt;a href=&#34;https://docs.aws.amazon.com/AmazonECS/latest/userguide/index.html&#34;&gt;AWS ECS Fargate&lt;/a&gt; container using an
&lt;a href=&#34;https://docs.aws.amazon.com/efs/latest/ug/index.html&#34;&gt;Amazon Elastic File System&lt;/a&gt; for metadata storage. The container
will be running for the entire time the context is deployed, even when no workflows are running. To avoid this cost we
recommend destroying the context when it is not needed. The Nextflow engine runs as a single batch job per workflow instance
and is only running when workflows are running.&lt;/p&gt;
&lt;p&gt;In both cases a serverless WES API endpoint is deployed through &lt;a href=&#34;https://docs.aws.amazon.com/apigatewayv2/latest/api-reference/&#34;&gt;Amazon API Gateway&lt;/a&gt; to act as the interface between Amazon Genomics CLI and
the engine.&lt;/p&gt;
&lt;h3 id=&#34;tags&#34;&gt;Tags&lt;/h3&gt;
&lt;p&gt;Being part of a context, engine related infrastructure is &lt;a href=&#34;https://aws.github.io/amazon-genomics-cli/amazon-genomics-cli/docs/concepts/namespaces/#tags&#34;&gt;tagged&lt;/a&gt; with the context name, username and project name. These tags may be used to help
differentiate costs.&lt;/p&gt;
&lt;h2 id=&#34;technical-details&#34;&gt;Technical Details&lt;/h2&gt;
&lt;p&gt;Supported engines are currently deployed with configurations that allow them to make use of files in S3 and submit workflows
as jobs to AWS Batch. Because the current generation of engines we support do not directly support the &lt;a href=&#34;https://ga4gh.github.io/workflow-execution-service-schemas/docs/&#34;&gt;WES API&lt;/a&gt;, adapters
are deployed as Fargate container tasks. AWS API Gateway is used to provide a gateway between Amazon Genomics CLI and the WES adapters.&lt;/p&gt;
&lt;p&gt;When &lt;code&gt;workflow&lt;/code&gt; commands are issued on Amazon Genomics CLI, it will send WES API calls to the appropriate endpoint. The adapter mapped
to that endpoint will then translate the WES command and either send the command to the engines REST API for Cromwell, or
spawn a Nextflow engine task and submit the workflow with that task. At this point the engine is responsible for creating
controlling and destroying the resources that will be used for task execution.&lt;/p&gt;

      </description>
    </item>
    
    <item>
      <title>Docs: Logs</title>
      <link>https://aws.github.io/amazon-genomics-cli/docs/concepts/logs/</link>
      <pubDate>Tue, 31 Aug 2021 17:30:49 -0400</pubDate>
      
      <guid>https://aws.github.io/amazon-genomics-cli/docs/concepts/logs/</guid>
      <description>
        
        
        &lt;p&gt;The infrastructure deployed by Amazon Genomics CLI records logs for many activities including the workflow runs, workflow
engines as well as infrastructure. The logs are recorded in CloudWatch but are accessible through the CLI.&lt;/p&gt;
&lt;p&gt;When debugging or reviewing a workflow run, the engine logs and workflow logs will be the most useful. For diagnosing
infrastructure or access problems the adapter logs and access logs will be informative.&lt;/p&gt;
&lt;h2 id=&#34;engine-logs&#34;&gt;Engine Logs&lt;/h2&gt;
&lt;p&gt;Engine logs are the logs produced by a workflow engine in a context. The logs produced depend on the engine implementation.
Engines that run in &amp;ldquo;server&amp;rdquo; mode, such as Cromwell, produce a single log for the lifetime of the context that encompass
all workflows run through that engine. Engines that run as &amp;ldquo;head node&amp;rdquo; will produce discrete engine logs for each run.&lt;/p&gt;
&lt;h2 id=&#34;workflow-logs&#34;&gt;Workflow Logs&lt;/h2&gt;
&lt;p&gt;Workflow logs are the aggregate logs for all steps in a workflow run (instance). Any workflow steps that are retrieved from
a call cache are not run so there will be no workflow logs for these steps. Consulting the engine logs may show details of
the call cache. If a previously successful workflow is run with no changes in inputs or parameters it may have all steps
retrieved from the cache in which case there will be no workflow logs although the workflow instance will be marked as a
success and engine logs will be produced. The outputs for a completely cached workflow will also be available.&lt;/p&gt;
&lt;h2 id=&#34;adapter-logs&#34;&gt;Adapter Logs&lt;/h2&gt;
&lt;p&gt;Adapter logs consist of any logs produced by a WES adapter for a workflow engine. They can reveal information such as
the WES API calls that are made to the engine by Amazon Genomics CLI and any errors that may have occurred.&lt;/p&gt;
&lt;h2 id=&#34;access-logs&#34;&gt;Access Logs&lt;/h2&gt;
&lt;p&gt;Amazon Genomics CLI talks to an engine via
API Gateway which routes to the WES adapter. If an expected call does not appear in the adapter logs it may have been
blocked or incorrectly routed in the API Gateway. The API Gateway access logs may be informative in this case.&lt;/p&gt;
&lt;h2 id=&#34;commands&#34;&gt;Commands&lt;/h2&gt;
&lt;p&gt;A full reference of Amazon Genomics CLI &lt;code&gt;logs&lt;/code&gt; commands are available &lt;a href=&#34;https://aws.github.io/amazon-genomics-cli/amazon-genomics-cli/docs/reference/agc_logs/&#34;&gt;here&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&#34;costs&#34;&gt;Costs&lt;/h2&gt;
&lt;p&gt;Amazon Genomics CLI logs are stored in CloudWatch and accessed using the CloudWatch APIs. Standard CloudWatch charges apply.
All logs are retained permanently, even after a context is destroyed and other Amazon Genomics CLI infrastructure is
removed from an account. If they are no longer needed they may be removed using the AWS Console or the AWS CLI.&lt;/p&gt;

      </description>
    </item>
    
    <item>
      <title>Docs: Namespaces</title>
      <link>https://aws.github.io/amazon-genomics-cli/docs/concepts/namespaces/</link>
      <pubDate>Tue, 31 Aug 2021 17:26:20 -0400</pubDate>
      
      <guid>https://aws.github.io/amazon-genomics-cli/docs/concepts/namespaces/</guid>
      <description>
        
        
        &lt;p&gt;Amazon Genomics CLI uses namespacing to prevent conflicts when there are multiple &lt;a href=&#34;https://aws.github.io/amazon-genomics-cli/amazon-genomics-cli/docs/concepts/users/&#34;&gt;users&lt;/a&gt;, &lt;a href=&#34;https://aws.github.io/amazon-genomics-cli/amazon-genomics-cli/docs/concepts/contexts/&#34;&gt;contexts&lt;/a&gt;, and &lt;a href=&#34;https://aws.github.io/amazon-genomics-cli/amazon-genomics-cli/docs/concepts/projects/&#34;&gt;projects&lt;/a&gt; in the same AWS account and region.&lt;/p&gt;
&lt;p&gt;In any given account and region, an individual user may have many projects with many deployed contexts all running at the
same time without conflict as long as:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;No other user with the same Amazon Genomics CLI username exists in the same account and region.&lt;/li&gt;
&lt;li&gt;All projects, used by that user, have a unique name.&lt;/li&gt;
&lt;li&gt;All contexts within a project have a unique name.&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;shared-project-definitions&#34;&gt;Shared Project Definitions&lt;/h2&gt;
&lt;p&gt;Project definitions can be shared between users. A simple way to achieve this is by putting the project YAML file and associated
workflow definitions into a source control system like Git. If two users in the same account and region start contexts
from the same project definition, these contexts are discrete and include the Amazon Genomics CLI username in the names of their respective
infrastructures.&lt;/p&gt;
&lt;p&gt;Therefore, the following combination are allowed:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;userA -uses-&amp;gt; ProjectA -to-deploy-&amp;gt; ContextA
userB -uses-&amp;gt; ProjectA -to-deploy-&amp;gt; ContextA
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;In the above example it is useful to think of these as two instances of Context A. Both share the same definition but the
instances do not have the same infrastructure.&lt;/p&gt;
&lt;h2 id=&#34;tags&#34;&gt;Tags&lt;/h2&gt;
&lt;p&gt;All Amazon Genomics CLI infrastructure is tagged with the &lt;code&gt;application-name&lt;/code&gt; key and a value of &lt;code&gt;agc&lt;/code&gt;
Aside from the core account infrastructure, all deployed infrastructure is tagged with the following key value pairs:&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Key&lt;/th&gt;
&lt;th&gt;Value&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;agc-project&lt;/td&gt;
&lt;td&gt;The name of the project in which the context is defined&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;agc-user-id&lt;/td&gt;
&lt;td&gt;The unique username&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;agc-user-email&lt;/td&gt;
&lt;td&gt;The users email&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;agc-context&lt;/td&gt;
&lt;td&gt;The name of the context in which the infrastructure is deployed&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;agc-engine&lt;/td&gt;
&lt;td&gt;The name of the engine being run in the context&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;agc-engine-type&lt;/td&gt;
&lt;td&gt;The workflow language run by the engine&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;

      </description>
    </item>
    
    <item>
      <title>Docs: agc</title>
      <link>https://aws.github.io/amazon-genomics-cli/docs/reference/agc/</link>
      <pubDate>Mon, 06 May 2024 18:32:37 +0000</pubDate>
      
      <guid>https://aws.github.io/amazon-genomics-cli/docs/reference/agc/</guid>
      <description>
        
        
        &lt;h2 id=&#34;agc&#34;&gt;agc&lt;/h2&gt;
&lt;p&gt;üß¨ Launch and manage genomics workloads on AWS.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;agc [flags]
&lt;/code&gt;&lt;/pre&gt;&lt;h3 id=&#34;examples&#34;&gt;Examples&lt;/h3&gt;
&lt;pre&gt;&lt;code&gt;
  Displays the help menu for the specified sub-command.
  /code $ agc account --help
&lt;/code&gt;&lt;/pre&gt;&lt;h3 id=&#34;options&#34;&gt;Options&lt;/h3&gt;
&lt;pre&gt;&lt;code&gt;      --format string   Format option for output. Valid options are: text, table, json
  -h, --help            help for agc
      --silent          Suppresses all diagnostic information.
  -v, --verbose         Display verbose diagnostic information.
      --version         version for agc
&lt;/code&gt;&lt;/pre&gt;&lt;h3 id=&#34;see-also&#34;&gt;SEE ALSO&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://aws.github.io/amazon-genomics-cli/amazon-genomics-cli/docs/reference/agc_account/&#34;&gt;agc account&lt;/a&gt;	 - Commands for AWS account setup.
Install or remove AGC from your account.&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://aws.github.io/amazon-genomics-cli/amazon-genomics-cli/docs/reference/agc_completion/&#34;&gt;agc completion&lt;/a&gt;	 - generate the autocompletion script for the specified shell&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://aws.github.io/amazon-genomics-cli/amazon-genomics-cli/docs/reference/agc_configure/&#34;&gt;agc configure&lt;/a&gt;	 - Commands for configuration.
Configuration is stored per user.&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://aws.github.io/amazon-genomics-cli/amazon-genomics-cli/docs/reference/agc_context/&#34;&gt;agc context&lt;/a&gt;	 - Commands for contexts.
Contexts specify workflow engines and computational fleets to use when running a workflow.&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://aws.github.io/amazon-genomics-cli/amazon-genomics-cli/docs/reference/agc_logs/&#34;&gt;agc logs&lt;/a&gt;	 - Commands for various logs.&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://aws.github.io/amazon-genomics-cli/amazon-genomics-cli/docs/reference/agc_project/&#34;&gt;agc project&lt;/a&gt;	 - Commands to interact with projects.&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://aws.github.io/amazon-genomics-cli/amazon-genomics-cli/docs/reference/agc_workflow/&#34;&gt;agc workflow&lt;/a&gt;	 - Commands for workflows.
Workflows are potentially-dynamic graphs of computational tasks to execute.&lt;/li&gt;
&lt;/ul&gt;

      </description>
    </item>
    
    <item>
      <title>Docs: agc account</title>
      <link>https://aws.github.io/amazon-genomics-cli/docs/reference/agc_account/</link>
      <pubDate>Mon, 06 May 2024 18:32:37 +0000</pubDate>
      
      <guid>https://aws.github.io/amazon-genomics-cli/docs/reference/agc_account/</guid>
      <description>
        
        
        &lt;h2 id=&#34;agc-account&#34;&gt;agc account&lt;/h2&gt;
&lt;p&gt;Commands for AWS account setup.
Install or remove AGC from your account.&lt;/p&gt;
&lt;h3 id=&#34;synopsis&#34;&gt;Synopsis&lt;/h3&gt;
&lt;p&gt;Commands for AWS account setup.
AGC requires core infrastructure to be running in an account to function.
These commands should be used to install or remove AGC from your AWS account.&lt;/p&gt;
&lt;h3 id=&#34;options&#34;&gt;Options&lt;/h3&gt;
&lt;pre&gt;&lt;code&gt;  -p, --awsProfile string   Use the provided AWS CLI profile.
  -h, --help                help for account
&lt;/code&gt;&lt;/pre&gt;&lt;h3 id=&#34;options-inherited-from-parent-commands&#34;&gt;Options inherited from parent commands&lt;/h3&gt;
&lt;pre&gt;&lt;code&gt;      --format string   Format option for output. Valid options are: text, table, json
      --silent          Suppresses all diagnostic information.
  -v, --verbose         Display verbose diagnostic information.
&lt;/code&gt;&lt;/pre&gt;&lt;h3 id=&#34;see-also&#34;&gt;SEE ALSO&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://aws.github.io/amazon-genomics-cli/amazon-genomics-cli/docs/reference/agc/&#34;&gt;agc&lt;/a&gt;	 - üß¨ Launch and manage genomics workloads on AWS.&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://aws.github.io/amazon-genomics-cli/amazon-genomics-cli/docs/reference/agc_account_activate/&#34;&gt;agc account activate&lt;/a&gt;	 - Activate AGC in an AWS account.&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://aws.github.io/amazon-genomics-cli/amazon-genomics-cli/docs/reference/agc_account_deactivate/&#34;&gt;agc account deactivate&lt;/a&gt;	 - Deactivate AGC in an AWS account.&lt;/li&gt;
&lt;/ul&gt;

      </description>
    </item>
    
    <item>
      <title>Docs: agc account activate</title>
      <link>https://aws.github.io/amazon-genomics-cli/docs/reference/agc_account_activate/</link>
      <pubDate>Mon, 06 May 2024 18:32:37 +0000</pubDate>
      
      <guid>https://aws.github.io/amazon-genomics-cli/docs/reference/agc_account_activate/</guid>
      <description>
        
        
        &lt;h2 id=&#34;agc-account-activate&#34;&gt;agc account activate&lt;/h2&gt;
&lt;p&gt;Activate AGC in an AWS account.&lt;/p&gt;
&lt;h3 id=&#34;synopsis&#34;&gt;Synopsis&lt;/h3&gt;
&lt;p&gt;Activate AGC in an AWS account.
AGC will use your default AWS credentials to deploy all AWS resources
it needs to that account and region.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;agc account activate [flags]
&lt;/code&gt;&lt;/pre&gt;&lt;h3 id=&#34;examples&#34;&gt;Examples&lt;/h3&gt;
&lt;pre&gt;&lt;code&gt;
Activate AGC in your AWS account with a custom S3 bucket and VPC.
/code $ agc account activate --bucket my-custom-bucket --vpc my-vpc-id
&lt;/code&gt;&lt;/pre&gt;&lt;h3 id=&#34;options&#34;&gt;Options&lt;/h3&gt;
&lt;pre&gt;&lt;code&gt;      --ami string            The AMI that will be used by all workflow compute environments deployed in all contexts.
      --bucket string         The name of an S3 bucket that AGC will use to store its data.
                              An autogenerated name will be used if not specified. A new bucket will be created if the bucket does not exist.
  -h, --help                  help for activate
      --subnets strings       The list of private subnet IDs to use when specifying a VPC to run in. May only be used with the 
                              &#39;--vpc&#39; flag. If not supplied then all private subnets of a VPC will be used as possible targets of compute infrastructure.
                              Each subnet must have access to AWS service endpoints e.g. using VPC Gateway Endpoints or via a route to the public internet.
                              Subnet names may be a comma separated list or supplied as repeated flags. (e.g. &#39;--subnets subnet-1234 --subnets subnet-2345, subnet-3456&#39;)
                              
      --tags stringToString   A list of comma separated tags to be applied to all AGC resources in this account
                              (e.g. --tags &amp;quot;k1=v1&amp;quot;,&amp;quot;k2=v2&amp;quot;). Each key-value pair must be quoted as shown in the example,
                              otherwise the parsing will fail. (default [])
      --usePublicSubnets      Do not create a NAT gateway or VPC endpoints, to lower operating costs. 
                              You must enable the usePublicSubnets option in your project context if you use this flag.
      --vpc string            The ID of a VPC that AGC will run in. 
                              A new VPC will be created if not specified.
&lt;/code&gt;&lt;/pre&gt;&lt;h3 id=&#34;options-inherited-from-parent-commands&#34;&gt;Options inherited from parent commands&lt;/h3&gt;
&lt;pre&gt;&lt;code&gt;  -p, --awsProfile string   Use the provided AWS CLI profile.
      --format string       Format option for output. Valid options are: text, table, json
      --silent              Suppresses all diagnostic information.
  -v, --verbose             Display verbose diagnostic information.
&lt;/code&gt;&lt;/pre&gt;&lt;h3 id=&#34;see-also&#34;&gt;SEE ALSO&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://aws.github.io/amazon-genomics-cli/amazon-genomics-cli/docs/reference/agc_account/&#34;&gt;agc account&lt;/a&gt;	 - Commands for AWS account setup.
Install or remove AGC from your account.&lt;/li&gt;
&lt;/ul&gt;

      </description>
    </item>
    
    <item>
      <title>Docs: agc account deactivate</title>
      <link>https://aws.github.io/amazon-genomics-cli/docs/reference/agc_account_deactivate/</link>
      <pubDate>Mon, 06 May 2024 18:32:37 +0000</pubDate>
      
      <guid>https://aws.github.io/amazon-genomics-cli/docs/reference/agc_account_deactivate/</guid>
      <description>
        
        
        &lt;h2 id=&#34;agc-account-deactivate&#34;&gt;agc account deactivate&lt;/h2&gt;
&lt;p&gt;Deactivate AGC in an AWS account.&lt;/p&gt;
&lt;h3 id=&#34;synopsis&#34;&gt;Synopsis&lt;/h3&gt;
&lt;p&gt;Deactivate AGC in an AWS account.
AGC will use your default AWS credentials to remove all core AWS resources
it has created in that account and region. Deactivation may take up to 5 minutes to complete and return.
Buckets and logs will be preserved.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;agc account deactivate [flags]
&lt;/code&gt;&lt;/pre&gt;&lt;h3 id=&#34;examples&#34;&gt;Examples&lt;/h3&gt;
&lt;pre&gt;&lt;code&gt;
Deactivate AGC in your AWS account.
/code $ agc account deactivate
&lt;/code&gt;&lt;/pre&gt;&lt;h3 id=&#34;options&#34;&gt;Options&lt;/h3&gt;
&lt;pre&gt;&lt;code&gt;  -f, --force   Force account deactivation by removing all resources associated with AGC.
                This includes project and context resources, even if they are running workflows.
                If not specified, only the core resources will be deleted if possible.
  -h, --help    help for deactivate
&lt;/code&gt;&lt;/pre&gt;&lt;h3 id=&#34;options-inherited-from-parent-commands&#34;&gt;Options inherited from parent commands&lt;/h3&gt;
&lt;pre&gt;&lt;code&gt;  -p, --awsProfile string   Use the provided AWS CLI profile.
      --format string       Format option for output. Valid options are: text, table, json
      --silent              Suppresses all diagnostic information.
  -v, --verbose             Display verbose diagnostic information.
&lt;/code&gt;&lt;/pre&gt;&lt;h3 id=&#34;see-also&#34;&gt;SEE ALSO&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://aws.github.io/amazon-genomics-cli/amazon-genomics-cli/docs/reference/agc_account/&#34;&gt;agc account&lt;/a&gt;	 - Commands for AWS account setup.
Install or remove AGC from your account.&lt;/li&gt;
&lt;/ul&gt;

      </description>
    </item>
    
    <item>
      <title>Docs: agc completion</title>
      <link>https://aws.github.io/amazon-genomics-cli/docs/reference/agc_completion/</link>
      <pubDate>Mon, 06 May 2024 18:32:37 +0000</pubDate>
      
      <guid>https://aws.github.io/amazon-genomics-cli/docs/reference/agc_completion/</guid>
      <description>
        
        
        &lt;h2 id=&#34;agc-completion&#34;&gt;agc completion&lt;/h2&gt;
&lt;p&gt;generate the autocompletion script for the specified shell&lt;/p&gt;
&lt;h3 id=&#34;synopsis&#34;&gt;Synopsis&lt;/h3&gt;
&lt;p&gt;Generate the autocompletion script for agc for the specified shell.
See each sub-command&amp;rsquo;s help for details on how to use the generated script.&lt;/p&gt;
&lt;h3 id=&#34;options&#34;&gt;Options&lt;/h3&gt;
&lt;pre&gt;&lt;code&gt;  -h, --help   help for completion
&lt;/code&gt;&lt;/pre&gt;&lt;h3 id=&#34;options-inherited-from-parent-commands&#34;&gt;Options inherited from parent commands&lt;/h3&gt;
&lt;pre&gt;&lt;code&gt;      --format string   Format option for output. Valid options are: text, table, json
      --silent          Suppresses all diagnostic information.
  -v, --verbose         Display verbose diagnostic information.
&lt;/code&gt;&lt;/pre&gt;&lt;h3 id=&#34;see-also&#34;&gt;SEE ALSO&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://aws.github.io/amazon-genomics-cli/amazon-genomics-cli/docs/reference/agc/&#34;&gt;agc&lt;/a&gt;	 - üß¨ Launch and manage genomics workloads on AWS.&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://aws.github.io/amazon-genomics-cli/amazon-genomics-cli/docs/reference/agc_completion_bash/&#34;&gt;agc completion bash&lt;/a&gt;	 - generate the autocompletion script for bash&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://aws.github.io/amazon-genomics-cli/amazon-genomics-cli/docs/reference/agc_completion_fish/&#34;&gt;agc completion fish&lt;/a&gt;	 - generate the autocompletion script for fish&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://aws.github.io/amazon-genomics-cli/amazon-genomics-cli/docs/reference/agc_completion_powershell/&#34;&gt;agc completion powershell&lt;/a&gt;	 - generate the autocompletion script for powershell&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://aws.github.io/amazon-genomics-cli/amazon-genomics-cli/docs/reference/agc_completion_zsh/&#34;&gt;agc completion zsh&lt;/a&gt;	 - generate the autocompletion script for zsh&lt;/li&gt;
&lt;/ul&gt;

      </description>
    </item>
    
    <item>
      <title>Docs: agc completion bash</title>
      <link>https://aws.github.io/amazon-genomics-cli/docs/reference/agc_completion_bash/</link>
      <pubDate>Mon, 06 May 2024 18:32:37 +0000</pubDate>
      
      <guid>https://aws.github.io/amazon-genomics-cli/docs/reference/agc_completion_bash/</guid>
      <description>
        
        
        &lt;h2 id=&#34;agc-completion-bash&#34;&gt;agc completion bash&lt;/h2&gt;
&lt;p&gt;generate the autocompletion script for bash&lt;/p&gt;
&lt;h3 id=&#34;synopsis&#34;&gt;Synopsis&lt;/h3&gt;
&lt;p&gt;Generate the autocompletion script for the bash shell.&lt;/p&gt;
&lt;p&gt;This script depends on the &amp;lsquo;bash-completion&amp;rsquo; package.
If it is not installed already, you can install it via your OS&amp;rsquo;s package manager.&lt;/p&gt;
&lt;p&gt;To load completions in your current shell session:
$ source &amp;lt;(agc completion bash)&lt;/p&gt;
&lt;p&gt;To load completions for every new session, execute once:
Linux:
$ agc completion bash &amp;gt; /etc/bash_completion.d/agc
MacOS:
$ agc completion bash &amp;gt; /usr/local/etc/bash_completion.d/agc&lt;/p&gt;
&lt;p&gt;You will need to start a new shell for this setup to take effect.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;agc completion bash
&lt;/code&gt;&lt;/pre&gt;&lt;h3 id=&#34;options&#34;&gt;Options&lt;/h3&gt;
&lt;pre&gt;&lt;code&gt;  -h, --help              help for bash
      --no-descriptions   disable completion descriptions
&lt;/code&gt;&lt;/pre&gt;&lt;h3 id=&#34;options-inherited-from-parent-commands&#34;&gt;Options inherited from parent commands&lt;/h3&gt;
&lt;pre&gt;&lt;code&gt;      --format string   Format option for output. Valid options are: text, table, json
      --silent          Suppresses all diagnostic information.
  -v, --verbose         Display verbose diagnostic information.
&lt;/code&gt;&lt;/pre&gt;&lt;h3 id=&#34;see-also&#34;&gt;SEE ALSO&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://aws.github.io/amazon-genomics-cli/amazon-genomics-cli/docs/reference/agc_completion/&#34;&gt;agc completion&lt;/a&gt;	 - generate the autocompletion script for the specified shell&lt;/li&gt;
&lt;/ul&gt;

      </description>
    </item>
    
    <item>
      <title>Docs: agc completion fish</title>
      <link>https://aws.github.io/amazon-genomics-cli/docs/reference/agc_completion_fish/</link>
      <pubDate>Mon, 06 May 2024 18:32:37 +0000</pubDate>
      
      <guid>https://aws.github.io/amazon-genomics-cli/docs/reference/agc_completion_fish/</guid>
      <description>
        
        
        &lt;h2 id=&#34;agc-completion-fish&#34;&gt;agc completion fish&lt;/h2&gt;
&lt;p&gt;generate the autocompletion script for fish&lt;/p&gt;
&lt;h3 id=&#34;synopsis&#34;&gt;Synopsis&lt;/h3&gt;
&lt;p&gt;Generate the autocompletion script for the fish shell.&lt;/p&gt;
&lt;p&gt;To load completions in your current shell session:
$ agc completion fish | source&lt;/p&gt;
&lt;p&gt;To load completions for every new session, execute once:
$ agc completion fish &amp;gt; ~/.config/fish/completions/agc.fish&lt;/p&gt;
&lt;p&gt;You will need to start a new shell for this setup to take effect.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;agc completion fish [flags]
&lt;/code&gt;&lt;/pre&gt;&lt;h3 id=&#34;options&#34;&gt;Options&lt;/h3&gt;
&lt;pre&gt;&lt;code&gt;  -h, --help              help for fish
      --no-descriptions   disable completion descriptions
&lt;/code&gt;&lt;/pre&gt;&lt;h3 id=&#34;options-inherited-from-parent-commands&#34;&gt;Options inherited from parent commands&lt;/h3&gt;
&lt;pre&gt;&lt;code&gt;      --format string   Format option for output. Valid options are: text, table, json
      --silent          Suppresses all diagnostic information.
  -v, --verbose         Display verbose diagnostic information.
&lt;/code&gt;&lt;/pre&gt;&lt;h3 id=&#34;see-also&#34;&gt;SEE ALSO&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://aws.github.io/amazon-genomics-cli/amazon-genomics-cli/docs/reference/agc_completion/&#34;&gt;agc completion&lt;/a&gt;	 - generate the autocompletion script for the specified shell&lt;/li&gt;
&lt;/ul&gt;

      </description>
    </item>
    
    <item>
      <title>Docs: agc completion powershell</title>
      <link>https://aws.github.io/amazon-genomics-cli/docs/reference/agc_completion_powershell/</link>
      <pubDate>Mon, 06 May 2024 18:32:37 +0000</pubDate>
      
      <guid>https://aws.github.io/amazon-genomics-cli/docs/reference/agc_completion_powershell/</guid>
      <description>
        
        
        &lt;h2 id=&#34;agc-completion-powershell&#34;&gt;agc completion powershell&lt;/h2&gt;
&lt;p&gt;generate the autocompletion script for powershell&lt;/p&gt;
&lt;h3 id=&#34;synopsis&#34;&gt;Synopsis&lt;/h3&gt;
&lt;p&gt;Generate the autocompletion script for powershell.&lt;/p&gt;
&lt;p&gt;To load completions in your current shell session:
PS C:&amp;gt; agc completion powershell | Out-String | Invoke-Expression&lt;/p&gt;
&lt;p&gt;To load completions for every new session, add the output of the above command
to your powershell profile.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;agc completion powershell [flags]
&lt;/code&gt;&lt;/pre&gt;&lt;h3 id=&#34;options&#34;&gt;Options&lt;/h3&gt;
&lt;pre&gt;&lt;code&gt;  -h, --help              help for powershell
      --no-descriptions   disable completion descriptions
&lt;/code&gt;&lt;/pre&gt;&lt;h3 id=&#34;options-inherited-from-parent-commands&#34;&gt;Options inherited from parent commands&lt;/h3&gt;
&lt;pre&gt;&lt;code&gt;      --format string   Format option for output. Valid options are: text, table, json
      --silent          Suppresses all diagnostic information.
  -v, --verbose         Display verbose diagnostic information.
&lt;/code&gt;&lt;/pre&gt;&lt;h3 id=&#34;see-also&#34;&gt;SEE ALSO&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://aws.github.io/amazon-genomics-cli/amazon-genomics-cli/docs/reference/agc_completion/&#34;&gt;agc completion&lt;/a&gt;	 - generate the autocompletion script for the specified shell&lt;/li&gt;
&lt;/ul&gt;

      </description>
    </item>
    
    <item>
      <title>Docs: agc completion zsh</title>
      <link>https://aws.github.io/amazon-genomics-cli/docs/reference/agc_completion_zsh/</link>
      <pubDate>Mon, 06 May 2024 18:32:37 +0000</pubDate>
      
      <guid>https://aws.github.io/amazon-genomics-cli/docs/reference/agc_completion_zsh/</guid>
      <description>
        
        
        &lt;h2 id=&#34;agc-completion-zsh&#34;&gt;agc completion zsh&lt;/h2&gt;
&lt;p&gt;generate the autocompletion script for zsh&lt;/p&gt;
&lt;h3 id=&#34;synopsis&#34;&gt;Synopsis&lt;/h3&gt;
&lt;p&gt;Generate the autocompletion script for the zsh shell.&lt;/p&gt;
&lt;p&gt;If shell completion is not already enabled in your environment you will need
to enable it.  You can execute the following once:&lt;/p&gt;
&lt;p&gt;$ echo &amp;ldquo;autoload -U compinit; compinit&amp;rdquo; &amp;raquo; ~/.zshrc&lt;/p&gt;
&lt;p&gt;To load completions for every new session, execute once:&lt;/p&gt;
&lt;h1 id=&#34;linux&#34;&gt;Linux:&lt;/h1&gt;
&lt;p&gt;$ agc completion zsh &amp;gt; &amp;ldquo;${fpath[1]}/_agc&amp;rdquo;&lt;/p&gt;
&lt;h1 id=&#34;macos&#34;&gt;macOS:&lt;/h1&gt;
&lt;p&gt;$ agc completion zsh &amp;gt; /usr/local/share/zsh/site-functions/_agc&lt;/p&gt;
&lt;p&gt;You will need to start a new shell for this setup to take effect.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;agc completion zsh [flags]
&lt;/code&gt;&lt;/pre&gt;&lt;h3 id=&#34;options&#34;&gt;Options&lt;/h3&gt;
&lt;pre&gt;&lt;code&gt;  -h, --help              help for zsh
      --no-descriptions   disable completion descriptions
&lt;/code&gt;&lt;/pre&gt;&lt;h3 id=&#34;options-inherited-from-parent-commands&#34;&gt;Options inherited from parent commands&lt;/h3&gt;
&lt;pre&gt;&lt;code&gt;      --format string   Format option for output. Valid options are: text, table, json
      --silent          Suppresses all diagnostic information.
  -v, --verbose         Display verbose diagnostic information.
&lt;/code&gt;&lt;/pre&gt;&lt;h3 id=&#34;see-also&#34;&gt;SEE ALSO&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://aws.github.io/amazon-genomics-cli/amazon-genomics-cli/docs/reference/agc_completion/&#34;&gt;agc completion&lt;/a&gt;	 - generate the autocompletion script for the specified shell&lt;/li&gt;
&lt;/ul&gt;

      </description>
    </item>
    
    <item>
      <title>Docs: agc configure</title>
      <link>https://aws.github.io/amazon-genomics-cli/docs/reference/agc_configure/</link>
      <pubDate>Mon, 06 May 2024 18:32:37 +0000</pubDate>
      
      <guid>https://aws.github.io/amazon-genomics-cli/docs/reference/agc_configure/</guid>
      <description>
        
        
        &lt;h2 id=&#34;agc-configure&#34;&gt;agc configure&lt;/h2&gt;
&lt;p&gt;Commands for configuration.
Configuration is stored per user.&lt;/p&gt;
&lt;h3 id=&#34;synopsis&#34;&gt;Synopsis&lt;/h3&gt;
&lt;p&gt;Commands for configuration.
Configure local settings and preferences to customize the CLI experience.&lt;/p&gt;
&lt;h3 id=&#34;options&#34;&gt;Options&lt;/h3&gt;
&lt;pre&gt;&lt;code&gt;  -p, --awsProfile string   Use the provided AWS CLI profile.
  -h, --help                help for configure
&lt;/code&gt;&lt;/pre&gt;&lt;h3 id=&#34;options-inherited-from-parent-commands&#34;&gt;Options inherited from parent commands&lt;/h3&gt;
&lt;pre&gt;&lt;code&gt;      --format string   Format option for output. Valid options are: text, table, json
      --silent          Suppresses all diagnostic information.
  -v, --verbose         Display verbose diagnostic information.
&lt;/code&gt;&lt;/pre&gt;&lt;h3 id=&#34;see-also&#34;&gt;SEE ALSO&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://aws.github.io/amazon-genomics-cli/amazon-genomics-cli/docs/reference/agc/&#34;&gt;agc&lt;/a&gt;	 - üß¨ Launch and manage genomics workloads on AWS.&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://aws.github.io/amazon-genomics-cli/amazon-genomics-cli/docs/reference/agc_configure_describe/&#34;&gt;agc configure describe&lt;/a&gt;	 - Shows current configuration of the AGC setup for current user&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://aws.github.io/amazon-genomics-cli/amazon-genomics-cli/docs/reference/agc_configure_email/&#34;&gt;agc configure email&lt;/a&gt;	 - Sets user email address to be used to tag AGC resources created in the account&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://aws.github.io/amazon-genomics-cli/amazon-genomics-cli/docs/reference/agc_configure_format/&#34;&gt;agc configure format&lt;/a&gt;	 - Sets default format option for output display of AGC commands. Valid format options are &amp;lsquo;text&amp;rsquo;, &amp;lsquo;table&amp;rsquo;, or &amp;lsquo;json&amp;rsquo;&lt;/li&gt;
&lt;/ul&gt;

      </description>
    </item>
    
    <item>
      <title>Docs: agc configure describe</title>
      <link>https://aws.github.io/amazon-genomics-cli/docs/reference/agc_configure_describe/</link>
      <pubDate>Mon, 06 May 2024 18:32:37 +0000</pubDate>
      
      <guid>https://aws.github.io/amazon-genomics-cli/docs/reference/agc_configure_describe/</guid>
      <description>
        
        
        &lt;h2 id=&#34;agc-configure-describe&#34;&gt;agc configure describe&lt;/h2&gt;
&lt;p&gt;Shows current configuration of the AGC setup for current user&lt;/p&gt;
&lt;h3 id=&#34;synopsis&#34;&gt;Synopsis&lt;/h3&gt;
&lt;p&gt;Running this command reads current configuration file for AGC and prints out it content
Output of the command has following format:
CONFIG:
FORMAT: Name
USER: Email Id&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;agc configure describe [flags]
&lt;/code&gt;&lt;/pre&gt;&lt;h3 id=&#34;options&#34;&gt;Options&lt;/h3&gt;
&lt;pre&gt;&lt;code&gt;  -h, --help   help for describe
&lt;/code&gt;&lt;/pre&gt;&lt;h3 id=&#34;options-inherited-from-parent-commands&#34;&gt;Options inherited from parent commands&lt;/h3&gt;
&lt;pre&gt;&lt;code&gt;  -p, --awsProfile string   Use the provided AWS CLI profile.
      --format string       Format option for output. Valid options are: text, table, json
      --silent              Suppresses all diagnostic information.
  -v, --verbose             Display verbose diagnostic information.
&lt;/code&gt;&lt;/pre&gt;&lt;h3 id=&#34;see-also&#34;&gt;SEE ALSO&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://aws.github.io/amazon-genomics-cli/amazon-genomics-cli/docs/reference/agc_configure/&#34;&gt;agc configure&lt;/a&gt;	 - Commands for configuration.
Configuration is stored per user.&lt;/li&gt;
&lt;/ul&gt;

      </description>
    </item>
    
    <item>
      <title>Docs: agc configure email</title>
      <link>https://aws.github.io/amazon-genomics-cli/docs/reference/agc_configure_email/</link>
      <pubDate>Mon, 06 May 2024 18:32:37 +0000</pubDate>
      
      <guid>https://aws.github.io/amazon-genomics-cli/docs/reference/agc_configure_email/</guid>
      <description>
        
        
        &lt;h2 id=&#34;agc-configure-email&#34;&gt;agc configure email&lt;/h2&gt;
&lt;p&gt;Sets user email address to be used to tag AGC resources created in the account&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;agc configure email user_email_address [flags]
&lt;/code&gt;&lt;/pre&gt;&lt;h3 id=&#34;options&#34;&gt;Options&lt;/h3&gt;
&lt;pre&gt;&lt;code&gt;  -h, --help   help for email
&lt;/code&gt;&lt;/pre&gt;&lt;h3 id=&#34;options-inherited-from-parent-commands&#34;&gt;Options inherited from parent commands&lt;/h3&gt;
&lt;pre&gt;&lt;code&gt;  -p, --awsProfile string   Use the provided AWS CLI profile.
      --format string       Format option for output. Valid options are: text, table, json
      --silent              Suppresses all diagnostic information.
  -v, --verbose             Display verbose diagnostic information.
&lt;/code&gt;&lt;/pre&gt;&lt;h3 id=&#34;see-also&#34;&gt;SEE ALSO&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://aws.github.io/amazon-genomics-cli/amazon-genomics-cli/docs/reference/agc_configure/&#34;&gt;agc configure&lt;/a&gt;	 - Commands for configuration.
Configuration is stored per user.&lt;/li&gt;
&lt;/ul&gt;

      </description>
    </item>
    
    <item>
      <title>Docs: agc configure format</title>
      <link>https://aws.github.io/amazon-genomics-cli/docs/reference/agc_configure_format/</link>
      <pubDate>Mon, 06 May 2024 18:32:37 +0000</pubDate>
      
      <guid>https://aws.github.io/amazon-genomics-cli/docs/reference/agc_configure_format/</guid>
      <description>
        
        
        &lt;h2 id=&#34;agc-configure-format&#34;&gt;agc configure format&lt;/h2&gt;
&lt;p&gt;Sets default format option for output display of AGC commands. Valid format options are &amp;lsquo;text&amp;rsquo;, &amp;lsquo;table&amp;rsquo;, or &amp;lsquo;json&amp;rsquo;&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;agc configure format output_format [flags]
&lt;/code&gt;&lt;/pre&gt;&lt;h3 id=&#34;options&#34;&gt;Options&lt;/h3&gt;
&lt;pre&gt;&lt;code&gt;  -h, --help   help for format
&lt;/code&gt;&lt;/pre&gt;&lt;h3 id=&#34;options-inherited-from-parent-commands&#34;&gt;Options inherited from parent commands&lt;/h3&gt;
&lt;pre&gt;&lt;code&gt;  -p, --awsProfile string   Use the provided AWS CLI profile.
      --format string       Format option for output. Valid options are: text, table, json
      --silent              Suppresses all diagnostic information.
  -v, --verbose             Display verbose diagnostic information.
&lt;/code&gt;&lt;/pre&gt;&lt;h3 id=&#34;see-also&#34;&gt;SEE ALSO&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://aws.github.io/amazon-genomics-cli/amazon-genomics-cli/docs/reference/agc_configure/&#34;&gt;agc configure&lt;/a&gt;	 - Commands for configuration.
Configuration is stored per user.&lt;/li&gt;
&lt;/ul&gt;

      </description>
    </item>
    
    <item>
      <title>Docs: agc context</title>
      <link>https://aws.github.io/amazon-genomics-cli/docs/reference/agc_context/</link>
      <pubDate>Mon, 06 May 2024 18:32:37 +0000</pubDate>
      
      <guid>https://aws.github.io/amazon-genomics-cli/docs/reference/agc_context/</guid>
      <description>
        
        
        &lt;h2 id=&#34;agc-context&#34;&gt;agc context&lt;/h2&gt;
&lt;p&gt;Commands for contexts.
Contexts specify workflow engines and computational fleets to use when running a workflow.&lt;/p&gt;
&lt;h3 id=&#34;synopsis&#34;&gt;Synopsis&lt;/h3&gt;
&lt;p&gt;Commands for contexts.
Contexts specify workflow engines and computational fleets to use when running a workflow.
Users can quickly switch between infrastructure configurations by specifying a
particular context.&lt;/p&gt;
&lt;h3 id=&#34;options&#34;&gt;Options&lt;/h3&gt;
&lt;pre&gt;&lt;code&gt;  -p, --awsProfile string   Use the provided AWS CLI profile.
  -h, --help                help for context
&lt;/code&gt;&lt;/pre&gt;&lt;h3 id=&#34;options-inherited-from-parent-commands&#34;&gt;Options inherited from parent commands&lt;/h3&gt;
&lt;pre&gt;&lt;code&gt;      --format string   Format option for output. Valid options are: text, table, json
      --silent          Suppresses all diagnostic information.
  -v, --verbose         Display verbose diagnostic information.
&lt;/code&gt;&lt;/pre&gt;&lt;h3 id=&#34;see-also&#34;&gt;SEE ALSO&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://aws.github.io/amazon-genomics-cli/amazon-genomics-cli/docs/reference/agc/&#34;&gt;agc&lt;/a&gt;	 - üß¨ Launch and manage genomics workloads on AWS.&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://aws.github.io/amazon-genomics-cli/amazon-genomics-cli/docs/reference/agc_context_deploy/&#34;&gt;agc context deploy&lt;/a&gt;	 - Deploy contexts in the current project&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://aws.github.io/amazon-genomics-cli/amazon-genomics-cli/docs/reference/agc_context_describe/&#34;&gt;agc context describe&lt;/a&gt;	 - Show the information for a specific context in the current project&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://aws.github.io/amazon-genomics-cli/amazon-genomics-cli/docs/reference/agc_context_destroy/&#34;&gt;agc context destroy&lt;/a&gt;	 - Destroy contexts in the current project.&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://aws.github.io/amazon-genomics-cli/amazon-genomics-cli/docs/reference/agc_context_list/&#34;&gt;agc context list&lt;/a&gt;	 - List contexts in the project&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://aws.github.io/amazon-genomics-cli/amazon-genomics-cli/docs/reference/agc_context_status/&#34;&gt;agc context status&lt;/a&gt;	 - Show the status for the deployed contexts in the project&lt;/li&gt;
&lt;/ul&gt;

      </description>
    </item>
    
    <item>
      <title>Docs: agc context deploy</title>
      <link>https://aws.github.io/amazon-genomics-cli/docs/reference/agc_context_deploy/</link>
      <pubDate>Mon, 06 May 2024 18:32:37 +0000</pubDate>
      
      <guid>https://aws.github.io/amazon-genomics-cli/docs/reference/agc_context_deploy/</guid>
      <description>
        
        
        &lt;h2 id=&#34;agc-context-deploy&#34;&gt;agc context deploy&lt;/h2&gt;
&lt;p&gt;Deploy contexts in the current project&lt;/p&gt;
&lt;h3 id=&#34;synopsis&#34;&gt;Synopsis&lt;/h3&gt;
&lt;p&gt;deploy is for deploying one or more contexts.
It creates AGC resources in AWS.&lt;/p&gt;
&lt;p&gt;Output of the command has following format:
DETAIL: AccessLogGroupName BucketLocation EngineLogGroupName Status StatusReason WesLogGroupName WesUrl
SUMMARY: IsSpot MaxVCpus Name
ENGINE: Engine Type
FILESYSTEM: FSType
FSCONFIG: FSProvisionedThroughput
STRING&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;agc context deploy {context_name ... | --all} [flags]
&lt;/code&gt;&lt;/pre&gt;&lt;h3 id=&#34;examples&#34;&gt;Examples&lt;/h3&gt;
&lt;pre&gt;&lt;code&gt;
/code agc context deploy context1 context2
&lt;/code&gt;&lt;/pre&gt;&lt;h3 id=&#34;options&#34;&gt;Options&lt;/h3&gt;
&lt;pre&gt;&lt;code&gt;      --all               Deploy all contexts in the project
  -c, --context strings   Names of one or more contexts to deploy
  -h, --help              help for deploy
&lt;/code&gt;&lt;/pre&gt;&lt;h3 id=&#34;options-inherited-from-parent-commands&#34;&gt;Options inherited from parent commands&lt;/h3&gt;
&lt;pre&gt;&lt;code&gt;  -p, --awsProfile string   Use the provided AWS CLI profile.
      --format string       Format option for output. Valid options are: text, table, json
      --silent              Suppresses all diagnostic information.
  -v, --verbose             Display verbose diagnostic information.
&lt;/code&gt;&lt;/pre&gt;&lt;h3 id=&#34;see-also&#34;&gt;SEE ALSO&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://aws.github.io/amazon-genomics-cli/amazon-genomics-cli/docs/reference/agc_context/&#34;&gt;agc context&lt;/a&gt;	 - Commands for contexts.
Contexts specify workflow engines and computational fleets to use when running a workflow.&lt;/li&gt;
&lt;/ul&gt;

      </description>
    </item>
    
    <item>
      <title>Docs: agc context describe</title>
      <link>https://aws.github.io/amazon-genomics-cli/docs/reference/agc_context_describe/</link>
      <pubDate>Mon, 06 May 2024 18:32:37 +0000</pubDate>
      
      <guid>https://aws.github.io/amazon-genomics-cli/docs/reference/agc_context_describe/</guid>
      <description>
        
        
        &lt;h2 id=&#34;agc-context-describe&#34;&gt;agc context describe&lt;/h2&gt;
&lt;p&gt;Show the information for a specific context in the current project&lt;/p&gt;
&lt;h3 id=&#34;synopsis&#34;&gt;Synopsis&lt;/h3&gt;
&lt;p&gt;describe is for showing information about the specified context.&lt;/p&gt;
&lt;p&gt;Output of the command has following format:
CONTEXT: MaxVCpus Name RequestSpotInstances Status StatusReason
INSTANCETYPE: Value
OUTPUTLOCATION: Url
WESENDPOINT: Url&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;agc context describe context_name [flags]
&lt;/code&gt;&lt;/pre&gt;&lt;h3 id=&#34;examples&#34;&gt;Examples&lt;/h3&gt;
&lt;pre&gt;&lt;code&gt;
/code agc context describe myCtx
&lt;/code&gt;&lt;/pre&gt;&lt;h3 id=&#34;options&#34;&gt;Options&lt;/h3&gt;
&lt;pre&gt;&lt;code&gt;  -c, --context string   Names of one or more contexts to deploy
  -h, --help             help for describe
&lt;/code&gt;&lt;/pre&gt;&lt;h3 id=&#34;options-inherited-from-parent-commands&#34;&gt;Options inherited from parent commands&lt;/h3&gt;
&lt;pre&gt;&lt;code&gt;  -p, --awsProfile string   Use the provided AWS CLI profile.
      --format string       Format option for output. Valid options are: text, table, json
      --silent              Suppresses all diagnostic information.
  -v, --verbose             Display verbose diagnostic information.
&lt;/code&gt;&lt;/pre&gt;&lt;h3 id=&#34;see-also&#34;&gt;SEE ALSO&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://aws.github.io/amazon-genomics-cli/amazon-genomics-cli/docs/reference/agc_context/&#34;&gt;agc context&lt;/a&gt;	 - Commands for contexts.
Contexts specify workflow engines and computational fleets to use when running a workflow.&lt;/li&gt;
&lt;/ul&gt;

      </description>
    </item>
    
    <item>
      <title>Docs: agc context destroy</title>
      <link>https://aws.github.io/amazon-genomics-cli/docs/reference/agc_context_destroy/</link>
      <pubDate>Mon, 06 May 2024 18:32:37 +0000</pubDate>
      
      <guid>https://aws.github.io/amazon-genomics-cli/docs/reference/agc_context_destroy/</guid>
      <description>
        
        
        &lt;h2 id=&#34;agc-context-destroy&#34;&gt;agc context destroy&lt;/h2&gt;
&lt;p&gt;Destroy contexts in the current project.&lt;/p&gt;
&lt;h3 id=&#34;synopsis&#34;&gt;Synopsis&lt;/h3&gt;
&lt;p&gt;destroy is for destroying one or more contexts.
It destroys AGC resources in AWS.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;agc context destroy {context_name ... | --all} [flags]
&lt;/code&gt;&lt;/pre&gt;&lt;h3 id=&#34;examples&#34;&gt;Examples&lt;/h3&gt;
&lt;pre&gt;&lt;code&gt;
/code agc context destroy context1 context2
&lt;/code&gt;&lt;/pre&gt;&lt;h3 id=&#34;options&#34;&gt;Options&lt;/h3&gt;
&lt;pre&gt;&lt;code&gt;      --all               Destroy all contexts in the project
  -c, --context strings   Names of one or more contexts to destroy
      --force             Destroy context and stop running workflows within context
  -h, --help              help for destroy
&lt;/code&gt;&lt;/pre&gt;&lt;h3 id=&#34;options-inherited-from-parent-commands&#34;&gt;Options inherited from parent commands&lt;/h3&gt;
&lt;pre&gt;&lt;code&gt;  -p, --awsProfile string   Use the provided AWS CLI profile.
      --format string       Format option for output. Valid options are: text, table, json
      --silent              Suppresses all diagnostic information.
  -v, --verbose             Display verbose diagnostic information.
&lt;/code&gt;&lt;/pre&gt;&lt;h3 id=&#34;see-also&#34;&gt;SEE ALSO&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://aws.github.io/amazon-genomics-cli/amazon-genomics-cli/docs/reference/agc_context/&#34;&gt;agc context&lt;/a&gt;	 - Commands for contexts.
Contexts specify workflow engines and computational fleets to use when running a workflow.&lt;/li&gt;
&lt;/ul&gt;

      </description>
    </item>
    
    <item>
      <title>Docs: agc context list</title>
      <link>https://aws.github.io/amazon-genomics-cli/docs/reference/agc_context_list/</link>
      <pubDate>Mon, 06 May 2024 18:32:37 +0000</pubDate>
      
      <guid>https://aws.github.io/amazon-genomics-cli/docs/reference/agc_context_list/</guid>
      <description>
        
        
        &lt;h2 id=&#34;agc-context-list&#34;&gt;agc context list&lt;/h2&gt;
&lt;p&gt;List contexts in the project&lt;/p&gt;
&lt;h3 id=&#34;synopsis&#34;&gt;Synopsis&lt;/h3&gt;
&lt;p&gt;list is for showing a combined list of contexts specified in
the project specification.&lt;/p&gt;
&lt;p&gt;Output of the command has following format:
CONTEXTSUMMARY: EngineName Name&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;agc context list [flags]
&lt;/code&gt;&lt;/pre&gt;&lt;h3 id=&#34;options&#34;&gt;Options&lt;/h3&gt;
&lt;pre&gt;&lt;code&gt;  -h, --help   help for list
&lt;/code&gt;&lt;/pre&gt;&lt;h3 id=&#34;options-inherited-from-parent-commands&#34;&gt;Options inherited from parent commands&lt;/h3&gt;
&lt;pre&gt;&lt;code&gt;  -p, --awsProfile string   Use the provided AWS CLI profile.
      --format string       Format option for output. Valid options are: text, table, json
      --silent              Suppresses all diagnostic information.
  -v, --verbose             Display verbose diagnostic information.
&lt;/code&gt;&lt;/pre&gt;&lt;h3 id=&#34;see-also&#34;&gt;SEE ALSO&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://aws.github.io/amazon-genomics-cli/amazon-genomics-cli/docs/reference/agc_context/&#34;&gt;agc context&lt;/a&gt;	 - Commands for contexts.
Contexts specify workflow engines and computational fleets to use when running a workflow.&lt;/li&gt;
&lt;/ul&gt;

      </description>
    </item>
    
    <item>
      <title>Docs: agc context status</title>
      <link>https://aws.github.io/amazon-genomics-cli/docs/reference/agc_context_status/</link>
      <pubDate>Mon, 06 May 2024 18:32:37 +0000</pubDate>
      
      <guid>https://aws.github.io/amazon-genomics-cli/docs/reference/agc_context_status/</guid>
      <description>
        
        
        &lt;h2 id=&#34;agc-context-status&#34;&gt;agc context status&lt;/h2&gt;
&lt;p&gt;Show the status for the deployed contexts in the project&lt;/p&gt;
&lt;h3 id=&#34;synopsis&#34;&gt;Synopsis&lt;/h3&gt;
&lt;p&gt;status is for showing the status for the deployed contexts in the project.&lt;/p&gt;
&lt;p&gt;Output of the command has following format:
INSTANCE: ContextName ContextReason ContextStatus IsDefinedInProjectFile&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;agc context status [flags]
&lt;/code&gt;&lt;/pre&gt;&lt;h3 id=&#34;examples&#34;&gt;Examples&lt;/h3&gt;
&lt;pre&gt;&lt;code&gt;
/code agc context status
&lt;/code&gt;&lt;/pre&gt;&lt;h3 id=&#34;options&#34;&gt;Options&lt;/h3&gt;
&lt;pre&gt;&lt;code&gt;  -h, --help   help for status
&lt;/code&gt;&lt;/pre&gt;&lt;h3 id=&#34;options-inherited-from-parent-commands&#34;&gt;Options inherited from parent commands&lt;/h3&gt;
&lt;pre&gt;&lt;code&gt;  -p, --awsProfile string   Use the provided AWS CLI profile.
      --format string       Format option for output. Valid options are: text, table, json
      --silent              Suppresses all diagnostic information.
  -v, --verbose             Display verbose diagnostic information.
&lt;/code&gt;&lt;/pre&gt;&lt;h3 id=&#34;see-also&#34;&gt;SEE ALSO&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://aws.github.io/amazon-genomics-cli/amazon-genomics-cli/docs/reference/agc_context/&#34;&gt;agc context&lt;/a&gt;	 - Commands for contexts.
Contexts specify workflow engines and computational fleets to use when running a workflow.&lt;/li&gt;
&lt;/ul&gt;

      </description>
    </item>
    
    <item>
      <title>Docs: agc logs</title>
      <link>https://aws.github.io/amazon-genomics-cli/docs/reference/agc_logs/</link>
      <pubDate>Mon, 06 May 2024 18:32:37 +0000</pubDate>
      
      <guid>https://aws.github.io/amazon-genomics-cli/docs/reference/agc_logs/</guid>
      <description>
        
        
        &lt;h2 id=&#34;agc-logs&#34;&gt;agc logs&lt;/h2&gt;
&lt;p&gt;Commands for various logs.&lt;/p&gt;
&lt;h3 id=&#34;synopsis&#34;&gt;Synopsis&lt;/h3&gt;
&lt;p&gt;Commands for various logs.
Logs can currently be listed for workflows, workflow engines,
and various AGC infrastructure parts.
You can also show the content of any CloudWatch log stream that you have
access rights to.&lt;/p&gt;
&lt;h3 id=&#34;options&#34;&gt;Options&lt;/h3&gt;
&lt;pre&gt;&lt;code&gt;  -p, --awsProfile string   Use the provided AWS CLI profile.
  -h, --help                help for logs
&lt;/code&gt;&lt;/pre&gt;&lt;h3 id=&#34;options-inherited-from-parent-commands&#34;&gt;Options inherited from parent commands&lt;/h3&gt;
&lt;pre&gt;&lt;code&gt;      --format string   Format option for output. Valid options are: text, table, json
      --silent          Suppresses all diagnostic information.
  -v, --verbose         Display verbose diagnostic information.
&lt;/code&gt;&lt;/pre&gt;&lt;h3 id=&#34;see-also&#34;&gt;SEE ALSO&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://aws.github.io/amazon-genomics-cli/amazon-genomics-cli/docs/reference/agc/&#34;&gt;agc&lt;/a&gt;	 - üß¨ Launch and manage genomics workloads on AWS.&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://aws.github.io/amazon-genomics-cli/amazon-genomics-cli/docs/reference/agc_logs_access/&#34;&gt;agc logs access&lt;/a&gt;	 - Show workflow access logs for a given context.&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://aws.github.io/amazon-genomics-cli/amazon-genomics-cli/docs/reference/agc_logs_adapter/&#34;&gt;agc logs adapter&lt;/a&gt;	 - Show workflow adapter logs for a given context.&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://aws.github.io/amazon-genomics-cli/amazon-genomics-cli/docs/reference/agc_logs_engine/&#34;&gt;agc logs engine&lt;/a&gt;	 - Show workflow engine logs for a given context.&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://aws.github.io/amazon-genomics-cli/amazon-genomics-cli/docs/reference/agc_logs_workflow/&#34;&gt;agc logs workflow&lt;/a&gt;	 - Show the task logs of a given workflow&lt;/li&gt;
&lt;/ul&gt;

      </description>
    </item>
    
    <item>
      <title>Docs: agc logs access</title>
      <link>https://aws.github.io/amazon-genomics-cli/docs/reference/agc_logs_access/</link>
      <pubDate>Mon, 06 May 2024 18:32:37 +0000</pubDate>
      
      <guid>https://aws.github.io/amazon-genomics-cli/docs/reference/agc_logs_access/</guid>
      <description>
        
        
        &lt;h2 id=&#34;agc-logs-access&#34;&gt;agc logs access&lt;/h2&gt;
&lt;p&gt;Show workflow access logs for a given context.&lt;/p&gt;
&lt;h3 id=&#34;synopsis&#34;&gt;Synopsis&lt;/h3&gt;
&lt;p&gt;Show workflow access logs for a given context.
If no start, end, or look back periods are set, this command will show logs from the last hour.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;agc logs access -c context_name [-f filter] [-s start_date] [-e end_date] [-l look_back] [-t] [flags]
&lt;/code&gt;&lt;/pre&gt;&lt;h3 id=&#34;examples&#34;&gt;Examples&lt;/h3&gt;
&lt;pre&gt;&lt;code&gt;
/code agc logs access -c myCtx -s 2021/3/31 -e 2021/4/1 -f ERROR
&lt;/code&gt;&lt;/pre&gt;&lt;h3 id=&#34;options&#34;&gt;Options&lt;/h3&gt;
&lt;pre&gt;&lt;code&gt;  -c, --context string     Name of context
  -e, --end string         A date to stop displaying logs.
                           Supports most date formats, such as mm/dd/yy or yyyy-mm-dd-07:00.
                           Times respect the system timezone.
  -f, --filter string      Match terms, phrases, or values in the logs.
                           Filters are case sensitive and multiple terms combine with AND logic.
                           Use a question mark for OR, such as &amp;quot;?ERROR ?WARN&amp;quot;. Filter out terms with a minus, such as &amp;quot;-INFO&amp;quot;.
  -h, --help               help for access
  -l, --look-back string   A period of time to look back from now, such as &amp;quot;2h45m&amp;quot;.
                           Valid time units are &amp;quot;s&amp;quot;, &amp;quot;m&amp;quot;, and &amp;quot;h&amp;quot;.
  -s, --start string       A date to begin displaying logs.
                           Supports most date formats, such as 2021/03/31 or 8/8/2021 01:00:01 PM.
                           Times respect the system timezone.
  -t, --tail               Follow the log output.
&lt;/code&gt;&lt;/pre&gt;&lt;h3 id=&#34;options-inherited-from-parent-commands&#34;&gt;Options inherited from parent commands&lt;/h3&gt;
&lt;pre&gt;&lt;code&gt;  -p, --awsProfile string   Use the provided AWS CLI profile.
      --format string       Format option for output. Valid options are: text, table, json
      --silent              Suppresses all diagnostic information.
  -v, --verbose             Display verbose diagnostic information.
&lt;/code&gt;&lt;/pre&gt;&lt;h3 id=&#34;see-also&#34;&gt;SEE ALSO&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://aws.github.io/amazon-genomics-cli/amazon-genomics-cli/docs/reference/agc_logs/&#34;&gt;agc logs&lt;/a&gt;	 - Commands for various logs.&lt;/li&gt;
&lt;/ul&gt;

      </description>
    </item>
    
    <item>
      <title>Docs: agc logs adapter</title>
      <link>https://aws.github.io/amazon-genomics-cli/docs/reference/agc_logs_adapter/</link>
      <pubDate>Mon, 06 May 2024 18:32:37 +0000</pubDate>
      
      <guid>https://aws.github.io/amazon-genomics-cli/docs/reference/agc_logs_adapter/</guid>
      <description>
        
        
        &lt;h2 id=&#34;agc-logs-adapter&#34;&gt;agc logs adapter&lt;/h2&gt;
&lt;p&gt;Show workflow adapter logs for a given context.&lt;/p&gt;
&lt;h3 id=&#34;synopsis&#34;&gt;Synopsis&lt;/h3&gt;
&lt;p&gt;Show workflow adapter logs for a given context.
If no start, end, or look back periods are set, this command will show logs from the last hour.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;agc logs adapter -c context_name [-f filter] [-s start_date] [-e end_date] [-l look_back] [-t] [flags]
&lt;/code&gt;&lt;/pre&gt;&lt;h3 id=&#34;examples&#34;&gt;Examples&lt;/h3&gt;
&lt;pre&gt;&lt;code&gt;
/code agc logs adapter -c myCtx -s 2021/3/31 -e 2021/4/1 -f ERROR
&lt;/code&gt;&lt;/pre&gt;&lt;h3 id=&#34;options&#34;&gt;Options&lt;/h3&gt;
&lt;pre&gt;&lt;code&gt;  -c, --context string     Name of context
  -e, --end string         A date to stop displaying logs.
                           Supports most date formats, such as mm/dd/yy or yyyy-mm-dd-07:00.
                           Times respect the system timezone.
  -f, --filter string      Match terms, phrases, or values in the logs.
                           Filters are case sensitive and multiple terms combine with AND logic.
                           Use a question mark for OR, such as &amp;quot;?ERROR ?WARN&amp;quot;. Filter out terms with a minus, such as &amp;quot;-INFO&amp;quot;.
  -h, --help               help for adapter
  -l, --look-back string   A period of time to look back from now, such as &amp;quot;2h45m&amp;quot;.
                           Valid time units are &amp;quot;s&amp;quot;, &amp;quot;m&amp;quot;, and &amp;quot;h&amp;quot;.
  -s, --start string       A date to begin displaying logs.
                           Supports most date formats, such as 2021/03/31 or 8/8/2021 01:00:01 PM.
                           Times respect the system timezone.
  -t, --tail               Follow the log output.
&lt;/code&gt;&lt;/pre&gt;&lt;h3 id=&#34;options-inherited-from-parent-commands&#34;&gt;Options inherited from parent commands&lt;/h3&gt;
&lt;pre&gt;&lt;code&gt;  -p, --awsProfile string   Use the provided AWS CLI profile.
      --format string       Format option for output. Valid options are: text, table, json
      --silent              Suppresses all diagnostic information.
  -v, --verbose             Display verbose diagnostic information.
&lt;/code&gt;&lt;/pre&gt;&lt;h3 id=&#34;see-also&#34;&gt;SEE ALSO&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://aws.github.io/amazon-genomics-cli/amazon-genomics-cli/docs/reference/agc_logs/&#34;&gt;agc logs&lt;/a&gt;	 - Commands for various logs.&lt;/li&gt;
&lt;/ul&gt;

      </description>
    </item>
    
    <item>
      <title>Docs: agc logs engine</title>
      <link>https://aws.github.io/amazon-genomics-cli/docs/reference/agc_logs_engine/</link>
      <pubDate>Mon, 06 May 2024 18:32:37 +0000</pubDate>
      
      <guid>https://aws.github.io/amazon-genomics-cli/docs/reference/agc_logs_engine/</guid>
      <description>
        
        
        &lt;h2 id=&#34;agc-logs-engine&#34;&gt;agc logs engine&lt;/h2&gt;
&lt;p&gt;Show workflow engine logs for a given context.&lt;/p&gt;
&lt;h3 id=&#34;synopsis&#34;&gt;Synopsis&lt;/h3&gt;
&lt;p&gt;Show workflow engine logs for a given context.
If no start, end, or look back periods are set, this command will show logs from the last hour.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;agc logs engine -c context_name [-r run_id] [-f filter] [-s start_date] [-e end_date] [-l look_back] [-t] [flags]
&lt;/code&gt;&lt;/pre&gt;&lt;h3 id=&#34;examples&#34;&gt;Examples&lt;/h3&gt;
&lt;pre&gt;&lt;code&gt;
/code agc logs engine -c myCtx -r 1234-aed-32db -s 2021/3/31 -e 2021/4/1 -f ERROR
&lt;/code&gt;&lt;/pre&gt;&lt;h3 id=&#34;options&#34;&gt;Options&lt;/h3&gt;
&lt;pre&gt;&lt;code&gt;  -c, --context string     Name of context
  -e, --end string         A date to stop displaying logs.
                           Supports most date formats, such as mm/dd/yy or yyyy-mm-dd-07:00.
                           Times respect the system timezone.
  -f, --filter string      Match terms, phrases, or values in the logs.
                           Filters are case sensitive and multiple terms combine with AND logic.
                           Use a question mark for OR, such as &amp;quot;?ERROR ?WARN&amp;quot;. Filter out terms with a minus, such as &amp;quot;-INFO&amp;quot;.
  -h, --help               help for engine
  -l, --look-back string   A period of time to look back from now, such as &amp;quot;2h45m&amp;quot;.
                           Valid time units are &amp;quot;s&amp;quot;, &amp;quot;m&amp;quot;, and &amp;quot;h&amp;quot;.
  -r, --run-id string      filter to engine logs to this workflow run id
  -s, --start string       A date to begin displaying logs.
                           Supports most date formats, such as 2021/03/31 or 8/8/2021 01:00:01 PM.
                           Times respect the system timezone.
  -t, --tail               Follow the log output.
&lt;/code&gt;&lt;/pre&gt;&lt;h3 id=&#34;options-inherited-from-parent-commands&#34;&gt;Options inherited from parent commands&lt;/h3&gt;
&lt;pre&gt;&lt;code&gt;  -p, --awsProfile string   Use the provided AWS CLI profile.
      --format string       Format option for output. Valid options are: text, table, json
      --silent              Suppresses all diagnostic information.
  -v, --verbose             Display verbose diagnostic information.
&lt;/code&gt;&lt;/pre&gt;&lt;h3 id=&#34;see-also&#34;&gt;SEE ALSO&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://aws.github.io/amazon-genomics-cli/amazon-genomics-cli/docs/reference/agc_logs/&#34;&gt;agc logs&lt;/a&gt;	 - Commands for various logs.&lt;/li&gt;
&lt;/ul&gt;

      </description>
    </item>
    
    <item>
      <title>Docs: agc logs workflow</title>
      <link>https://aws.github.io/amazon-genomics-cli/docs/reference/agc_logs_workflow/</link>
      <pubDate>Mon, 06 May 2024 18:32:37 +0000</pubDate>
      
      <guid>https://aws.github.io/amazon-genomics-cli/docs/reference/agc_logs_workflow/</guid>
      <description>
        
        
        &lt;h2 id=&#34;agc-logs-workflow&#34;&gt;agc logs workflow&lt;/h2&gt;
&lt;p&gt;Show the task logs of a given workflow&lt;/p&gt;
&lt;h3 id=&#34;synopsis&#34;&gt;Synopsis&lt;/h3&gt;
&lt;p&gt;Show the task logs of a given workflow.
If the &amp;ndash;run flag is omitted then the latest workflow run is used.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;agc logs workflow workflow_name [-r run_id] [--failed_tasks] [flags]
&lt;/code&gt;&lt;/pre&gt;&lt;h3 id=&#34;options&#34;&gt;Options&lt;/h3&gt;
&lt;pre&gt;&lt;code&gt;      --all-tasks          Show logs of all tasks in the given workflow run
  -e, --end string         A date to stop displaying logs.
                           Supports most date formats, such as mm/dd/yy or yyyy-mm-dd-07:00.
                           Times respect the system timezone.
      --failed-tasks       Only show logs of tasks that have not exited cleanly.
  -f, --filter string      Match terms, phrases, or values in the logs.
                           Filters are case sensitive and multiple terms combine with AND logic.
                           Use a question mark for OR, such as &amp;quot;?ERROR ?WARN&amp;quot;. Filter out terms with a minus, such as &amp;quot;-INFO&amp;quot;.
  -h, --help               help for workflow
  -l, --look-back string   A period of time to look back from now, such as &amp;quot;2h45m&amp;quot;.
                           Valid time units are &amp;quot;s&amp;quot;, &amp;quot;m&amp;quot;, and &amp;quot;h&amp;quot;.
  -r, --run string         The ID of a workflow run to retrieve.
  -s, --start string       A date to begin displaying logs.
                           Supports most date formats, such as 2021/03/31 or 8/8/2021 01:00:01 PM.
                           Times respect the system timezone.
  -t, --tail               Follow the log output.
      --task string        The ID of a single task to retrieve.
&lt;/code&gt;&lt;/pre&gt;&lt;h3 id=&#34;options-inherited-from-parent-commands&#34;&gt;Options inherited from parent commands&lt;/h3&gt;
&lt;pre&gt;&lt;code&gt;  -p, --awsProfile string   Use the provided AWS CLI profile.
      --format string       Format option for output. Valid options are: text, table, json
      --silent              Suppresses all diagnostic information.
  -v, --verbose             Display verbose diagnostic information.
&lt;/code&gt;&lt;/pre&gt;&lt;h3 id=&#34;see-also&#34;&gt;SEE ALSO&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://aws.github.io/amazon-genomics-cli/amazon-genomics-cli/docs/reference/agc_logs/&#34;&gt;agc logs&lt;/a&gt;	 - Commands for various logs.&lt;/li&gt;
&lt;/ul&gt;

      </description>
    </item>
    
    <item>
      <title>Docs: agc project</title>
      <link>https://aws.github.io/amazon-genomics-cli/docs/reference/agc_project/</link>
      <pubDate>Mon, 06 May 2024 18:32:37 +0000</pubDate>
      
      <guid>https://aws.github.io/amazon-genomics-cli/docs/reference/agc_project/</guid>
      <description>
        
        
        &lt;h2 id=&#34;agc-project&#34;&gt;agc project&lt;/h2&gt;
&lt;p&gt;Commands to interact with projects.&lt;/p&gt;
&lt;h3 id=&#34;synopsis&#34;&gt;Synopsis&lt;/h3&gt;
&lt;p&gt;Commands to interact with projects.
A project is a local configuration file that describes the workflows, data,
and contexts you are working with.&lt;/p&gt;
&lt;h3 id=&#34;options&#34;&gt;Options&lt;/h3&gt;
&lt;pre&gt;&lt;code&gt;  -h, --help   help for project
&lt;/code&gt;&lt;/pre&gt;&lt;h3 id=&#34;options-inherited-from-parent-commands&#34;&gt;Options inherited from parent commands&lt;/h3&gt;
&lt;pre&gt;&lt;code&gt;      --format string   Format option for output. Valid options are: text, table, json
      --silent          Suppresses all diagnostic information.
  -v, --verbose         Display verbose diagnostic information.
&lt;/code&gt;&lt;/pre&gt;&lt;h3 id=&#34;see-also&#34;&gt;SEE ALSO&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://aws.github.io/amazon-genomics-cli/amazon-genomics-cli/docs/reference/agc/&#34;&gt;agc&lt;/a&gt;	 - üß¨ Launch and manage genomics workloads on AWS.&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://aws.github.io/amazon-genomics-cli/amazon-genomics-cli/docs/reference/agc_project_describe/&#34;&gt;agc project describe&lt;/a&gt;	 - Describe a project&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://aws.github.io/amazon-genomics-cli/amazon-genomics-cli/docs/reference/agc_project_init/&#34;&gt;agc project init&lt;/a&gt;	 - Initialize current directory with a new empty AGC project for a particular workflow type.&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://aws.github.io/amazon-genomics-cli/amazon-genomics-cli/docs/reference/agc_project_validate/&#34;&gt;agc project validate&lt;/a&gt;	 - Validate an agc-project.yaml file&lt;/li&gt;
&lt;/ul&gt;

      </description>
    </item>
    
    <item>
      <title>Docs: agc project describe</title>
      <link>https://aws.github.io/amazon-genomics-cli/docs/reference/agc_project_describe/</link>
      <pubDate>Mon, 06 May 2024 18:32:37 +0000</pubDate>
      
      <guid>https://aws.github.io/amazon-genomics-cli/docs/reference/agc_project_describe/</guid>
      <description>
        
        
        &lt;h2 id=&#34;agc-project-describe&#34;&gt;agc project describe&lt;/h2&gt;
&lt;p&gt;Describe a project&lt;/p&gt;
&lt;h3 id=&#34;synopsis&#34;&gt;Synopsis&lt;/h3&gt;
&lt;p&gt;Describe is for describing the current project specification. The current project specification is determined to be the agc-project.yaml file in the current working directory or a parent of the current directory&lt;/p&gt;
&lt;p&gt;Output of the command has following format:
PROJECT: Name
DATA: Location ReadOnly&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;agc project describe [flags]
&lt;/code&gt;&lt;/pre&gt;&lt;h3 id=&#34;examples&#34;&gt;Examples&lt;/h3&gt;
&lt;pre&gt;&lt;code&gt;
/code agc project describe
&lt;/code&gt;&lt;/pre&gt;&lt;h3 id=&#34;options&#34;&gt;Options&lt;/h3&gt;
&lt;pre&gt;&lt;code&gt;  -h, --help   help for describe
&lt;/code&gt;&lt;/pre&gt;&lt;h3 id=&#34;options-inherited-from-parent-commands&#34;&gt;Options inherited from parent commands&lt;/h3&gt;
&lt;pre&gt;&lt;code&gt;      --format string   Format option for output. Valid options are: text, table, json
      --silent          Suppresses all diagnostic information.
  -v, --verbose         Display verbose diagnostic information.
&lt;/code&gt;&lt;/pre&gt;&lt;h3 id=&#34;see-also&#34;&gt;SEE ALSO&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://aws.github.io/amazon-genomics-cli/amazon-genomics-cli/docs/reference/agc_project/&#34;&gt;agc project&lt;/a&gt;	 - Commands to interact with projects.&lt;/li&gt;
&lt;/ul&gt;

      </description>
    </item>
    
    <item>
      <title>Docs: agc project init</title>
      <link>https://aws.github.io/amazon-genomics-cli/docs/reference/agc_project_init/</link>
      <pubDate>Mon, 06 May 2024 18:32:37 +0000</pubDate>
      
      <guid>https://aws.github.io/amazon-genomics-cli/docs/reference/agc_project_init/</guid>
      <description>
        
        
        &lt;h2 id=&#34;agc-project-init&#34;&gt;agc project init&lt;/h2&gt;
&lt;p&gt;Initialize current directory with a new empty AGC project for a particular workflow type.&lt;/p&gt;
&lt;h3 id=&#34;synopsis&#34;&gt;Synopsis&lt;/h3&gt;
&lt;p&gt;Initialize current directory with a new empty AGC project for a particular workflow type.
Project specification file &amp;lsquo;agc-project.yaml&amp;rsquo; will be created in the current directory.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;agc project init project_name --workflow-type {cwl|nextflow|snakemake|wdl} [flags]
&lt;/code&gt;&lt;/pre&gt;&lt;h3 id=&#34;examples&#34;&gt;Examples&lt;/h3&gt;
&lt;pre&gt;&lt;code&gt;
Initialize a new project named &amp;quot;myProject&amp;quot;.
/code $ agc project init myProject --workflow-type my_workflow_type
&lt;/code&gt;&lt;/pre&gt;&lt;h3 id=&#34;options&#34;&gt;Options&lt;/h3&gt;
&lt;pre&gt;&lt;code&gt;  -h, --help                   help for init
  -w, --workflow-type string   uses the specified workflow type for the default context. Valid values include [cwl nextflow snakemake wdl]
&lt;/code&gt;&lt;/pre&gt;&lt;h3 id=&#34;options-inherited-from-parent-commands&#34;&gt;Options inherited from parent commands&lt;/h3&gt;
&lt;pre&gt;&lt;code&gt;      --format string   Format option for output. Valid options are: text, table, json
      --silent          Suppresses all diagnostic information.
  -v, --verbose         Display verbose diagnostic information.
&lt;/code&gt;&lt;/pre&gt;&lt;h3 id=&#34;see-also&#34;&gt;SEE ALSO&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://aws.github.io/amazon-genomics-cli/amazon-genomics-cli/docs/reference/agc_project/&#34;&gt;agc project&lt;/a&gt;	 - Commands to interact with projects.&lt;/li&gt;
&lt;/ul&gt;

      </description>
    </item>
    
    <item>
      <title>Docs: agc project validate</title>
      <link>https://aws.github.io/amazon-genomics-cli/docs/reference/agc_project_validate/</link>
      <pubDate>Mon, 06 May 2024 18:32:37 +0000</pubDate>
      
      <guid>https://aws.github.io/amazon-genomics-cli/docs/reference/agc_project_validate/</guid>
      <description>
        
        
        &lt;h2 id=&#34;agc-project-validate&#34;&gt;agc project validate&lt;/h2&gt;
&lt;p&gt;Validate an agc-project.yaml file&lt;/p&gt;
&lt;h3 id=&#34;synopsis&#34;&gt;Synopsis&lt;/h3&gt;
&lt;p&gt;Determines if the current project specification follows the required format and lists any syntax errors.
The current project specification is determined to be the agc-project.yaml file in the current working directory or a parent of the current directory
Output of the command has following format:
PROJECT: Name
DATA: Location ReadOnly&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;agc project validate [flags]
&lt;/code&gt;&lt;/pre&gt;&lt;h3 id=&#34;examples&#34;&gt;Examples&lt;/h3&gt;
&lt;pre&gt;&lt;code&gt;
/code agc project describe
&lt;/code&gt;&lt;/pre&gt;&lt;h3 id=&#34;options&#34;&gt;Options&lt;/h3&gt;
&lt;pre&gt;&lt;code&gt;  -h, --help   help for validate
&lt;/code&gt;&lt;/pre&gt;&lt;h3 id=&#34;options-inherited-from-parent-commands&#34;&gt;Options inherited from parent commands&lt;/h3&gt;
&lt;pre&gt;&lt;code&gt;      --format string   Format option for output. Valid options are: text, table, json
      --silent          Suppresses all diagnostic information.
  -v, --verbose         Display verbose diagnostic information.
&lt;/code&gt;&lt;/pre&gt;&lt;h3 id=&#34;see-also&#34;&gt;SEE ALSO&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://aws.github.io/amazon-genomics-cli/amazon-genomics-cli/docs/reference/agc_project/&#34;&gt;agc project&lt;/a&gt;	 - Commands to interact with projects.&lt;/li&gt;
&lt;/ul&gt;

      </description>
    </item>
    
    <item>
      <title>Docs: agc workflow</title>
      <link>https://aws.github.io/amazon-genomics-cli/docs/reference/agc_workflow/</link>
      <pubDate>Mon, 06 May 2024 18:32:37 +0000</pubDate>
      
      <guid>https://aws.github.io/amazon-genomics-cli/docs/reference/agc_workflow/</guid>
      <description>
        
        
        &lt;h2 id=&#34;agc-workflow&#34;&gt;agc workflow&lt;/h2&gt;
&lt;p&gt;Commands for workflows.
Workflows are potentially-dynamic graphs of computational tasks to execute.&lt;/p&gt;
&lt;h3 id=&#34;synopsis&#34;&gt;Synopsis&lt;/h3&gt;
&lt;p&gt;Commands for workflows.
Workflows are potentially-dynamic graphs of computational tasks to execute.&lt;/p&gt;
&lt;p&gt;Workflow specifications are files whose content specify a workflow to execute
given a particular set of input parameters to use. Workflow specifications are
typed according to which workflow definition language they use (e.g. WDL).&lt;/p&gt;
&lt;h3 id=&#34;options&#34;&gt;Options&lt;/h3&gt;
&lt;pre&gt;&lt;code&gt;  -p, --awsProfile string   Use the provided AWS CLI profile.
  -h, --help                help for workflow
&lt;/code&gt;&lt;/pre&gt;&lt;h3 id=&#34;options-inherited-from-parent-commands&#34;&gt;Options inherited from parent commands&lt;/h3&gt;
&lt;pre&gt;&lt;code&gt;      --format string   Format option for output. Valid options are: text, table, json
      --silent          Suppresses all diagnostic information.
  -v, --verbose         Display verbose diagnostic information.
&lt;/code&gt;&lt;/pre&gt;&lt;h3 id=&#34;see-also&#34;&gt;SEE ALSO&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://aws.github.io/amazon-genomics-cli/amazon-genomics-cli/docs/reference/agc/&#34;&gt;agc&lt;/a&gt;	 - üß¨ Launch and manage genomics workloads on AWS.&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://aws.github.io/amazon-genomics-cli/amazon-genomics-cli/docs/reference/agc_workflow_describe/&#34;&gt;agc workflow describe&lt;/a&gt;	 - Show the information for a specific workflow in the current project&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://aws.github.io/amazon-genomics-cli/amazon-genomics-cli/docs/reference/agc_workflow_list/&#34;&gt;agc workflow list&lt;/a&gt;	 - Show a list of workflows related to the current project&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://aws.github.io/amazon-genomics-cli/amazon-genomics-cli/docs/reference/agc_workflow_output/&#34;&gt;agc workflow output&lt;/a&gt;	 - Show the output for a workflow run in the current project.&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://aws.github.io/amazon-genomics-cli/amazon-genomics-cli/docs/reference/agc_workflow_run/&#34;&gt;agc workflow run&lt;/a&gt;	 - Run a workflow&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://aws.github.io/amazon-genomics-cli/amazon-genomics-cli/docs/reference/agc_workflow_status/&#34;&gt;agc workflow status&lt;/a&gt;	 - Show the status for workflow run(s) in the current project.&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://aws.github.io/amazon-genomics-cli/amazon-genomics-cli/docs/reference/agc_workflow_stop/&#34;&gt;agc workflow stop&lt;/a&gt;	 - Stop the workflow with the specified workflow instance id.&lt;/li&gt;
&lt;/ul&gt;

      </description>
    </item>
    
    <item>
      <title>Docs: agc workflow describe</title>
      <link>https://aws.github.io/amazon-genomics-cli/docs/reference/agc_workflow_describe/</link>
      <pubDate>Mon, 06 May 2024 18:32:37 +0000</pubDate>
      
      <guid>https://aws.github.io/amazon-genomics-cli/docs/reference/agc_workflow_describe/</guid>
      <description>
        
        
        &lt;h2 id=&#34;agc-workflow-describe&#34;&gt;agc workflow describe&lt;/h2&gt;
&lt;p&gt;Show the information for a specific workflow in the current project&lt;/p&gt;
&lt;h3 id=&#34;synopsis&#34;&gt;Synopsis&lt;/h3&gt;
&lt;p&gt;describe is for showing details on the specified workflow.
It includes workflow specification and list of recent instances of that workflow.
An instance is created every time we run a workflow.&lt;/p&gt;
&lt;p&gt;Output of the command has following format:
WORKFLOW: Name Source TypeLanguage TypeVersion&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;agc workflow describe workflow_name [--max_instances] [flags]
&lt;/code&gt;&lt;/pre&gt;&lt;h3 id=&#34;options&#34;&gt;Options&lt;/h3&gt;
&lt;pre&gt;&lt;code&gt;  -h, --help   help for describe
&lt;/code&gt;&lt;/pre&gt;&lt;h3 id=&#34;options-inherited-from-parent-commands&#34;&gt;Options inherited from parent commands&lt;/h3&gt;
&lt;pre&gt;&lt;code&gt;  -p, --awsProfile string   Use the provided AWS CLI profile.
      --format string       Format option for output. Valid options are: text, table, json
      --silent              Suppresses all diagnostic information.
  -v, --verbose             Display verbose diagnostic information.
&lt;/code&gt;&lt;/pre&gt;&lt;h3 id=&#34;see-also&#34;&gt;SEE ALSO&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://aws.github.io/amazon-genomics-cli/amazon-genomics-cli/docs/reference/agc_workflow/&#34;&gt;agc workflow&lt;/a&gt;	 - Commands for workflows.
Workflows are potentially-dynamic graphs of computational tasks to execute.&lt;/li&gt;
&lt;/ul&gt;

      </description>
    </item>
    
    <item>
      <title>Docs: agc workflow list</title>
      <link>https://aws.github.io/amazon-genomics-cli/docs/reference/agc_workflow_list/</link>
      <pubDate>Mon, 06 May 2024 18:32:37 +0000</pubDate>
      
      <guid>https://aws.github.io/amazon-genomics-cli/docs/reference/agc_workflow_list/</guid>
      <description>
        
        
        &lt;h2 id=&#34;agc-workflow-list&#34;&gt;agc workflow list&lt;/h2&gt;
&lt;p&gt;Show a list of workflows related to the current project&lt;/p&gt;
&lt;h3 id=&#34;synopsis&#34;&gt;Synopsis&lt;/h3&gt;
&lt;p&gt;list is for showing a combined list of workflows defined in the project specification
and workflow instances that were run in this AWS account.&lt;/p&gt;
&lt;p&gt;Output of the command has following format:
WORKFLOWNAME: Name&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;agc workflow list [flags]
&lt;/code&gt;&lt;/pre&gt;&lt;h3 id=&#34;options&#34;&gt;Options&lt;/h3&gt;
&lt;pre&gt;&lt;code&gt;  -h, --help   help for list
&lt;/code&gt;&lt;/pre&gt;&lt;h3 id=&#34;options-inherited-from-parent-commands&#34;&gt;Options inherited from parent commands&lt;/h3&gt;
&lt;pre&gt;&lt;code&gt;  -p, --awsProfile string   Use the provided AWS CLI profile.
      --format string       Format option for output. Valid options are: text, table, json
      --silent              Suppresses all diagnostic information.
  -v, --verbose             Display verbose diagnostic information.
&lt;/code&gt;&lt;/pre&gt;&lt;h3 id=&#34;see-also&#34;&gt;SEE ALSO&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://aws.github.io/amazon-genomics-cli/amazon-genomics-cli/docs/reference/agc_workflow/&#34;&gt;agc workflow&lt;/a&gt;	 - Commands for workflows.
Workflows are potentially-dynamic graphs of computational tasks to execute.&lt;/li&gt;
&lt;/ul&gt;

      </description>
    </item>
    
  </channel>
</rss>
